{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "LSTM_103CL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNRPftWw9pK"
      },
      "source": [
        "# LSTM \n",
        "We previously used linear regression\n",
        "to predict future air temp based on past air temp.\n",
        "Here, use LSTM for the same task.\n",
        "Where LinReg viewed each vector as one point,\n",
        "LSTM will view each vector as a time series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeDotTmw9pX",
        "outputId": "6c2afbb0-0d3e-4a09-fb9b-ecc6f8da70eb"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "STEAM_FILE='steam.csv'\n",
        "WEATHER_FILE='weather.csv'\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5deM-us2w9pZ"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredError\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdk510Cw9pc"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n",
        "def get_site_timeseries(panda,site):\n",
        "    # Assume the panda dataframe has a datetime column.\n",
        "    # (If not, call fix_date_type() before this.)\n",
        "    # Extract the timeseries for one site.\n",
        "    # Convert the datetime column to a DatetimeIndex.\n",
        "    site_df = panda[panda['site_id']==site]\n",
        "    temp_col = site_df['date']\n",
        "    temp_val = temp_col.values\n",
        "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
        "    dropped = site_df.drop('date',axis=1)\n",
        "    panda = dropped.set_index(temp_ndx)\n",
        "    return panda"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZgkgsP6w9pg"
      },
      "source": [
        "SITE = 'Eagle'\n",
        "METER = 'steam'\n",
        "BLDG = 'Eagle_education_Peter'   # one example\n",
        "PREDICTOR_VARIABLE = 'airTemperature'  # for starters\n",
        "PREDICTED_VARIABLE = 'steam'  # for starters"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YVYM_bqw9pi"
      },
      "source": [
        "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
        "wet_df = fix_date_type(wet_df)\n",
        "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
        "stm_df = fix_date_type(stm_df)\n",
        "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
        "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynRgLt9w9pk"
      },
      "source": [
        "DOWNSAMPLE = False   # if true, use 1 time per day, else 24 times per day\n",
        "STEPS_HISTORY = 7 \n",
        "STEPS_FUTURE =  1    \n",
        "def smooth(df):\n",
        "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
        "    smoothed = None\n",
        "    if DOWNSAMPLE:\n",
        "        # This alternate method samples down to 1/24 time steps.\n",
        "        smoothed = df.resample(\"24H\").mean() \n",
        "    else:\n",
        "        # This method does not reduce the number of time steps.\n",
        "        # Note the first 23 measurements get set to Nan.\n",
        "        smoothed=df.rolling(window=24).mean()\n",
        "        smoothed=smoothed[24:]\n",
        "    return smoothed\n",
        "\n",
        "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
        "# We will ignore buildings that have >max bad meter readings.\n",
        "def is_usable_column(df,column_name):\n",
        "    MAX_BAD = 500 \n",
        "    bad = df[column_name].isin([0]).sum()\n",
        "    return bad<=MAX_BAD\n",
        "\n",
        "def prepare_for_learning(df):\n",
        "    # This is very slow. Is there a faster way? See...\n",
        "    # https://stackoverflow.com/questions/27852343/split-python-sequence-time-series-array-into-subsequences-with-overlap\n",
        "    # X = df.drop(METER,axis=1) # this would use all predictors, just drop the predicted\n",
        "    X=[]\n",
        "    y=[]\n",
        "    predictor_series = df[PREDICTOR_VARIABLE].values\n",
        "    predicted_series = df[PREDICTED_VARIABLE].values\n",
        "    for i in range(STEPS_HISTORY,len(df)-STEPS_FUTURE):\n",
        "        one_predictor = [[p] for p in predictor_series[i-STEPS_HISTORY:i]]\n",
        "        one_predicted = [[p] for p in predicted_series[i:i+STEPS_FUTURE]]\n",
        "        X.append(one_predictor)\n",
        "        y.append(one_predicted)\n",
        "    # Return two lists of lists of lists.\n",
        "    # At this point, each data point is a scalar (1D) but RNN expects a vector.\n",
        "    # 1000 samples * 100 time steps * 1D vector.\n",
        "    return X,y \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8rzumTw9p2"
      },
      "source": [
        "TIMESTEP_VECTOR_DIMENSION = 1 # we are univariate so far\n",
        "def make_RNN():\n",
        "    rnn = Sequential([\n",
        "        LSTM(40,return_sequences=True, \n",
        "                  input_shape=(STEPS_HISTORY,TIMESTEP_VECTOR_DIMENSION)), \n",
        "        LSTM(20,return_sequences=True),\n",
        "        LSTM(STEPS_FUTURE)  \n",
        "    ])\n",
        "    #        TimeDistributed(Dense(STEPS_FUTURE))  ???\n",
        "    rnn = Sequential([\n",
        "        SimpleRNN(20,return_sequences=True, \n",
        "                  input_shape=(STEPS_HISTORY,TIMESTEP_VECTOR_DIMENSION)), \n",
        "        SimpleRNN(10,return_sequences=False),\n",
        "        Dense(STEPS_FUTURE)  \n",
        "    ])\n",
        "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
        "    return rnn"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypnRqq9w9p4",
        "outputId": "a6f81f4b-b26e-4259-c2c6-da461b57937d"
      },
      "source": [
        "cors = []\n",
        "EPOCHS=50\n",
        "# Test on only Peter just during code development\n",
        "for BLDG in all_buildings:\n",
        "    print(\"Building\",BLDG)\n",
        "    # Get steam usage for one building.\n",
        "    bldg_specific_steam = stm_df[[BLDG]]\n",
        "    # Concatenate steam usage with weather.\n",
        "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
        "    # Drop the site, which is constant (we selected for one site).\n",
        "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
        "    # The original steam table used column name = building name.\n",
        "    # We are processing one building, so rename to the column 'steam'.\n",
        "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
        "    # In order to filter bad buildings, count sum of NaN + zero.\n",
        "    one_bldg_df = one_bldg_df.fillna(0)\n",
        "    \n",
        "    if is_usable_column(one_bldg_df,METER):\n",
        "        one_bldg_df = smooth(one_bldg_df) \n",
        "        X,y = prepare_for_learning(one_bldg_df)\n",
        "        # Ideally, split Year1 = train, Year2 = test.\n",
        "        # Some data is incomplete, so split 1st half and 2nd half.\n",
        "        split = len(X)//2 \n",
        "        X_train = np.asarray(X[0:split])\n",
        "        y_train = np.asarray(y[0:split])\n",
        "        X_test = np.asarray(X[split:])\n",
        "        y_test = np.asarray(y[split:])\n",
        "        print(\"Train on\",len(X_train),\"samples...\")\n",
        "        model = make_RNN()\n",
        "        print(model.summary())\n",
        "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Compare. Solve the problem that predict.shape != truth.shape \n",
        "        ##print(\" before ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
        "        nsamples, nsteps, ndim = y_test.shape\n",
        "        y_test = y_test.reshape(nsamples,nsteps*ndim)\n",
        "        #nsamples, nsteps, ndim = y_pred.shape\n",
        "        #y_pred = y_pred.reshape(nsamples,nsteps*ndim)\n",
        "        ##print(\" after ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
        "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
        "        # Keep a table for reporting later.\n",
        "        mean = one_bldg_df[METER].mean()\n",
        "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][PREDICTOR_VARIABLE] \n",
        "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
        "        print(\"cor,mean,rmse,rmse/mean,bldg:\",cor,mean,rmse,rmse/mean,BLDG)\n",
        "\n",
        "        ## break   ## REMOVE THIS LINE TO LOOP OVER BUILDINGS!\n",
        "        \n",
        "if True:\n",
        "    print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
        "    print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",PREDICTOR_VARIABLE)\n",
        "    print(\"          Using one weather feature as leading correlate.\")\n",
        "    print(\"Column 2: Mean usage.\")\n",
        "    print(\"          Using mean to help understand the RMSE.\")\n",
        "    print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
        "    print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
        "    print(\"Column 5: Building.\")\n",
        "    for cor in sorted(cors):\n",
        "        print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            "Building Eagle_health_Athena\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_18 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_19 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 345319.9851\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 325809.2133\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 334212.9890\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 332911.3337\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 323112.7802\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 323697.3267\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 316062.4100\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 311882.7102\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 308553.4155\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 308296.4707\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 305782.2786\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 300011.9734\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 295731.7156\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 300303.1752\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 291353.7256\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 294051.5260\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 292264.7450\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 287391.9241\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 283289.2074\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 282043.9809\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 274387.0361\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 277004.5869\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 268028.1841\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 268677.4614\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 267799.1714\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 263502.5748\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 266824.3243\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 262232.0464\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 257106.4912\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 254868.7197\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 248412.3655\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 247415.6658\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 249364.0085\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 240940.9811\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 240528.8749\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 233107.2200\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 238054.0641\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 235587.1741\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 236999.2068\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 233217.4973\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 227529.4626\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 225919.5490\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 227525.3559\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 219102.0627\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 218359.8856\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 216431.3644\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 209641.1310\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 215916.7995\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 204967.6817\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 206754.8528\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.849214848008229 477.4110643545472 352.22088954653884 0.7377727829218544 Eagle_health_Athena\n",
            "Building Eagle_assembly_Herbert\n",
            "Building Eagle_public_Alvin\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_20 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_21 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 51885.6255\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 50383.5926\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 49740.3103\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 47338.1553\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 47235.2146\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 43864.6569\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 44476.8495\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 42732.6422\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 42245.1046\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 41461.0608\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 39564.8419\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 39667.5930\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 38561.6835\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 37382.3929\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 36516.9868\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 34719.4297\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 34081.4706\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 33660.1694\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 32803.6732\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 31466.6338\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 30659.4465\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 30357.7739\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 29314.8748\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 28381.6864\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 27663.0840\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 26601.9824\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 26609.9708\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 25472.7949\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 24450.5351\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 24418.7530\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 23706.5480\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 22500.7102\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 22011.7671\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 21284.0383\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 20962.0020\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 21024.2205\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 19526.3149\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 19536.9326\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18531.6738\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18361.4259\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17584.4109\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17749.7545\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16963.4860\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16531.6288\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16090.9133\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 14722.5903\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 15337.5790\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 14998.0084\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 14071.9353\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 14295.9002\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.755524810622147 181.93965687500068 56.12133980366132 0.30846128198548145 Eagle_public_Alvin\n",
            "Building Eagle_education_Raul\n",
            "Building Eagle_education_Roman\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_22 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_23 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 1681864.9755\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1655446.5259\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1627185.8718\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1626576.2405\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1628795.8555\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1601665.1041\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1610032.1323\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1609136.9050\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1596246.1214\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1605628.9845\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1579150.7636\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1564364.4573\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1588258.7959\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1534044.5105\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1535354.9745\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1546171.6777\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1548986.6823\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1541156.3755\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1515572.9964\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1532332.3018\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1523902.5477\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1511902.6023\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1461303.0764\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1503536.5050\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1490202.8295\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1477673.2114\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1454662.5414\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1477799.2905\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1487879.7977\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1437814.8650\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1431554.1355\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1445260.6591\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1449618.0495\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1412991.3418\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1413331.3527\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1411402.5291\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1402719.9168\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1414216.8055\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1356223.8168\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1381735.4477\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1342046.6459\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1375274.9450\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1367601.6068\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1366826.3855\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1358870.2445\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1354547.3273\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1311516.8077\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1359393.9659\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1319227.9114\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1309493.9882\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8040385849969112 1197.0160150732597 1119.0396883139724 0.9348577414358863 Eagle_education_Roman\n",
            "Building Eagle_office_Mandi\n",
            "Building Eagle_education_Jewell\n",
            "Building Eagle_office_Henriette\n",
            "Building Eagle_health_Reba\n",
            "Building Eagle_lodging_Edgardo\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_24 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_25 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 8684.2894\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7903.9152\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7284.9129\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6640.5810\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6376.8623\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6192.9539\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5744.1386\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5216.1034\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5041.0405\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4741.0513\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4603.3892\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4442.5033\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4084.5963\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3949.9181\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3656.4339\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3488.3575\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3254.6800\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2998.3075\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3122.5369\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2833.6401\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2749.6598\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2723.7350\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2604.5856\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2519.9777\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2304.3394\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2373.3095\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2363.3543\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2015.2791\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1944.2533\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1877.2222\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1782.9799\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1673.0095\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1583.6736\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1518.2582\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1555.7501\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1433.1167\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1400.6177\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1348.0990\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1261.6250\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1240.0287\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1160.5012\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1146.0156\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1107.8143\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1061.4094\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 998.4210\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 998.1185\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 981.7885\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 973.5388\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 941.4665\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 904.4380\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7661481928706323 81.87169456264219 29.892428159567448 0.36511309945705306 Eagle_lodging_Edgardo\n",
            "Building Eagle_education_Cassie\n",
            "Building Eagle_education_Peter\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_26 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_27 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 13005849.4909\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12920154.0436\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12716707.5564\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12710457.5491\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12971155.3527\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12546409.5382\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12651511.5600\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12503123.3164\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12477675.9418\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12703477.8255\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12665774.6727\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12898992.2909\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12739336.8800\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12434305.6545\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 12544666.2436\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12435453.2909\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12539279.0255\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12398231.9455\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12498495.3491\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12639161.1891\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12291057.4582\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12383734.8873\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12343672.4073\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12306243.9418\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12261591.2327\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12258997.9455\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12403847.1345\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12306693.8873\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12118495.2291\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12546061.5127\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12431839.5164\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12210264.2473\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12216540.3964\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12175454.4400\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12076623.5745\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12089707.1345\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12134843.4327\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12243992.0945\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12006350.0436\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12148401.0109\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11943910.8945\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11770005.6836\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12095117.7309\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11846766.8109\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11914056.5236\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11901396.4218\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11768627.5782\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 12035111.8400\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11886923.4873\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11826017.5382\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8267485430759834 3147.4307034315702 3079.9949194240985 0.9785743387665539 Eagle_education_Peter\n",
            "Building Eagle_health_Gregoria\n",
            "Building Eagle_lodging_Dawn\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_28 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_29 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 12706.9402\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11799.5749\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11042.2488\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 10869.9526\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 10168.9160\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9718.3315\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8952.5538\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8668.8672\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8433.2338\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8096.7953\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7664.9057\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7426.1427\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6815.4494\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6523.8126\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6315.7373\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5983.5060\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5690.5716\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5328.0313\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4964.9415\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4672.1030\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4833.5035\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4624.3286\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4359.9017\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4103.2821\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3913.9484\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3833.4382\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3899.0212\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3452.0401\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3263.3105\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3355.0411\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3135.1803\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3035.5034\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2893.3067\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2721.7700\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2793.4604\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2606.7099\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2631.9043\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2411.2024\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2388.9212\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2311.6480\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2198.7494\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2209.5238\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1998.6100\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1975.2340\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2008.1066\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1909.3157\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1795.2851\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1806.3022\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1730.4945\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1673.3369\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7248890899079364 92.73484781606884 39.64639427658803 0.42752422859660116 Eagle_lodging_Dawn\n",
            "Building Eagle_office_Nereida\n",
            "Building Eagle_lodging_Tressa\n",
            "Building Eagle_education_Eileen\n",
            "Building Eagle_education_Wesley\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_30 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_31 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 0.0273\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3.7552e-04\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3.2629e-04\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.6594e-04\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5519e-04\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5869e-04\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.5507e-04\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3303e-04\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2495e-04\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4823e-04\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4047e-04\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.4691e-04\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.5143e-04\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2395e-04\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5426e-04\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3993e-04\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.9163e-04\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4648e-04\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2449e-04\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5591e-04\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4662e-04\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.3557e-04\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2433e-04\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.3445e-04\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2527e-04\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.6163e-04\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5944e-04\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3747e-04\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.2475e-04\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.5250e-04\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2370e-04\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4789e-04\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2491e-04\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3186e-04\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2567e-04\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3854e-04\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3664e-04\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3097e-04\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.4015e-04\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2901e-04\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3867e-04\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.1975e-04\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.4010e-04\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2244e-04\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.2567e-04\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2637e-04\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.1742e-04\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.3142e-04\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2.2270e-04\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2.2960e-04\n",
            "cor,mean,rmse,rmse/mean,bldg: 0.7078518941773995 0.10523124548135511 0.028043870288022067 0.26649756124943785 Eagle_education_Wesley\n",
            "Building Eagle_health_Vincenza\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_32 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_33 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 15110.2965\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 13853.4992\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 13070.5479\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12454.3498\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11828.5330\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11202.1665\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 10771.1696\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 10038.4712\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9687.0554\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9227.2079\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8704.8854\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8197.6340\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7836.3689\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7362.7837\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6987.5625\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6586.7093\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6282.8461\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5798.4444\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5645.7803\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5247.0268\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4954.0386\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4563.2800\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4352.2618\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4044.2341\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3975.6046\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3647.9290\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3413.2893\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3271.6411\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3062.6760\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2934.6419\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2760.2592\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2556.1233\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2365.4743\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2302.7018\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2197.3298\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2154.3195\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1981.6613\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1933.1114\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1838.0637\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1844.6020\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1797.1357\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1730.4158\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1647.7812\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1653.8935\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1641.4821\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1653.9692\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1612.5193\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1647.4595\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1590.6164\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1616.0241\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8217409529348659 121.90840096508708 35.58218419255212 0.2918763917077575 Eagle_health_Vincenza\n",
            "Building Eagle_office_Dallas\n",
            "Building Eagle_education_Shante\n",
            "Building Eagle_office_Chauncey\n",
            "Building Eagle_office_Phyllis\n",
            "Building Eagle_office_Freida\n",
            "Building Eagle_office_Francis\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_34 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_35 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 85295.2128\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 82685.7091\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 81165.6390\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 79505.1385\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 77198.4484\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 76106.7925\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 74302.6622\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 72914.4338\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 71829.4894\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 69903.1608\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 68315.7425\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 66948.0593\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 66470.5167\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 64745.5434\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 62680.4812\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 61653.4769\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 60202.3229\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 59008.7407\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 57149.4257\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 55637.7410\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 54539.8038\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 53295.8682\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 53275.0851\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 51149.8070\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 50395.2730\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 49027.6166\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 47824.9295\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 46899.8340\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 45171.3129\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 44874.9812\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 43599.4176\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 42082.7570\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 41232.5313\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 40442.1383\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 38728.6268\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 38456.2178\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 36602.9873\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 36156.7316\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 35935.7389\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 34262.6091\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 33753.2340\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 32242.6890\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 31513.4269\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 30190.5904\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 29721.9341\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 29069.3387\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 28298.9866\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 27244.0970\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 26254.5831\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 25169.3850\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.612183884934729 335.95636354975403 257.36396843218785 0.7660636807496373 Eagle_office_Francis\n",
            "Building Eagle_office_Sheree\n",
            "Building Eagle_education_Sherrill\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_36 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_37 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 5462177.8127\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5393426.9800\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5375838.2127\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5420457.5036\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5271601.1891\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5333980.3873\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5336019.6200\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5314772.6573\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5162346.6455\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5293539.1491\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5293822.4455\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5222163.8600\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5151773.4800\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5150615.7800\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5277954.4436\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5215367.4418\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5146846.6855\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5269514.0800\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5137619.0018\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5154025.7436\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5103303.0309\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5103303.7382\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5107054.9282\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5128480.1455\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4992489.0709\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5017220.8218\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5074698.4000\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4976154.9200\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5054139.5291\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5060846.7545\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5073296.6527\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4955113.9736\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5034297.1073\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4971115.7327\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4930525.8509\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5006543.3255\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4998020.7800\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5017506.5091\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5019314.5218\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4977402.6900\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4825477.9545\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4771641.3000\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4843361.8764\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4977265.8891\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4770223.9264\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4941255.8127\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4934397.7236\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4849877.4036\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4828898.5182\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4703220.2418\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.9191698832911114 2030.3587884358317 2110.9153052835914 1.0396760007672434 Eagle_education_Sherrill\n",
            "Building Eagle_education_Brooke\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_38 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_39 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 4316538.3164\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4377053.3400\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4386507.0127\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4312864.3573\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4310151.3009\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4370830.1109\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4299442.9609\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4244451.8964\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4258682.4773\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4225789.8955\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4163918.9555\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4201499.9973\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4266005.8645\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4294720.6527\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4197539.6400\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4171243.1727\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4162485.3018\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4194458.1655\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4181111.8918\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4106293.1091\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4183117.2809\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4169596.3873\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4096114.1864\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4045692.9427\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4126582.6964\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4114507.3773\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4108241.1973\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4081456.1591\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4096789.2082\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4040905.7736\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3965301.0173\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4044473.9427\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4047760.4773\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4053312.1518\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3961480.4955\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3958090.7673\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3975403.3291\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3901199.4682\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3943988.3018\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3963146.9918\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3963302.3764\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3870843.1945\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3946133.9564\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3935160.2355\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3895435.9109\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3835394.7873\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3937055.0918\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3897936.4836\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3873502.8200\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3771097.8891\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8668943529930063 1634.2804902547134 1574.6600910649668 0.9635188698970185 Eagle_education_Brooke\n",
            "Building Eagle_education_Alberto\n",
            "Building Eagle_food_Kay\n",
            "Building Eagle_health_Jodi\n",
            "Building Eagle_education_Norah\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_40 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_41 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 611797.8416\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 596874.6655\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 602986.9100\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 576434.1668\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 592832.5323\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 584152.8180\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 562048.0934\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 556933.2492\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 580864.1031\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 572490.3036\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 566032.2500\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 576960.7550\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 545132.2324\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 542525.2126\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 531567.9053\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 536846.8575\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 537373.8575\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 538549.9827\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 541647.5925\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 542952.3272\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 519244.8950\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 520992.6312\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 513902.0680\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 521791.4424\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 507387.8364\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 498606.1635\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 501089.9836\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 499627.5036\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 498684.5766\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 495313.2170\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 489139.1584\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 488079.4345\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 478868.3707\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 477675.4210\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 494093.8241\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 457558.9011\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 468639.8464\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 455184.1826\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 467853.3881\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 457305.3892\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 452125.1711\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 458173.6858\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 453970.3327\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 444971.4707\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 441238.5932\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 444052.7947\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 434114.5822\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 433683.2541\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 433064.6308\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 432247.4609\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8006961414633348 711.3309670245861 702.6958445863334 0.9878606122345939 Eagle_education_Norah\n",
            "Building Eagle_education_Will\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_42 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_43 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 76633.5195\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 72872.4908\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 71104.0117\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 71418.1939\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 68478.6367\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 67764.2470\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 65377.0808\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 65231.4954\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 63866.2345\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 62957.6454\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 60707.9023\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 59508.0127\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 57261.4010\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 56683.8266\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 55925.4113\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 54247.4307\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 53119.0462\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 51995.3475\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 50933.9992\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 48572.5649\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 49036.5382\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 47085.0866\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 45610.5132\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 44544.5753\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 44458.1507\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 41885.4007\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 41333.7247\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 39868.2338\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 39660.4182\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 39156.7951\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 37460.3023\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 36329.1483\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 35922.6034\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 34741.0770\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 34095.3081\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 31918.5936\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 32028.2040\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 31247.8516\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 29857.0498\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 28945.0841\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 28690.4384\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 27861.2848\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 27210.3555\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 26688.2833\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 24565.2975\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 25000.2022\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 23482.8478\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 23291.6186\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 22923.5752\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 21854.8852\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.3432541996930441 226.06948909769736 60.38917703851708 0.26712661350076977 Eagle_education_Will\n",
            "Building Eagle_lodging_Blake\n",
            "Building Eagle_education_Petra\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_44 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_45 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 4080.4931\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3611.0822\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3267.9584\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3079.0233\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2724.1808\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2605.2506\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2434.6906\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2332.6780\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2068.8880\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1956.6383\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1877.9764\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1710.9665\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1627.9882\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1542.1776\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1497.4024\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1445.6371\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1418.3236\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1293.5906\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1279.4324\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1223.6860\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1052.6384\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 980.4712\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 861.9315\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 861.0949\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 822.8212\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 730.5390\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 693.6199\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 626.4926\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 573.6723\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 550.7419\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 532.3377\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 497.5507\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 480.9922\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 424.1274\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 408.7136\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 388.1605\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 364.6079\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 355.0593\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 329.4429\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 333.3047\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 305.7403\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 314.1306\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 296.6395\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 276.4516\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 265.5562\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 260.7319\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 257.8429\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 242.2510\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 236.6891\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 237.8600\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8318744067272149 56.9627497750187 16.534227704970746 0.29026386138791904 Eagle_education_Petra\n",
            "Building Eagle_lodging_Trina\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_46 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_47 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 11152.8228\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 10455.5813\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9689.8386\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9497.0108\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9308.9690\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8493.8383\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8420.8212\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8200.3466\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7688.8236\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7210.1891\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7212.7571\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6731.1420\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6351.6779\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6418.9031\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5734.0218\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6041.7220\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5385.2596\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5449.5987\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5022.7826\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5126.1256\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4980.4891\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4694.9330\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4732.4669\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4376.8215\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4546.1711\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4218.5084\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3991.5542\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3872.8772\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 4052.2198\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3897.0250\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3605.3629\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3510.4585\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3371.4343\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3113.0212\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3146.7168\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2973.3515\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3049.1890\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 3020.6293\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2835.9781\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2760.0323\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2609.1202\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2663.5398\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2686.3521\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2405.2933\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2457.8027\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2397.1741\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2199.6034\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2362.4940\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2377.0499\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2153.5712\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7102555423632535 91.19691350551751 34.7641568078799 0.38119883087684353 Eagle_lodging_Trina\n",
            "Building Eagle_health_Reuben\n",
            "Building Eagle_education_Teresa\n",
            "Train on 8756 samples...\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_48 (SimpleRNN)    (None, 7, 20)             440       \n",
            "_________________________________________________________________\n",
            "simple_rnn_49 (SimpleRNN)    (None, 10)                310       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 761\n",
            "Trainable params: 761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 2s 4ms/step - loss: 29107.7044\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 27089.0249\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 25991.7072\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 25189.9873\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 24539.7386\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 24244.6738\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 23557.0050\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 22234.8252\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 21379.5680\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 20959.9827\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 20617.3600\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 19827.9820\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 18346.2036\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 17525.3788\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 17616.0376\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 17447.1107\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 16825.9748\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 16149.4574\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 15449.2239\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 14875.3519\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 14476.7192\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 13709.3314\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 13406.4314\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 13416.0495\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 12940.4952\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 12377.8174\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11957.4300\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11520.0668\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 11255.0052\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 10800.4471\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 10558.2700\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 10052.7836\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9967.8531\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9361.9119\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9598.6450\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 9021.3796\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8860.1513\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8504.5674\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8628.2591\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 8299.7430\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7934.2555\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7213.6700\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7238.8325\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7441.4019\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7475.1426\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6978.1504\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6548.8744\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6542.6319\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6127.5389\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6002.7337\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.730241336157007 148.50737262033783 43.299061516404336 0.2915616965839082 Eagle_education_Teresa\n",
            "Building Eagle_office_Norbert\n",
            "Building Eagle_lodging_Casey\n",
            "Building Eagle_office_Tia\n",
            "Building Eagle_office_Remedios\n",
            "Building Eagle_office_Patrice\n",
            "Building Eagle_education_Shana\n",
            "History 7 Future 1\n",
            "Column 1: Correlation of steam and airTemperature\n",
            "          Using one weather feature as leading correlate.\n",
            "Column 2: Mean usage.\n",
            "          Using mean to help understand the RMSE.\n",
            "Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\n",
            "Column 4: RMSE/mean normalized to help understand RMSE.\n",
            "Column 5: Building.\n",
            "-0.9192    2030.36    2110.92  1.04   Eagle_education_Sherrill\n",
            "-0.8669    1634.28    1574.66  0.96   Eagle_education_Brooke\n",
            "-0.8492     477.41     352.22  0.74   Eagle_health_Athena\n",
            "-0.8319      56.96      16.53  0.29   Eagle_education_Petra\n",
            "-0.8267    3147.43    3079.99  0.98   Eagle_education_Peter\n",
            "-0.8217     121.91      35.58  0.29   Eagle_health_Vincenza\n",
            "-0.8040    1197.02    1119.04  0.93   Eagle_education_Roman\n",
            "-0.8007     711.33     702.70  0.99   Eagle_education_Norah\n",
            "-0.7661      81.87      29.89  0.37   Eagle_lodging_Edgardo\n",
            "-0.7555     181.94      56.12  0.31   Eagle_public_Alvin\n",
            "-0.7302     148.51      43.30  0.29   Eagle_education_Teresa\n",
            "-0.7249      92.73      39.65  0.43   Eagle_lodging_Dawn\n",
            "-0.7103      91.20      34.76  0.38   Eagle_lodging_Trina\n",
            "-0.6122     335.96     257.36  0.77   Eagle_office_Francis\n",
            "-0.3433     226.07      60.39  0.27   Eagle_education_Will\n",
            " 0.7079       0.11       0.03  0.27   Eagle_education_Wesley\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW9PKIwow9p8"
      },
      "source": [
        "## Useful Links\n",
        "\n",
        "Jason Brownlee  \n",
        "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
        "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
        "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/\n",
        "https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1WeQ4Vw9p-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}