{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN_225.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNRPftWw9pK"
      },
      "source": [
        "# RNN \n",
        "Use non-consecutive predictors. Skip = 3. Use 7 predictors (prev 21 hr) to predict next 3 (9 hr). Smoothing window size 3. Predict steam given steam and day of year. Compare to RNN 223, 224."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5deM-us2w9pZ"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredError\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZgkgsP6w9pg",
        "outputId": "6c397309-50f8-46dc-e1a7-f4132662c38b"
      },
      "source": [
        "# Constants\n",
        "EPOCHS=50  # use 5 for software testing, 50 for model testing\n",
        "SITE = 'Eagle'\n",
        "PREDICTORS = ['hour','month','doy','meter','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
        "PREDICTORS = ['doy','meter'] # short list for testing\n",
        "NUM_PREDICTORS=len(PREDICTORS)\n",
        "print(\"PREDICTORS=\",NUM_PREDICTORS,PREDICTORS)\n",
        "PREDICTED_VARIABLE = 'meter'  \n",
        "STEPS_SKIP = 3\n",
        "STEPS_FORWARD = 7 \n",
        "STEPS_FUTURE =  3 \n",
        "METER_FILE='steam.csv'\n",
        "WEATHER_FILE='weather.csv'\n",
        "EXAMPLE='Eagle_lodging_Edgardo'\n",
        "SITE_BUILDINGS = None\n",
        "SMOOTHING_WINDOW=3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTORS= 2 ['doy', 'meter']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeDotTmw9pX",
        "outputId": "9827de78-5753-4cab-ded5-6f2bd94c4efc"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdk510Cw9pc"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "6YVYM_bqw9pi",
        "outputId": "f03c8f37-b0ea-4465-e19d-8760bd7f8c7e"
      },
      "source": [
        "def load_weather_for_site(site):\n",
        "    wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
        "    wet_df = fix_date_type(wet_df)\n",
        "    site_df = wet_df.loc[wet_df['site_id'] == site]\n",
        "    # Drop the site, which is constant (we selected for one site).\n",
        "    site_df = site_df.drop(['site_id'],axis=1)\n",
        "    site_df.insert(0,'hour',0)\n",
        "    site_df.insert(1,'month',0)\n",
        "    site_df.insert(2,'doy',0)\n",
        "    L=len(site_df)\n",
        "    for i in range(0,L):\n",
        "        dt=site_df.index[i]\n",
        "        hour=dt.hour\n",
        "        month=dt.month\n",
        "        doy=dt.dayofyear\n",
        "        site_df.iat[i,0] = hour\n",
        "        site_df.iat[i,1] = month\n",
        "        site_df.iat[i,2] = doy\n",
        "    return site_df\n",
        "\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "one_site_weather.tail()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>doy</th>\n",
              "      <th>airTemperature</th>\n",
              "      <th>cloudCoverage</th>\n",
              "      <th>dewTemperature</th>\n",
              "      <th>precipDepth1HR</th>\n",
              "      <th>precipDepth6HR</th>\n",
              "      <th>seaLvlPressure</th>\n",
              "      <th>windDirection</th>\n",
              "      <th>windSpeed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 18:00:00</th>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-11.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1026.2</td>\n",
              "      <td>330.0</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-21.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-21.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.2</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.4</td>\n",
              "      <td>330.0</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.4</td>\n",
              "      <td>320.0</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     hour  month  doy  ...  seaLvlPressure  windDirection  windSpeed\n",
              "timestamp                              ...                                          \n",
              "2017-12-31 18:00:00    18     12  365  ...          1026.2          330.0        2.6\n",
              "2017-12-31 20:00:00    20     12  365  ...          1027.0          320.0        1.5\n",
              "2017-12-31 21:00:00    21     12  365  ...          1027.2          310.0        2.6\n",
              "2017-12-31 22:00:00    22     12  365  ...          1027.4          330.0        3.1\n",
              "2017-12-31 23:00:00    23     12  365  ...          1027.4          320.0        4.6\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "s-EKuCBibz9d",
        "outputId": "20bd317e-3710-4c45-f9fa-9fde4b38ddf7"
      },
      "source": [
        "def load_meter_for_building(bldg,smooth=0):\n",
        "    all_df = read_zip_to_panda(ZIP_PATH,METER_FILE)\n",
        "    all_df = fix_date_type(all_df)\n",
        "    global SITE_BUILDINGS\n",
        "    SITE_BUILDINGS = [x for x in all_df.columns if x.startswith(SITE)]\n",
        "    site_series = all_df[bldg]\n",
        "    site_df = site_series.to_frame()\n",
        "    #site_df = all_df.loc[all_df['site_id'] == site]\n",
        "    # Change column name from building name to meter.\n",
        "    site_df = site_df.rename(columns={bldg : PREDICTED_VARIABLE})\n",
        "    if smooth>0:\n",
        "        site_df = site_df.rolling(smooth).mean()\n",
        "    return site_df\n",
        "\n",
        "one_bldg_meter = load_meter_for_building(EXAMPLE)\n",
        "print(type(one_bldg_meter))\n",
        "one_bldg_meter.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meter</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 19:00:00</th>\n",
              "      <td>92.2957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>277.5584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>280.5331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>289.3302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>164.3474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        meter\n",
              "timestamp                    \n",
              "2017-12-31 19:00:00   92.2957\n",
              "2017-12-31 20:00:00  277.5584\n",
              "2017-12-31 21:00:00  280.5331\n",
              "2017-12-31 22:00:00  289.3302\n",
              "2017-12-31 23:00:00  164.3474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynRgLt9w9pk",
        "outputId": "5d509e74-4fb8-4fd7-faed-9fda091748ff"
      },
      "source": [
        "# This is the first version that uses STEPS_SKIP.\n",
        "# To retrofit this to older notebooks, set STEPS_SKIP=0.\n",
        "def prepare_for_learning(wdf,mdf):\n",
        "    df = pd.concat([wdf,mdf],axis=1)\n",
        "    num_samples = len(df) - STEPS_FORWARD*STEPS_SKIP - STEPS_FUTURE*STEPS_SKIP\n",
        "    X_shape = (num_samples,STEPS_FORWARD,NUM_PREDICTORS)\n",
        "    Y_shape = (num_samples,STEPS_FUTURE)\n",
        "    X=np.zeros(X_shape)\n",
        "    y=np.zeros(Y_shape)\n",
        "    predictor_series = df[PREDICTORS].values  # selected features\n",
        "    predicted_series = df[PREDICTED_VARIABLE].values  # meter\n",
        "    # TO DO: can we take predicted from mdf instead?\n",
        "    for sam in range (0,num_samples): \n",
        "        prev_val = 0\n",
        "        for time in range (0,STEPS_FORWARD): \n",
        "            one_period = predictor_series[sam+time*STEPS_SKIP]\n",
        "            for feat in range (0,NUM_PREDICTORS):\n",
        "                val = one_period[feat]\n",
        "                if np.isnan(val):\n",
        "                    val = prev_val\n",
        "                else:\n",
        "                    prev_val = val\n",
        "                X[sam,time,feat] = val\n",
        "        for time1 in range (STEPS_FORWARD,STEPS_FORWARD+STEPS_FUTURE): \n",
        "            time0 = time1 - STEPS_FORWARD\n",
        "            y[sam,time0]=predicted_series[sam+time1*STEPS_SKIP]\n",
        "    return X,y \n",
        "X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "print(\"X shape:\",X.shape)\n",
        "print(\"y shape:\",y.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (17514, 7, 2)\n",
            "y shape: (17514, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mObWmpMDVuNQ",
        "outputId": "c0e5dc00-5e8f-4017-d839-6d6ff96c6697"
      },
      "source": [
        "print(\"X columns:\",PREDICTORS)\n",
        "print(\"X example:\\n\",X[100].astype(int))\n",
        "print(\"y example:\\n\",y[100].astype(int))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X columns: ['doy', 'meter']\n",
            "X example:\n",
            " [[  5 232]\n",
            " [  5 135]\n",
            " [  5 320]\n",
            " [  5 296]\n",
            " [  5 235]\n",
            " [  5 172]\n",
            " [  5 225]]\n",
            "y example:\n",
            " [222  43 322]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8rzumTw9p2"
      },
      "source": [
        "def make_RNN():\n",
        "    # The GRU in Keras is optimized for speed on CoLab GPU.\n",
        "    rnn = Sequential([\n",
        "        GRU(16,return_sequences=True, \n",
        "                  input_shape=(STEPS_FORWARD,NUM_PREDICTORS)), \n",
        "        GRU(16,return_sequences=True),\n",
        "        GRU(16,return_sequences=False),\n",
        "        Dense(STEPS_FUTURE)\n",
        "    ])\n",
        "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
        "    return rnn"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypnRqq9w9p4",
        "scrolled": false,
        "outputId": "f9a6fd76-01be-4b7b-f95f-f2d8c18d1fea"
      },
      "source": [
        "cors = []\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "for BLDG in SITE_BUILDINGS:\n",
        "    print(\"Building\",BLDG)\n",
        "    one_bldg_meter = load_meter_for_building(BLDG,SMOOTHING_WINDOW)\n",
        "    count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "    MAX_BAD = 500\n",
        "    if count_bad<=MAX_BAD:\n",
        "        # Must get rid of Nan labels, else loss hits NaN during training.\n",
        "        print(\" Count bad values before pseudofill:\",count_bad)\n",
        "        pseudovalue = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
        "        count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "        print(\" Count bad values after pseudofill:\",count_bad)\n",
        "        # \n",
        "        X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "        split = len(X)//2   # year 1 vs year 2\n",
        "        X_train = np.asarray(X[0:split])\n",
        "        y_train = np.asarray(y[0:split])\n",
        "        X_test = np.asarray(X[split:])\n",
        "        y_test = np.asarray(y[split:])\n",
        "        model = make_RNN()\n",
        "        print(model.summary())\n",
        "        #print(\"Example X train:\\n\",X_train[example].astype(int))\n",
        "        example=411\n",
        "        print(\"Example y train:\\n\",y_train[example].astype(int))\n",
        "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
        "        # Keep a table for reporting later.\n",
        "        y_pred = model.predict(X_test)\n",
        "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
        "        mean = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
        "        print(\"mean,rmse,rmse/mean,bldg:\",mean,rmse,rmse/mean,BLDG)\n",
        "        for hr in range(0,24,2):\n",
        "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))\n",
        "print()\n",
        "print(\"History\",STEPS_FORWARD,\"Future\",STEPS_FUTURE)\n",
        "print(\"Column 1: Mean usage.\")\n",
        "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
        "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
        "print(\"Column 4: Building.\")\n",
        "for cor in sorted(cors):\n",
        "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [58 58 72]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 20s 5ms/step - loss: 1186.3695\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 878.1918\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 673.8937\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 540.1477\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 429.1287\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 359.8451\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 300.3411\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 267.9622\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 214.0931\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 156.4280\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 122.7137\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 98.9955\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 78.8164\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 67.6534\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 59.3970\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 53.3272\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 50.2330\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 46.9568\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 45.5533\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.4693\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 41.5284\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.2576\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.3824\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.9703\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.1034\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.5228\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.8436\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.4519\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.6036\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.1240\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.3045\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.9380\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.8700\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.8743\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.8306\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.0733\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.5555\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.5964\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.9782\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.3038\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.9981\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29.3795\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.1377\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.6481\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.7926\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29.8525\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28.6935\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29.1098\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29.3239\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.4636\n",
            "mean,rmse,rmse/mean,bldg: 36.93460755405991 5.594033157267418 0.15145776624483218 Eagle_office_Lamont\n",
            "Example prediction:\n",
            " 0 [59 58 56]\n",
            "Example prediction:\n",
            " 2 [56 55 54]\n",
            "Example prediction:\n",
            " 4 [52 51 50]\n",
            "Example prediction:\n",
            " 6 [48 48 49]\n",
            "Example prediction:\n",
            " 8 [44 45 45]\n",
            "Example prediction:\n",
            " 10 [46 47 47]\n",
            "Example prediction:\n",
            " 12 [41 42 42]\n",
            "Example prediction:\n",
            " 14 [43 44 44]\n",
            "Example prediction:\n",
            " 16 [45 46 46]\n",
            "Example prediction:\n",
            " 18 [46 46 46]\n",
            "Example prediction:\n",
            " 20 [42 43 44]\n",
            "Example prediction:\n",
            " 22 [42 43 43]\n",
            "Building Eagle_health_Athena\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_3 (GRU)                  (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1453 1341 1187]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 349625.8624\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 340315.5353\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 339331.2734\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 332465.7657\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 320190.3347\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 328380.3556\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 321577.2092\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 319382.3011\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 313179.6125\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 309686.0176\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 304396.6474\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 298935.2185\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 291219.6284\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 287106.2576\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 282490.4666\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 278653.6981\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 278304.1889\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 272649.4434\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 270644.7410\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 267258.1088\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 261673.2276\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 254604.8316\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 251525.2290\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 245207.1286\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 243981.6127\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 243199.1205\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 235622.2803\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 236928.4870\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 232714.8558\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 222741.1697\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 226501.9702\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 224597.7259\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 217326.2381\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 210659.9575\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 208037.8965\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 207858.0211\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 202595.9611\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 200962.4201\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 196109.8588\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 194496.1869\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 188740.8429\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 186405.8066\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 185592.0029\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 188928.2466\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 180738.4099\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 176574.1438\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 174710.6686\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 170797.1838\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 170655.4643\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 168095.7907\n",
            "mean,rmse,rmse/mean,bldg: 477.6710835157538 312.6492840871996 0.6545283875800874 Eagle_health_Athena\n",
            "Example prediction:\n",
            " 0 [228 227 227]\n",
            "Example prediction:\n",
            " 2 [228 227 227]\n",
            "Example prediction:\n",
            " 4 [228 227 227]\n",
            "Example prediction:\n",
            " 6 [228 227 227]\n",
            "Example prediction:\n",
            " 8 [228 227 227]\n",
            "Example prediction:\n",
            " 10 [228 227 227]\n",
            "Example prediction:\n",
            " 12 [228 227 227]\n",
            "Example prediction:\n",
            " 14 [228 227 227]\n",
            "Example prediction:\n",
            " 16 [228 227 227]\n",
            "Example prediction:\n",
            " 18 [228 227 227]\n",
            "Example prediction:\n",
            " 20 [228 227 227]\n",
            "Example prediction:\n",
            " 22 [228 227 227]\n",
            "Building Eagle_assembly_Herbert\n",
            "Building Eagle_public_Alvin\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_6 (GRU)                  (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [458 560 422]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 54876.6719\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 53523.2220\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 52187.5898\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 49780.6425\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47470.0899\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 46636.5902\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44470.7930\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 43233.6962\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 41864.3944\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39460.9445\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37710.3613\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37473.7628\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 36023.7948\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34834.8328\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33402.8188\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32048.4742\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31840.8197\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29845.5736\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29272.0578\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28270.5374\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 27556.8043\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25533.7133\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25338.5511\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 23765.3188\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 24767.4161\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 22685.6948\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 21798.8516\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 20867.2689\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 20042.8963\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 19786.5984\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 19257.4758\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 18551.5451\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 17869.7456\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 17066.0208\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16933.5896\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16486.4159\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15779.2309\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15453.4848\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15400.8092\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15249.2074\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14574.6876\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14793.3638\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14033.7784\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13494.1829\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13574.9814\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13222.8773\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13561.0445\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13031.6460\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13561.6566\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12781.1832\n",
            "mean,rmse,rmse/mean,bldg: 182.0635582126762 77.33893678934191 0.42479086725855925 Eagle_public_Alvin\n",
            "Example prediction:\n",
            " 0 [194 193 194]\n",
            "Example prediction:\n",
            " 2 [194 193 194]\n",
            "Example prediction:\n",
            " 4 [194 193 194]\n",
            "Example prediction:\n",
            " 6 [194 193 194]\n",
            "Example prediction:\n",
            " 8 [194 193 194]\n",
            "Example prediction:\n",
            " 10 [194 193 194]\n",
            "Example prediction:\n",
            " 12 [194 193 194]\n",
            "Example prediction:\n",
            " 14 [194 193 194]\n",
            "Example prediction:\n",
            " 16 [194 193 194]\n",
            "Example prediction:\n",
            " 18 [194 193 194]\n",
            "Example prediction:\n",
            " 20 [194 193 194]\n",
            "Example prediction:\n",
            " 22 [194 193 194]\n",
            "Building Eagle_education_Raul\n",
            "Building Eagle_education_Roman\n",
            " Count bad values before pseudofill: 35\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_9 (GRU)                  (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [2555 2589 2437]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1757535.5959\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1723955.3664\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1705904.4768\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1623899.5564\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1634076.0950\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1651052.0809\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1636608.2145\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1617932.9664\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1610792.3677\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1600795.7568\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1582149.6736\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1601210.9250\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1559118.9955\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1570931.4714\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1573118.3314\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1540123.5868\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1541261.8123\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1542011.7532\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1521879.5768\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1493859.5614\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1472336.8691\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1500742.2205\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1486551.2470\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1454563.3355\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1450235.7709\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1431337.9532\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1425454.9955\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1385178.2109\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1450811.3009\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1416903.9573\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1401160.7309\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1381987.7982\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1384388.3577\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1388046.9591\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1354381.8077\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1364779.2100\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1315818.6909\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1347507.6600\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1332692.3336\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1307066.6027\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1302666.5605\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1286471.7509\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1255370.6859\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1271284.7586\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1274537.8455\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1249140.3300\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1228959.7320\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1212386.7105\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1219563.5941\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1182640.0573\n",
            "mean,rmse,rmse/mean,bldg: 1199.3775815637814 1067.7893342359268 0.8902862206609814 Eagle_education_Roman\n",
            "Example prediction:\n",
            " 0 [232 232 234]\n",
            "Example prediction:\n",
            " 2 [232 232 234]\n",
            "Example prediction:\n",
            " 4 [232 232 234]\n",
            "Example prediction:\n",
            " 6 [232 232 234]\n",
            "Example prediction:\n",
            " 8 [232 232 234]\n",
            "Example prediction:\n",
            " 10 [232 232 234]\n",
            "Example prediction:\n",
            " 12 [232 232 234]\n",
            "Example prediction:\n",
            " 14 [232 232 234]\n",
            "Example prediction:\n",
            " 16 [232 232 234]\n",
            "Example prediction:\n",
            " 18 [232 232 234]\n",
            "Example prediction:\n",
            " 20 [232 232 234]\n",
            "Example prediction:\n",
            " 22 [232 232 234]\n",
            "Building Eagle_office_Mandi\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_12 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [64 63 63]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1466.8783\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1078.9622\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 845.2242\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 679.7887\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 545.1360\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 444.7100\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 386.2607\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 336.2268\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 304.7587\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 287.0975\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 273.2939\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 261.8294\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 265.9014\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 257.1472\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 262.1824\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 263.5522\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 262.3048\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 264.8443\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 259.9607\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 147.7474\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 104.1027\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 80.5750\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 63.8273\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 54.0595\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47.8124\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 43.0969\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 38.6369\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.8022\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 36.3459\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.4247\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 36.2638\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 36.3175\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.4214\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.2171\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.6427\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.1260\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.7026\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 32.6363\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.1379\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.4300\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.8426\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.9245\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.8297\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.3477\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.7463\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.0876\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.2737\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.6406\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.0212\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.1092\n",
            "mean,rmse,rmse/mean,bldg: 35.89274527609939 6.024878307901291 0.1678578292508931 Eagle_office_Mandi\n",
            "Example prediction:\n",
            " 0 [59 58 58]\n",
            "Example prediction:\n",
            " 2 [43 44 43]\n",
            "Example prediction:\n",
            " 4 [30 32 31]\n",
            "Example prediction:\n",
            " 6 [40 42 41]\n",
            "Example prediction:\n",
            " 8 [51 52 51]\n",
            "Example prediction:\n",
            " 10 [39 41 40]\n",
            "Example prediction:\n",
            " 12 [49 49 49]\n",
            "Example prediction:\n",
            " 14 [46 47 46]\n",
            "Example prediction:\n",
            " 16 [37 39 38]\n",
            "Example prediction:\n",
            " 18 [54 54 53]\n",
            "Example prediction:\n",
            " 20 [55 55 54]\n",
            "Example prediction:\n",
            " 22 [57 57 56]\n",
            "Building Eagle_education_Jewell\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_15 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_16 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_17 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [216 223 207]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 4219.7390\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3978.1404\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3551.8230\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3516.0997\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3197.6943\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2998.5749\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2947.6139\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2758.8889\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2757.3557\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2539.4113\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2389.1829\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2266.7266\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2168.1636\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2000.3310\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2038.7530\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1804.8564\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1839.0974\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1658.3890\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1562.3691\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1569.4960\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1441.0427\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1392.7983\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1348.0971\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1294.5615\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1267.0432\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1179.4521\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1100.0538\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1088.7241\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1079.6860\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1017.2862\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1006.6735\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 898.9177\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 906.9453\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 880.7535\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 874.3839\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 820.3289\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 820.3866\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 823.2126\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 769.0293\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 757.8162\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 754.1075\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 702.7493\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 679.3605\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 666.1476\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 681.9623\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 620.5727\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 624.4625\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 610.9091\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 634.4275\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 587.4040\n",
            "mean,rmse,rmse/mean,bldg: 15.763918737885179 10.780157023995754 0.6838500758119218 Eagle_education_Jewell\n",
            "Example prediction:\n",
            " 0 [97 96 95]\n",
            "Example prediction:\n",
            " 2 [69 70 70]\n",
            "Example prediction:\n",
            " 4 [13 14 15]\n",
            "Example prediction:\n",
            " 6 [18 18 19]\n",
            "Example prediction:\n",
            " 8 [15 16 18]\n",
            "Example prediction:\n",
            " 10 [22 23 24]\n",
            "Example prediction:\n",
            " 12 [21 22 24]\n",
            "Example prediction:\n",
            " 14 [22 23 24]\n",
            "Example prediction:\n",
            " 16 [34 36 36]\n",
            "Example prediction:\n",
            " 18 [34 36 36]\n",
            "Example prediction:\n",
            " 20 [27 29 29]\n",
            "Example prediction:\n",
            " 22 [27 28 29]\n",
            "Building Eagle_office_Henriette\n",
            " Count bad values before pseudofill: 162\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_18 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_19 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_20 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 0.0139\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6.4966e-06\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2.2408e-06\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.4253e-06\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.0108e-06\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.8861e-07\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.4464e-07\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 5.3992e-07\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 4.8376e-07\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2681e-07\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6.4604e-07\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.0682e-06\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.6406e-07\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.6629e-07\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.8830e-07\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2496e-07\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.2718e-07\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.8971e-07\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.6017e-06\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.5956e-07\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.1854e-07\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.3903e-06\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.4307e-07\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.4219e-06\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8.0198e-07\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.2211e-07\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.7797e-07\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8.1474e-07\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.1458e-07\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9.3164e-07\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.1342e-06\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.9769e-07\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.0362e-06\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6.5547e-07\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6.3732e-07\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8.8404e-07\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.1969e-07\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9.7318e-07\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.0300e-07\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.6703e-06\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.8714e-07\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.7234e-07\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.6999e-07\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.6347e-07\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.2677e-06\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.4003e-07\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.2467e-07\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.2990e-07\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9270e-07\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3010e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean,rmse,rmse/mean,bldg: 0.0 0.0007760865802264659 inf Eagle_office_Henriette\n",
            "Example prediction:\n",
            " 0 [0 0 0]\n",
            "Example prediction:\n",
            " 2 [0 0 0]\n",
            "Example prediction:\n",
            " 4 [0 0 0]\n",
            "Example prediction:\n",
            " 6 [0 0 0]\n",
            "Example prediction:\n",
            " 8 [0 0 0]\n",
            "Example prediction:\n",
            " 10 [0 0 0]\n",
            "Example prediction:\n",
            " 12 [0 0 0]\n",
            "Example prediction:\n",
            " 14 [0 0 0]\n",
            "Example prediction:\n",
            " 16 [0 0 0]\n",
            "Example prediction:\n",
            " 18 [0 0 0]\n",
            "Example prediction:\n",
            " 20 [0 0 0]\n",
            "Example prediction:\n",
            " 22 [0 0 0]\n",
            "Building Eagle_health_Reba\n",
            " Count bad values before pseudofill: 36\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_21 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_22 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_23 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1722 1765 1758]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1447041.2700\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1413451.9377\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1461735.4032\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1404382.7323\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1399936.9555\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1410602.2523\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1401415.3982\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1394640.1914\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1364100.3136\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1351272.9914\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1344612.6968\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1341686.2464\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1316298.3218\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1316347.6745\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1280076.4389\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1315362.5168\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1288577.8609\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1270441.4002\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1285982.6427\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1242506.5909\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1255767.4220\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1236158.8236\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1255196.2436\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1216412.5509\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1194895.7423\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1209742.7105\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1198838.4905\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1175037.1950\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1164786.3802\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1158816.2616\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1166880.2536\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1136203.6789\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1117263.3768\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1130558.2307\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1119866.7691\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1098358.5039\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1094743.9898\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1105340.5768\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1085165.6527\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1071432.3405\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1047577.8875\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1055759.1255\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1067707.9055\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1035641.2123\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1033096.9064\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1037893.4745\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1032941.9864\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1017473.6509\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1028051.1675\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1012761.7327\n",
            "mean,rmse,rmse/mean,bldg: 1084.4328846508208 922.9472763797248 0.8510875033791574 Eagle_health_Reba\n",
            "Example prediction:\n",
            " 0 [232 231 232]\n",
            "Example prediction:\n",
            " 2 [232 231 232]\n",
            "Example prediction:\n",
            " 4 [232 231 232]\n",
            "Example prediction:\n",
            " 6 [232 231 232]\n",
            "Example prediction:\n",
            " 8 [232 231 232]\n",
            "Example prediction:\n",
            " 10 [232 231 232]\n",
            "Example prediction:\n",
            " 12 [232 231 232]\n",
            "Example prediction:\n",
            " 14 [232 231 232]\n",
            "Example prediction:\n",
            " 16 [232 231 232]\n",
            "Example prediction:\n",
            " 18 [232 231 232]\n",
            "Example prediction:\n",
            " 20 [232 231 232]\n",
            "Example prediction:\n",
            " 22 [232 231 232]\n",
            "Building Eagle_lodging_Edgardo\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_24 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_25 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_26 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [114 203 174]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 9489.6261\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8649.5482\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8166.4124\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7322.6677\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6823.4847\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6460.4412\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5928.8799\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5653.2120\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5435.6683\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4847.0863\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4748.2566\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4375.8719\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4419.8400\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4245.6868\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3846.6871\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3821.3045\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3764.9242\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3623.1388\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3500.6913\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3484.8764\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3532.8409\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3496.4127\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3447.4565\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3522.4314\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3317.2535\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3295.6381\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3454.2316\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2940.7455\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2703.2082\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2598.3283\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2386.1227\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2275.5843\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2170.6148\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2196.6217\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2128.3459\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2086.3143\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2073.2883\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2027.6363\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1926.4636\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1865.1901\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1852.4611\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1891.1341\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1881.5531\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1818.0097\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1754.7151\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1689.9318\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1754.0764\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1709.0015\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1713.1297\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1724.5065\n",
            "mean,rmse,rmse/mean,bldg: 81.9636656538589 44.36724063018337 0.5413037627861942 Eagle_lodging_Edgardo\n",
            "Example prediction:\n",
            " 0 [131 130 129]\n",
            "Example prediction:\n",
            " 2 [143 142 141]\n",
            "Example prediction:\n",
            " 4 [143 142 141]\n",
            "Example prediction:\n",
            " 6 [100  99  99]\n",
            "Example prediction:\n",
            " 8 [107 107 106]\n",
            "Example prediction:\n",
            " 10 [144 143 142]\n",
            "Example prediction:\n",
            " 12 [123 122 122]\n",
            "Example prediction:\n",
            " 14 [144 143 142]\n",
            "Example prediction:\n",
            " 16 [144 143 142]\n",
            "Example prediction:\n",
            " 18 [144 143 142]\n",
            "Example prediction:\n",
            " 20 [144 143 142]\n",
            "Example prediction:\n",
            " 22 [144 143 142]\n",
            "Building Eagle_education_Cassie\n",
            "Building Eagle_education_Peter\n",
            " Count bad values before pseudofill: 34\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_27 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_28 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_29 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [7242 7938 8046]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 12869818.8364\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12971467.1855\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13191737.6109\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12884678.7636\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12733575.6909\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13026557.5709\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12937207.4218\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12964666.1818\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12838655.5018\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12530186.0327\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12846131.1091\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12731007.8182\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12496402.1200\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12532550.1345\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12450041.8036\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12454834.9964\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12670262.2509\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12551466.6618\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12439874.4582\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12477469.0909\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12387666.3891\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12338764.4545\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12252856.8982\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12358030.3418\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12214943.7164\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12457477.7055\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12419303.2545\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11960973.8655\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11922469.4691\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12171030.7964\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11979317.5891\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11879853.1164\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11961785.6000\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12224707.5745\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11972187.3091\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11972679.4364\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11813028.3382\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11928955.7527\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11739719.1091\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12099369.0291\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11894020.6000\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11726506.0436\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11663521.0473\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11738554.3709\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11786505.3855\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11784522.3527\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11730638.7855\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11473470.9527\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11881304.4945\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11614970.7782\n",
            "mean,rmse,rmse/mean,bldg: 3154.8298985018228 3032.625564418702 0.961264366696552 Eagle_education_Peter\n",
            "Example prediction:\n",
            " 0 [233 235 234]\n",
            "Example prediction:\n",
            " 2 [233 235 234]\n",
            "Example prediction:\n",
            " 4 [233 235 234]\n",
            "Example prediction:\n",
            " 6 [233 235 234]\n",
            "Example prediction:\n",
            " 8 [233 235 234]\n",
            "Example prediction:\n",
            " 10 [233 235 234]\n",
            "Example prediction:\n",
            " 12 [233 235 234]\n",
            "Example prediction:\n",
            " 14 [233 235 234]\n",
            "Example prediction:\n",
            " 16 [233 235 234]\n",
            "Example prediction:\n",
            " 18 [233 235 234]\n",
            "Example prediction:\n",
            " 20 [233 235 234]\n",
            "Example prediction:\n",
            " 22 [233 235 234]\n",
            "Building Eagle_health_Gregoria\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_32 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 662283.5166\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 647580.3884\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 662559.3032\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 626182.7173\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 675133.4107\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 628945.9114\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 615572.3555\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 614662.1576\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 605844.2641\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 627839.0118\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 591627.4477\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 610162.3050\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 619879.2500\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 598604.2610\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 583436.9298\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 582965.3416\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 589348.9655\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 583252.1373\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 584236.3701\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 565937.8990\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 585719.5516\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 558801.3692\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 542345.7995\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 578514.3648\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 538696.0697\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 568835.7059\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 548048.9819\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 528293.8643\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 539086.3206\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 536642.8970\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 523033.3098\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 515436.2716\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 526451.7518\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 505635.9882\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 537081.4858\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 525298.2598\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 525466.6589\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 514102.2372\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 504815.9688\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 495888.8822\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 510101.2773\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 479541.1130\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 482796.1952\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 474938.8681\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 492560.2632\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 483598.8339\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 488569.9012\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 466747.1919\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 475599.0115\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 447162.4049\n",
            "mean,rmse,rmse/mean,bldg: 659.5054129061737 757.3750917789189 1.1483985983397362 Eagle_health_Gregoria\n",
            "Example prediction:\n",
            " 0 [226 224 225]\n",
            "Example prediction:\n",
            " 2 [226 224 225]\n",
            "Example prediction:\n",
            " 4 [226 224 225]\n",
            "Example prediction:\n",
            " 6 [226 224 225]\n",
            "Example prediction:\n",
            " 8 [226 224 225]\n",
            "Example prediction:\n",
            " 10 [226 224 225]\n",
            "Example prediction:\n",
            " 12 [226 224 225]\n",
            "Example prediction:\n",
            " 14 [226 224 225]\n",
            "Example prediction:\n",
            " 16 [226 224 225]\n",
            "Example prediction:\n",
            " 18 [226 224 225]\n",
            "Example prediction:\n",
            " 20 [226 224 225]\n",
            "Example prediction:\n",
            " 22 [226 224 225]\n",
            "Building Eagle_lodging_Dawn\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_33 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_34 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_35 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [298 305 281]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 13957.2540\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12493.9441\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11677.6034\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11004.7598\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 10223.4885\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9611.4153\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8947.6702\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8236.8207\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7662.8657\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7446.8693\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6719.4285\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6423.4541\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6106.9426\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5691.4084\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5307.7322\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5147.9350\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4658.3869\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4440.1078\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4452.9050\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4215.7850\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4086.1898\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4004.6579\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3809.0588\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3948.1663\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3745.1031\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3593.3928\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3472.0570\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3544.9760\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3432.3706\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3550.2890\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3553.8692\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3496.5300\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3486.2567\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3488.0971\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3091.6223\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2648.8227\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2582.4346\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2515.3281\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2312.8253\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2252.5687\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2163.5705\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2152.4057\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2068.4474\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2039.0236\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1869.9426\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1860.5759\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1799.1850\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1782.6006\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1751.8989\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1686.4236\n",
            "mean,rmse,rmse/mean,bldg: 92.8091523125402 39.78297183767796 0.4286535416647972 Eagle_lodging_Dawn\n",
            "Example prediction:\n",
            " 0 [148 148 148]\n",
            "Example prediction:\n",
            " 2 [146 145 146]\n",
            "Example prediction:\n",
            " 4 [116 115 116]\n",
            "Example prediction:\n",
            " 6 [118 117 117]\n",
            "Example prediction:\n",
            " 8 [108 107 107]\n",
            "Example prediction:\n",
            " 10 [110 109 109]\n",
            "Example prediction:\n",
            " 12 [124 123 123]\n",
            "Example prediction:\n",
            " 14 [156 157 157]\n",
            "Example prediction:\n",
            " 16 [156 157 157]\n",
            "Example prediction:\n",
            " 18 [156 157 157]\n",
            "Example prediction:\n",
            " 20 [156 157 157]\n",
            "Example prediction:\n",
            " 22 [156 157 157]\n",
            "Building Eagle_office_Nereida\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_36 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_37 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_38 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [435 433 535]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 72454.9745\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 69384.7797\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 67229.5434\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 65746.6136\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 62963.7338\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 61093.3497\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 59464.4424\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 57302.1760\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 55930.9877\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 54279.5450\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 51960.2055\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 50716.5366\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 48601.7596\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 45995.1799\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44349.2182\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44479.2975\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 42156.9960\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 40671.0002\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39179.2891\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37440.0354\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 36598.3449\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 35934.0471\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34408.9320\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33162.5157\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31500.9220\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30839.7952\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29850.5469\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28603.4388\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28088.8952\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 26237.3538\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25572.3968\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 24923.0727\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 23965.0163\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 22970.6158\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 22420.9728\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 21335.6300\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 20626.1941\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 18695.4694\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 18058.5745\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16691.9436\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16070.7638\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15260.9815\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14889.0843\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13936.7274\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13789.3284\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13283.7560\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12666.9615\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12567.4448\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12140.8841\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11675.3441\n",
            "mean,rmse,rmse/mean,bldg: 273.01729748007574 121.12960161067342 0.4436700631377146 Eagle_office_Nereida\n",
            "Example prediction:\n",
            " 0 [211 210 208]\n",
            "Example prediction:\n",
            " 2 [211 210 208]\n",
            "Example prediction:\n",
            " 4 [211 210 208]\n",
            "Example prediction:\n",
            " 6 [211 210 208]\n",
            "Example prediction:\n",
            " 8 [211 210 208]\n",
            "Example prediction:\n",
            " 10 [211 210 208]\n",
            "Example prediction:\n",
            " 12 [211 210 208]\n",
            "Example prediction:\n",
            " 14 [211 210 208]\n",
            "Example prediction:\n",
            " 16 [211 210 208]\n",
            "Example prediction:\n",
            " 18 [211 210 208]\n",
            "Example prediction:\n",
            " 20 [211 210 208]\n",
            "Example prediction:\n",
            " 22 [211 210 208]\n",
            "Building Eagle_lodging_Tressa\n",
            "Building Eagle_education_Eileen\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_39 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_40 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_41 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [103  95  64]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 2428.1978\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1985.5781\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1712.7148\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1438.0069\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1241.1900\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1059.4281\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1003.8270\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 897.6340\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 796.1550\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 784.0579\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 744.8906\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 720.2788\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 692.9929\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 722.2269\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 705.7430\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 703.8184\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 704.5107\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 694.3325\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 706.1537\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 683.4859\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 659.5757\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 572.0450\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 516.2776\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 499.1326\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 456.7808\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 413.9380\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 419.0210\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 405.9763\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 395.7316\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 387.9784\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 380.5609\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 366.3187\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 371.9592\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 376.0553\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 364.1173\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 349.1620\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 338.2049\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 339.0245\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 327.9840\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 328.8020\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 330.8925\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 321.2079\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 320.4777\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 312.5163\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 312.6732\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 306.9666\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 299.3396\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 309.3845\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 297.2345\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 289.8019\n",
            "mean,rmse,rmse/mean,bldg: 46.462781809371094 15.971448079453124 0.343747133888394 Eagle_education_Eileen\n",
            "Example prediction:\n",
            " 0 [54 52 43]\n",
            "Example prediction:\n",
            " 2 [52 50 35]\n",
            "Example prediction:\n",
            " 4 [43 40 31]\n",
            "Example prediction:\n",
            " 6 [45 43 39]\n",
            "Example prediction:\n",
            " 8 [36 35 33]\n",
            "Example prediction:\n",
            " 10 [39 39 41]\n",
            "Example prediction:\n",
            " 12 [33 34 45]\n",
            "Example prediction:\n",
            " 14 [33 38 57]\n",
            "Example prediction:\n",
            " 16 [38 45 61]\n",
            "Example prediction:\n",
            " 18 [43 46 48]\n",
            "Example prediction:\n",
            " 20 [38 41 41]\n",
            "Example prediction:\n",
            " 22 [38 41 40]\n",
            "Building Eagle_education_Wesley\n",
            " Count bad values before pseudofill: 112\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_42 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_43 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_44 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 0.0033\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.3530e-04\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.5622e-04\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2785e-04\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.4746e-04\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.8297e-04\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.3270e-04\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.1767e-04\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2931e-04\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2993e-04\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2753e-04\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.3448e-04\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.0696e-04\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.1571e-04\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2933e-04\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2041e-04\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2903e-04\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2035e-04\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.0892e-04\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.1187e-04\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9908e-04\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9956e-04\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.2044e-04\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9385e-04\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4.9942e-04\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.0285e-04\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9023e-04\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.9998e-04\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.7387e-04\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.8409e-04\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.7608e-04\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.6514e-04\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.7628e-04\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.5752e-04\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.5840e-04\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.6970e-04\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.4549e-04\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.4701e-04\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.4429e-04\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.5068e-04\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.5071e-04\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3471e-04\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.4325e-04\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3602e-04\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.2935e-04\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3770e-04\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.2802e-04\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4.5183e-04\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3645e-04\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.3234e-04\n",
            "mean,rmse,rmse/mean,bldg: 0.10558919611442527 0.026200373198322628 0.24813498125253 Eagle_education_Wesley\n",
            "Example prediction:\n",
            " 0 [0 0 0]\n",
            "Example prediction:\n",
            " 2 [0 0 0]\n",
            "Example prediction:\n",
            " 4 [0 0 0]\n",
            "Example prediction:\n",
            " 6 [0 0 0]\n",
            "Example prediction:\n",
            " 8 [0 0 0]\n",
            "Example prediction:\n",
            " 10 [0 0 0]\n",
            "Example prediction:\n",
            " 12 [0 0 0]\n",
            "Example prediction:\n",
            " 14 [0 0 0]\n",
            "Example prediction:\n",
            " 16 [0 0 0]\n",
            "Example prediction:\n",
            " 18 [0 0 0]\n",
            "Example prediction:\n",
            " 20 [0 0 0]\n",
            "Example prediction:\n",
            " 22 [0 0 0]\n",
            "Building Eagle_health_Vincenza\n",
            " Count bad values before pseudofill: 75\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_45 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_46 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_47 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [224 249 138]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 17068.4617\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15845.2222\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14784.7840\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13835.3712\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12817.7984\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12243.5989\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11303.1872\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 10578.6330\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 10009.3734\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9292.5697\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8672.0818\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8082.0442\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7591.2239\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6990.7504\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6686.4577\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 6167.1114\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5913.0556\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5622.6757\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5234.2572\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4912.0719\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4777.9222\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4476.1122\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4326.3411\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4181.2634\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4047.8988\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3856.0631\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3846.1423\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3670.2106\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3695.6213\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3559.7125\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3509.8468\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3505.9526\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3486.1977\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3343.9981\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3476.2754\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3437.7763\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3386.4401\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3460.4691\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3461.7299\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3412.2447\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3477.2108\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3451.5701\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2956.1175\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2651.6455\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2437.9237\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2394.6108\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2378.4251\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2300.2331\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2221.4885\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2099.5324\n",
            "mean,rmse,rmse/mean,bldg: 122.36347174423398 46.1254241714261 0.3769541964928731 Eagle_health_Vincenza\n",
            "Example prediction:\n",
            " 0 [145 148 146]\n",
            "Example prediction:\n",
            " 2 [144 148 146]\n",
            "Example prediction:\n",
            " 4 [141 144 143]\n",
            "Example prediction:\n",
            " 6 [126 127 127]\n",
            "Example prediction:\n",
            " 8 [128 129 129]\n",
            "Example prediction:\n",
            " 10 [125 125 125]\n",
            "Example prediction:\n",
            " 12 [121 122 122]\n",
            "Example prediction:\n",
            " 14 [145 149 147]\n",
            "Example prediction:\n",
            " 16 [145 149 147]\n",
            "Example prediction:\n",
            " 18 [145 149 147]\n",
            "Example prediction:\n",
            " 20 [145 149 147]\n",
            "Example prediction:\n",
            " 22 [145 149 147]\n",
            "Building Eagle_office_Dallas\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_48 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_49 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_50 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [215 113 154]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 4261.9578\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3907.3598\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3506.9314\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3733.2820\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3361.5969\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3243.6360\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3347.6902\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3046.1199\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3146.6767\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3077.4550\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2993.5420\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2844.4421\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2985.9996\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2927.5426\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2397.2680\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2653.8310\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2448.6110\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2213.2899\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2231.6742\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1966.6353\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2036.1492\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2038.0543\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1956.8172\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1817.4276\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1852.2520\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1869.8226\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1876.1007\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1931.5968\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1881.8745\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1809.4628\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1836.5487\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1675.8886\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1774.5939\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1712.8080\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1845.8127\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1717.4964\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1853.4169\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2003.3014\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1790.3672\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1838.2816\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1876.3757\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1750.3460\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1811.9165\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1639.9600\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1670.6383\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1979.7750\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1698.6220\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1760.0379\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1919.1553\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1719.4525\n",
            "mean,rmse,rmse/mean,bldg: 56.5030097936379 48.25530467477229 0.8540306941349117 Eagle_office_Dallas\n",
            "Example prediction:\n",
            " 0 [68 66 65]\n",
            "Example prediction:\n",
            " 2 [73 70 69]\n",
            "Example prediction:\n",
            " 4 [71 68 67]\n",
            "Example prediction:\n",
            " 6 [56 53 53]\n",
            "Example prediction:\n",
            " 8 [53 50 50]\n",
            "Example prediction:\n",
            " 10 [45 41 42]\n",
            "Example prediction:\n",
            " 12 [12 11 13]\n",
            "Example prediction:\n",
            " 14 [104 103 101]\n",
            "Example prediction:\n",
            " 16 [83 82 82]\n",
            "Example prediction:\n",
            " 18 [101 100  98]\n",
            "Example prediction:\n",
            " 20 [88 86 84]\n",
            "Example prediction:\n",
            " 22 [54 53 54]\n",
            "Building Eagle_education_Shante\n",
            " Count bad values before pseudofill: 23\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_51 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_52 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_53 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 165256.6807\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 185558.4752\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 176933.5307\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 164918.1146\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 172520.6188\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 171932.7177\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 161183.5989\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 164973.0849\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 169733.9983\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 178228.5963\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 163559.3778\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 173862.3545\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 182655.5469\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 162117.9418\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 162538.7649\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 160304.3063\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 155083.4792\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 185163.4643\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 160198.5168\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 172643.8591\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 156406.9747\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 156365.8882\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 159356.5261\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 152550.4308\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 153377.3227\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 161037.1849\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 161978.3945\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 155235.4004\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 158761.4640\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 149087.9067\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 157357.5933\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 142414.7543\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 151600.5630\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 159173.1709\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 144503.0912\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 154776.2578\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 143771.9621\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 158755.1565\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 161741.3786\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 171003.6330\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 149644.4738\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 162933.0994\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 156328.5926\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 153423.3682\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 173260.7635\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 154016.9152\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 155558.1979\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 156216.5034\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 152610.6539\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 153114.5808\n",
            "mean,rmse,rmse/mean,bldg: 1003.9941709339338 1856.543338249857 1.849157487162367 Eagle_education_Shante\n",
            "Example prediction:\n",
            " 0 [163 161 162]\n",
            "Example prediction:\n",
            " 2 [163 161 162]\n",
            "Example prediction:\n",
            " 4 [163 161 162]\n",
            "Example prediction:\n",
            " 6 [163 161 162]\n",
            "Example prediction:\n",
            " 8 [163 161 162]\n",
            "Example prediction:\n",
            " 10 [163 161 162]\n",
            "Example prediction:\n",
            " 12 [163 161 162]\n",
            "Example prediction:\n",
            " 14 [163 161 162]\n",
            "Example prediction:\n",
            " 16 [163 161 162]\n",
            "Example prediction:\n",
            " 18 [163 161 162]\n",
            "Example prediction:\n",
            " 20 [163 161 162]\n",
            "Example prediction:\n",
            " 22 [163 161 162]\n",
            "Building Eagle_office_Chauncey\n",
            " Count bad values before pseudofill: 116\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_54 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_55 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_56 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1623 1735 1718]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1087422.2223\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1078713.7157\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1062734.7814\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1064450.1750\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1063545.3145\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1051730.2573\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1033871.0220\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1025115.4391\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1029748.2109\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1008094.9605\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1004514.6343\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 986758.0395\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 989374.6607\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 986373.0020\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 986616.4630\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 966446.5068\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 951188.5880\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 950618.2120\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 934717.9498\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 937906.5907\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 922726.3939\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 920764.2557\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 903107.2270\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 891628.9689\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 888119.1173\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 878058.2409\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 877523.1130\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 862274.8543\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 856131.1607\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 852701.0011\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 835173.5157\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 839640.2191\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 827228.5984\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 822013.3730\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 808761.6543\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 800400.1664\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 795672.9543\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 786721.5309\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 789259.8850\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 771528.7925\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 762897.9395\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 755631.4766\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 753524.8386\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 743003.2825\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 740920.2984\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 741277.7207\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 734529.8575\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 720391.1102\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 712374.1182\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 706518.0825\n",
            "mean,rmse,rmse/mean,bldg: 1037.6368908901366 932.8230336950554 0.8989879233137456 Eagle_office_Chauncey\n",
            "Example prediction:\n",
            " 0 [229 234 231]\n",
            "Example prediction:\n",
            " 2 [229 234 231]\n",
            "Example prediction:\n",
            " 4 [229 234 231]\n",
            "Example prediction:\n",
            " 6 [229 234 231]\n",
            "Example prediction:\n",
            " 8 [229 234 231]\n",
            "Example prediction:\n",
            " 10 [229 234 231]\n",
            "Example prediction:\n",
            " 12 [229 234 231]\n",
            "Example prediction:\n",
            " 14 [229 234 231]\n",
            "Example prediction:\n",
            " 16 [229 234 231]\n",
            "Example prediction:\n",
            " 18 [229 234 231]\n",
            "Example prediction:\n",
            " 20 [229 234 231]\n",
            "Example prediction:\n",
            " 22 [229 234 231]\n",
            "Building Eagle_office_Phyllis\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_57 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_58 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_59 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [156 154 154]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 9108.8446\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8165.4881\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7381.2131\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6819.7718\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6096.7254\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5641.3939\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5001.9818\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4688.5938\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4241.2691\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3845.9172\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 3604.1788\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3221.6405\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2935.4287\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2707.9830\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2458.6081\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2266.9664\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2124.1281\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2027.4705\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1916.7786\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1817.6149\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1786.6524\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1711.0366\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1643.0115\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1611.3983\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1564.3304\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1595.8772\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1528.1129\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1571.5624\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1555.0321\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1598.6905\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1518.2048\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1535.1707\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1238.6100\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 834.4352\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 647.1045\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 568.6703\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 517.1663\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 454.2285\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 405.6500\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 372.8069\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 354.9586\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 316.9882\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 302.1497\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 292.1920\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 257.7649\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 250.8608\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 226.4399\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 227.2441\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 218.1223\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 219.0982\n",
            "mean,rmse,rmse/mean,bldg: 87.20950227834119 15.863817675503181 0.18190469227621106 Eagle_office_Phyllis\n",
            "Example prediction:\n",
            " 0 [140 140 139]\n",
            "Example prediction:\n",
            " 2 [140 140 139]\n",
            "Example prediction:\n",
            " 4 [138 138 137]\n",
            "Example prediction:\n",
            " 6 [136 136 135]\n",
            "Example prediction:\n",
            " 8 [134 133 133]\n",
            "Example prediction:\n",
            " 10 [126 125 125]\n",
            "Example prediction:\n",
            " 12 [132 131 131]\n",
            "Example prediction:\n",
            " 14 [128 127 127]\n",
            "Example prediction:\n",
            " 16 [123 123 123]\n",
            "Example prediction:\n",
            " 18 [129 128 128]\n",
            "Example prediction:\n",
            " 20 [131 131 131]\n",
            "Example prediction:\n",
            " 22 [131 130 130]\n",
            "Building Eagle_office_Freida\n",
            " Count bad values before pseudofill: 63\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_60 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_61 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_62 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [209 417 223]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 19626.4973\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 18650.3635\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17410.3177\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16652.6278\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15855.7018\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14789.7126\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14010.8810\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13917.9443\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13026.0983\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12348.9207\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11234.8840\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10681.4918\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 10124.9032\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9759.1008\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 9281.9679\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9030.9961\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8345.9585\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 8096.8771\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7904.1440\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 7138.9969\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7079.2643\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6823.7107\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6731.2955\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6669.9562\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6153.8643\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6156.6231\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6118.0247\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5894.2334\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5963.1021\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5854.8708\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5726.1167\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5548.9040\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5726.7837\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5664.7317\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5644.8514\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5590.5160\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5477.3216\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5766.8109\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5658.7975\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5564.4473\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5627.2141\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5581.6078\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 5661.1696\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5547.1897\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5646.2677\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5616.0851\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5708.1099\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5611.3754\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5592.5848\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5579.6948\n",
            "mean,rmse,rmse/mean,bldg: 101.557715031556 54.35013208002159 0.5351649755327197 Eagle_office_Freida\n",
            "Example prediction:\n",
            " 0 [125 125 125]\n",
            "Example prediction:\n",
            " 2 [125 125 125]\n",
            "Example prediction:\n",
            " 4 [124 124 124]\n",
            "Example prediction:\n",
            " 6 [64 63 64]\n",
            "Example prediction:\n",
            " 8 [64 63 64]\n",
            "Example prediction:\n",
            " 10 [64 63 64]\n",
            "Example prediction:\n",
            " 12 [64 63 64]\n",
            "Example prediction:\n",
            " 14 [64 63 64]\n",
            "Example prediction:\n",
            " 16 [64 63 64]\n",
            "Example prediction:\n",
            " 18 [64 63 64]\n",
            "Example prediction:\n",
            " 20 [64 63 64]\n",
            "Example prediction:\n",
            " 22 [64 63 64]\n",
            "Building Eagle_office_Francis\n",
            " Count bad values before pseudofill: 20\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_63 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_64 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_65 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [378 396 451]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 88209.1646\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 83304.7414\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 82031.2753\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 79280.3403\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 77050.9264\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 73871.3161\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 71732.1421\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 70867.8410\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 67341.6620\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 65601.2508\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 63844.0153\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 62238.1690\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 60167.4119\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 58222.0061\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 56549.7522\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 54393.0304\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 52176.2031\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 51337.1734\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48929.2831\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 47016.9286\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 45237.0083\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44306.0583\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 41414.4347\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 39985.7396\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 39598.4625\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37823.9913\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 35629.4495\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 34788.4604\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32908.0588\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 31706.7283\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30321.9190\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 29291.0059\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28622.5744\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27504.8299\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 26307.5183\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25665.9790\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 24214.4165\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 23079.2146\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 22003.8986\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20194.2392\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20271.4198\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19573.5612\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 18950.4410\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17718.7833\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 16695.3499\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16484.9405\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15449.6420\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14784.0614\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14603.9254\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13790.1738\n",
            "mean,rmse,rmse/mean,bldg: 336.48649201094844 204.2231123767318 0.6069281151710746 Eagle_office_Francis\n",
            "Example prediction:\n",
            " 0 [214 215 214]\n",
            "Example prediction:\n",
            " 2 [214 215 214]\n",
            "Example prediction:\n",
            " 4 [214 215 214]\n",
            "Example prediction:\n",
            " 6 [214 215 214]\n",
            "Example prediction:\n",
            " 8 [214 215 214]\n",
            "Example prediction:\n",
            " 10 [214 215 214]\n",
            "Example prediction:\n",
            " 12 [214 215 214]\n",
            "Example prediction:\n",
            " 14 [214 215 214]\n",
            "Example prediction:\n",
            " 16 [214 215 214]\n",
            "Example prediction:\n",
            " 18 [214 215 214]\n",
            "Example prediction:\n",
            " 20 [214 215 214]\n",
            "Example prediction:\n",
            " 22 [214 215 214]\n",
            "Building Eagle_office_Sheree\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_66 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_67 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_68 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [ 98 165 103]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 4713.4538\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 4126.9948\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3855.3718\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3451.9465\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 3085.8260\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2834.1378\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2682.0210\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2475.6767\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2327.6769\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2185.1961\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2077.3213\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 2099.5124\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2022.9773\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1940.7136\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1982.3633\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1923.5200\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1904.1295\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1915.8575\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1941.7379\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1910.4722\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1932.6409\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1954.1654\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1898.9636\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1914.6606\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1680.8272\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1532.7734\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1373.6197\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1349.4364\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1313.9553\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1283.8635\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1261.1494\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1205.1699\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1209.1819\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1170.8942\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1155.6928\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1132.6515\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1125.5759\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1118.1325\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1114.7214\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1101.8438\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1107.9622\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1107.6542\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1083.3106\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1074.7241\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1045.8099\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1074.3145\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1083.9729\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1072.7044\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 1073.7602\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1055.2045\n",
            "mean,rmse,rmse/mean,bldg: 62.02257521757287 40.17877339923466 0.6478088544096892 Eagle_office_Sheree\n",
            "Example prediction:\n",
            " 0 [88 92 91]\n",
            "Example prediction:\n",
            " 2 [100 103 102]\n",
            "Example prediction:\n",
            " 4 [ 97 100  98]\n",
            "Example prediction:\n",
            " 6 [100 104 103]\n",
            "Example prediction:\n",
            " 8 [97 99 98]\n",
            "Example prediction:\n",
            " 10 [71 60 62]\n",
            "Example prediction:\n",
            " 12 [75 66 68]\n",
            "Example prediction:\n",
            " 14 [100 104 103]\n",
            "Example prediction:\n",
            " 16 [100 104 103]\n",
            "Example prediction:\n",
            " 18 [100 104 103]\n",
            "Example prediction:\n",
            " 20 [100 104 103]\n",
            "Example prediction:\n",
            " 22 [100 104 103]\n",
            "Building Eagle_education_Sherrill\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_69 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_70 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_71 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [4128 4351 4503]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 5507214.7182\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5512562.4873\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 5444516.3164\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5403029.4345\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5479233.1309\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5369550.8273\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5460525.8109\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5418368.1255\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5379463.5182\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5240380.5091\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5290132.5927\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5300502.0400\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5236142.8845\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5250846.4855\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5377018.2800\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5213438.1109\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5244370.2073\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5252054.6200\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5114825.9291\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5124000.4927\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5092892.1473\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5110494.1764\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5075499.9436\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5088075.8364\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5054241.3036\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5080612.1291\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5075295.8727\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5027307.4218\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4992920.0800\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5007016.7364\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5038360.1600\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4963041.4400\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 4996223.0945\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4917049.9418\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4800230.4236\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4756705.3927\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4809332.3673\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4866729.1855\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4778175.9273\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4782641.8982\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4695187.7000\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4826465.8436\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4717887.9618\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4680206.0055\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4772302.8018\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4714250.9218\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4694752.9618\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4744525.7182\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4620204.0282\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4616995.1927\n",
            "mean,rmse,rmse/mean,bldg: 2032.483907505765 2073.61471187446 1.0202367183409438 Eagle_education_Sherrill\n",
            "Example prediction:\n",
            " 0 [233 232 232]\n",
            "Example prediction:\n",
            " 2 [233 232 232]\n",
            "Example prediction:\n",
            " 4 [233 232 232]\n",
            "Example prediction:\n",
            " 6 [233 232 232]\n",
            "Example prediction:\n",
            " 8 [233 232 232]\n",
            "Example prediction:\n",
            " 10 [233 232 232]\n",
            "Example prediction:\n",
            " 12 [233 232 232]\n",
            "Example prediction:\n",
            " 14 [233 232 232]\n",
            "Example prediction:\n",
            " 16 [233 232 232]\n",
            "Example prediction:\n",
            " 18 [233 232 232]\n",
            "Example prediction:\n",
            " 20 [233 232 232]\n",
            "Example prediction:\n",
            " 22 [233 232 232]\n",
            "Building Eagle_education_Brooke\n",
            " Count bad values before pseudofill: 56\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_72 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_73 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_74 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [4312 3417 4893]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 4739464.6873\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4617736.4273\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4638725.3800\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 5ms/step - loss: 4629791.4600\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4515546.6518\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4719738.0036\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4553016.9427\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4626417.1173\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4589703.0273\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4551035.9800\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4534611.0691\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4518617.6518\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4512543.3036\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4485782.9436\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4425250.8682\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4427283.6255\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4431242.7809\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4534321.2345\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4459432.6600\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4391680.9600\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4353151.3609\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4287573.5555\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4251781.6209\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4321366.7364\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4314199.0509\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4267696.4545\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4233128.6109\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4170881.8382\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4290355.6145\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4208730.2073\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4178494.0173\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4159179.6100\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4132554.0718\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4152362.3873\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4026935.4664\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4136455.8691\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4087162.5655\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4078723.0973\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4098483.5464\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4089505.5564\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4165299.1109\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4059767.9409\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4002830.2236\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4054599.7991\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3889854.0964\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3948693.7600\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4029657.2882\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3892902.6018\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4007810.3491\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3893395.3891\n",
            "mean,rmse,rmse/mean,bldg: 1639.356375181079 1632.213836725957 0.9956430837350219 Eagle_education_Brooke\n",
            "Example prediction:\n",
            " 0 [232 234 232]\n",
            "Example prediction:\n",
            " 2 [232 234 232]\n",
            "Example prediction:\n",
            " 4 [232 234 232]\n",
            "Example prediction:\n",
            " 6 [232 234 232]\n",
            "Example prediction:\n",
            " 8 [232 234 232]\n",
            "Example prediction:\n",
            " 10 [232 234 232]\n",
            "Example prediction:\n",
            " 12 [232 234 232]\n",
            "Example prediction:\n",
            " 14 [232 234 232]\n",
            "Example prediction:\n",
            " 16 [232 234 232]\n",
            "Example prediction:\n",
            " 18 [232 234 232]\n",
            "Example prediction:\n",
            " 20 [232 234 232]\n",
            "Example prediction:\n",
            " 22 [232 234 232]\n",
            "Building Eagle_education_Alberto\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_75 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_76 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_77 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1245 1231 1234]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 608716.0182\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 594600.9649\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 588617.0770\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 582036.4673\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 577852.0207\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 584017.8264\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 572154.6598\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 560615.0440\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 562073.7130\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 552973.0765\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 540664.1103\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 535787.4523\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 530644.7490\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 531413.5992\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 520204.1047\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 520109.6238\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 504254.2848\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 503484.4025\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 492068.4734\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 489792.3247\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 494410.0833\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 489138.0817\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 475048.5080\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 471578.1345\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 465650.9744\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 457873.6627\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 453064.5000\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 450004.5609\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 446019.0310\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 444011.2359\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 430178.1915\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 419690.8053\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 422368.5972\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 416625.8945\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 412894.0524\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 405847.8256\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 401722.7728\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 399286.6276\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 390276.1425\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 391656.4584\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 375462.2872\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 376931.0742\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 375474.5397\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 361128.2045\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 365183.9705\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 362505.2033\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 353100.8910\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 342494.8153\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 342813.3664\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 333598.1292\n",
            "mean,rmse,rmse/mean,bldg: 694.962522886029 519.5865858062679 0.7476469143235771 Eagle_education_Alberto\n",
            "Example prediction:\n",
            " 0 [230 230 231]\n",
            "Example prediction:\n",
            " 2 [230 230 231]\n",
            "Example prediction:\n",
            " 4 [230 230 231]\n",
            "Example prediction:\n",
            " 6 [230 230 231]\n",
            "Example prediction:\n",
            " 8 [230 230 231]\n",
            "Example prediction:\n",
            " 10 [230 230 231]\n",
            "Example prediction:\n",
            " 12 [230 230 231]\n",
            "Example prediction:\n",
            " 14 [230 230 231]\n",
            "Example prediction:\n",
            " 16 [230 230 231]\n",
            "Example prediction:\n",
            " 18 [230 230 231]\n",
            "Example prediction:\n",
            " 20 [230 230 231]\n",
            "Example prediction:\n",
            " 22 [230 230 231]\n",
            "Building Eagle_food_Kay\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_78 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_79 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_80 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [826 769 484]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 126821.5794\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 123633.6717\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 120928.1499\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 118779.8069\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 116513.4532\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 112109.7568\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 110795.3868\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 109208.7957\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 104105.7694\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 105853.6338\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 100915.2610\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 101384.5331\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 98757.6691\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 96083.7262\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 93083.7401\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 91553.9891\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 89531.9441\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 87659.0980\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 87134.8226\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 82471.7661\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 80004.2921\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 80076.1676\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 78798.0994\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 77735.2793\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 74202.8022\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 73822.3667\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 73169.3321\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 71975.8054\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 69744.7618\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 64180.3451\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 64007.2520\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 63990.1185\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 64258.5088\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 61737.0462\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 59783.7290\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 59115.3359\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 58123.0618\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 56736.2234\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 55062.9993\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 52247.3231\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 53619.4918\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 51779.1538\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 53395.5705\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 51595.2820\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48261.6689\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48971.2941\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48316.8035\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 47583.4821\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 46157.6324\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 47046.4818\n",
            "mean,rmse,rmse/mean,bldg: 276.2706673678431 175.86478697994218 0.6365669893785192 Eagle_food_Kay\n",
            "Example prediction:\n",
            " 0 [212 215 212]\n",
            "Example prediction:\n",
            " 2 [212 215 212]\n",
            "Example prediction:\n",
            " 4 [212 215 212]\n",
            "Example prediction:\n",
            " 6 [212 215 212]\n",
            "Example prediction:\n",
            " 8 [212 215 212]\n",
            "Example prediction:\n",
            " 10 [212 215 212]\n",
            "Example prediction:\n",
            " 12 [212 215 212]\n",
            "Example prediction:\n",
            " 14 [212 215 212]\n",
            "Example prediction:\n",
            " 16 [212 215 212]\n",
            "Example prediction:\n",
            " 18 [212 215 212]\n",
            "Example prediction:\n",
            " 20 [212 215 212]\n",
            "Example prediction:\n",
            " 22 [212 215 212]\n",
            "Building Eagle_health_Jodi\n",
            " Count bad values before pseudofill: 41\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_81 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_82 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_83 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [358 355 365]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 35105.2074\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 32873.4172\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 31917.9534\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30146.3681\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28656.0871\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27272.4782\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26249.4991\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25591.2347\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24112.9011\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22803.1055\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21666.2144\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20553.4421\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20282.7285\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 18596.9560\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17866.5378\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17112.5230\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16488.0010\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15633.5341\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14989.6944\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14097.8740\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13266.0076\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12887.7627\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12262.5608\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11734.3942\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11238.5758\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10803.7519\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10329.7033\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9887.1653\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9212.2623\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9076.4453\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8775.4892\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8482.6912\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8348.8719\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7611.1222\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7596.1524\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7615.6060\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7221.4031\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7265.9465\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7145.1686\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5421.9715\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5079.3566\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4698.8935\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4515.0419\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4423.1092\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4263.5599\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4184.9906\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4128.8745\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3886.8717\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3849.1323\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3759.8417\n",
            "mean,rmse,rmse/mean,bldg: 192.4223112628316 75.98212042828533 0.3948716753770854 Eagle_health_Jodi\n",
            "Example prediction:\n",
            " 0 [188 187 188]\n",
            "Example prediction:\n",
            " 2 [188 188 189]\n",
            "Example prediction:\n",
            " 4 [186 186 187]\n",
            "Example prediction:\n",
            " 6 [181 181 181]\n",
            "Example prediction:\n",
            " 8 [185 185 185]\n",
            "Example prediction:\n",
            " 10 [179 179 180]\n",
            "Example prediction:\n",
            " 12 [184 184 185]\n",
            "Example prediction:\n",
            " 14 [189 188 189]\n",
            "Example prediction:\n",
            " 16 [189 188 189]\n",
            "Example prediction:\n",
            " 18 [189 188 189]\n",
            "Example prediction:\n",
            " 20 [189 188 189]\n",
            "Example prediction:\n",
            " 22 [189 188 189]\n",
            "Building Eagle_education_Norah\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_84 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_85 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_86 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1782 1834 2083]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 631782.6682\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 615869.7745\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 594586.2459\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 616921.1273\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 594875.0934\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 592936.6423\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 589975.3855\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 582152.3014\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 566447.9949\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 564841.7223\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 564056.0207\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 557536.6152\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 551199.6409\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 547883.6135\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 535121.4565\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 521644.6528\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 519291.0212\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 512075.4285\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 520879.0580\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 510646.1045\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 515278.5883\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 498140.3065\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 514521.6690\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 492080.4061\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 476212.8042\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 486215.9367\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 476925.3726\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 473400.1011\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 460020.9308\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 457584.1761\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 451358.2169\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 453348.5551\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 440994.5959\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 440776.8639\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 423292.3882\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 455142.5734\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 428641.2284\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 436043.8248\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 418563.1335\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 403543.6241\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 405371.1526\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 405120.1052\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 401406.3706\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 395064.1931\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 387036.4166\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 390055.8788\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 375713.5356\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 377309.3074\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 379474.5445\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 365537.3268\n",
            "mean,rmse,rmse/mean,bldg: 712.0113639930826 658.9134774183887 0.9254255068670367 Eagle_education_Norah\n",
            "Example prediction:\n",
            " 0 [228 228 230]\n",
            "Example prediction:\n",
            " 2 [228 228 230]\n",
            "Example prediction:\n",
            " 4 [228 228 230]\n",
            "Example prediction:\n",
            " 6 [228 228 230]\n",
            "Example prediction:\n",
            " 8 [228 228 230]\n",
            "Example prediction:\n",
            " 10 [228 228 230]\n",
            "Example prediction:\n",
            " 12 [228 228 230]\n",
            "Example prediction:\n",
            " 14 [228 228 230]\n",
            "Example prediction:\n",
            " 16 [228 228 230]\n",
            "Example prediction:\n",
            " 18 [228 228 230]\n",
            "Example prediction:\n",
            " 20 [228 228 230]\n",
            "Example prediction:\n",
            " 22 [228 228 230]\n",
            "Building Eagle_education_Will\n",
            " Count bad values before pseudofill: 15\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_87 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_88 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_89 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [387 440 391]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 77909.9362\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 73694.4597\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 70548.2145\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 68641.8406\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 67689.8090\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 64318.4261\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 61163.3679\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 61530.9523\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 57425.0319\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 55919.8700\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 55443.9451\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 52838.9426\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 50635.9122\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48028.4220\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 47187.3672\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 45943.3491\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 43392.5756\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 42651.7576\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 40258.2121\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 39071.0078\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 37537.3716\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 36191.1350\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 35472.1584\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 33965.9173\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 32465.4393\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30753.3808\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 29505.0598\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28020.3244\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27359.1795\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25842.2587\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25266.9088\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24364.9704\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 23567.9999\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22104.9733\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21122.9680\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20967.7557\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19203.2917\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 18396.9027\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 18000.5163\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17728.1866\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16008.1756\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15752.1111\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15196.0503\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14656.7377\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13813.2877\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13093.9094\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13193.3114\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12471.2434\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12267.1786\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11535.7782\n",
            "mean,rmse,rmse/mean,bldg: 226.17039013254305 53.48229031641843 0.2364690191544353 Eagle_education_Will\n",
            "Example prediction:\n",
            " 0 [211 212 211]\n",
            "Example prediction:\n",
            " 2 [211 212 211]\n",
            "Example prediction:\n",
            " 4 [211 212 211]\n",
            "Example prediction:\n",
            " 6 [211 212 211]\n",
            "Example prediction:\n",
            " 8 [211 212 211]\n",
            "Example prediction:\n",
            " 10 [211 212 211]\n",
            "Example prediction:\n",
            " 12 [211 212 211]\n",
            "Example prediction:\n",
            " 14 [211 212 211]\n",
            "Example prediction:\n",
            " 16 [211 212 211]\n",
            "Example prediction:\n",
            " 18 [211 212 211]\n",
            "Example prediction:\n",
            " 20 [211 212 211]\n",
            "Example prediction:\n",
            " 22 [211 212 211]\n",
            "Building Eagle_lodging_Blake\n",
            " Count bad values before pseudofill: 8\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_90 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_91 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_92 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [8 8 8]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 31500.8054\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 29277.9533\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 29371.6165\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27747.2971\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28346.2470\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28334.8186\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27448.6442\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27611.7601\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28089.7200\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27806.9048\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27769.2326\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27227.6733\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27566.6422\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28119.4555\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27233.0117\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26420.4782\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27514.4569\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26275.1571\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28243.6475\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27670.4440\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27522.6212\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26660.4699\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26540.5856\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27891.7723\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27248.5240\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26476.2230\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26676.3140\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26121.1667\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26197.2842\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27296.3056\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28056.1836\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26545.9717\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25563.0452\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26181.5995\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25064.4717\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25179.6694\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26050.1705\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25163.1073\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25912.6966\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26484.4469\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24718.0392\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25448.1488\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25091.2663\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26722.9864\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25459.2321\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26652.4463\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24846.8831\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24883.0996\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25921.9916\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26012.4576\n",
            "mean,rmse,rmse/mean,bldg: 43.43471997795112 36.39242210964574 0.8378647802522895 Eagle_lodging_Blake\n",
            "Example prediction:\n",
            " 0 [85 86 85]\n",
            "Example prediction:\n",
            " 2 [85 85 85]\n",
            "Example prediction:\n",
            " 4 [85 86 85]\n",
            "Example prediction:\n",
            " 6 [85 85 85]\n",
            "Example prediction:\n",
            " 8 [85 86 85]\n",
            "Example prediction:\n",
            " 10 [85 86 85]\n",
            "Example prediction:\n",
            " 12 [85 86 85]\n",
            "Example prediction:\n",
            " 14 [85 86 85]\n",
            "Example prediction:\n",
            " 16 [85 86 86]\n",
            "Example prediction:\n",
            " 18 [85 86 86]\n",
            "Example prediction:\n",
            " 20 [85 86 85]\n",
            "Example prediction:\n",
            " 22 [85 86 85]\n",
            "Building Eagle_education_Petra\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_93 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_94 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_95 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [154 166 184]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 4378.6056\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3781.2814\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3254.3962\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2875.1158\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2575.0849\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2358.1887\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2139.5016\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1991.6748\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1823.6998\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1741.5610\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1642.0049\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1562.5152\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1481.2435\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1396.3514\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1404.5500\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1395.1522\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1395.9197\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1404.8558\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1352.7435\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1406.5862\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1375.1752\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1378.3668\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1359.1036\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1332.0151\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1352.8348\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1373.7234\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1279.1857\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 927.9970\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 802.2725\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 677.5940\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 602.3169\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 538.9554\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 505.5565\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 479.8482\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 435.6341\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 417.7258\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 385.0791\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 372.0349\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 348.3255\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 331.0822\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 319.3804\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 318.3740\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 309.2369\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 294.6872\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 295.2150\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 274.6681\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 269.7710\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 273.6880\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 270.6090\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 259.0909\n",
            "mean,rmse,rmse/mean,bldg: 57.04381605290169 24.054440843708136 0.4216835847973488 Eagle_education_Petra\n",
            "Example prediction:\n",
            " 0 [93 93 92]\n",
            "Example prediction:\n",
            " 2 [82 82 82]\n",
            "Example prediction:\n",
            " 4 [76 76 76]\n",
            "Example prediction:\n",
            " 6 [56 55 55]\n",
            "Example prediction:\n",
            " 8 [62 61 62]\n",
            "Example prediction:\n",
            " 10 [52 51 51]\n",
            "Example prediction:\n",
            " 12 [57 57 57]\n",
            "Example prediction:\n",
            " 14 [84 84 84]\n",
            "Example prediction:\n",
            " 16 [108 108 108]\n",
            "Example prediction:\n",
            " 18 [114 114 113]\n",
            "Example prediction:\n",
            " 20 [109 109 108]\n",
            "Example prediction:\n",
            " 22 [92 92 91]\n",
            "Building Eagle_lodging_Trina\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_96 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_97 (GRU)                 (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_98 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [289 316 331]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 13188.5714\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11737.9177\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10879.1932\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10732.2657\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9935.5523\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9135.6231\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8920.9557\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8243.6432\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7724.6616\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7670.4074\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7668.5215\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6922.2819\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6713.5949\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6479.0910\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6092.2748\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5932.6324\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5881.5988\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5831.1952\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5732.0297\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5395.9327\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5415.5845\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5479.2973\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5479.5943\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5338.2156\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5576.6334\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5437.3005\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5508.3156\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5236.0137\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5418.9729\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5359.2879\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5347.4355\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5340.8871\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4670.5771\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4424.1626\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4305.1032\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3935.5038\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3954.1264\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3774.6681\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3750.9687\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3636.4330\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3595.5749\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3413.8423\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3401.6095\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3197.0762\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3155.5804\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3186.0621\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3023.4530\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3012.3510\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2932.5932\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2975.4800\n",
            "mean,rmse,rmse/mean,bldg: 91.27234855584753 52.28064962033342 0.5727983386813373 Eagle_lodging_Trina\n",
            "Example prediction:\n",
            " 0 [114 114 114]\n",
            "Example prediction:\n",
            " 2 [104 103 103]\n",
            "Example prediction:\n",
            " 4 [95 95 94]\n",
            "Example prediction:\n",
            " 6 [89 89 88]\n",
            "Example prediction:\n",
            " 8 [106 105 105]\n",
            "Example prediction:\n",
            " 10 [107 106 107]\n",
            "Example prediction:\n",
            " 12 [94 93 93]\n",
            "Example prediction:\n",
            " 14 [152 152 152]\n",
            "Example prediction:\n",
            " 16 [152 152 152]\n",
            "Example prediction:\n",
            " 18 [144 144 144]\n",
            "Example prediction:\n",
            " 20 [144 144 144]\n",
            "Example prediction:\n",
            " 22 [120 120 119]\n",
            "Building Eagle_health_Reuben\n",
            "Building Eagle_education_Teresa\n",
            " Count bad values before pseudofill: 35\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_99 (GRU)                 (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_100 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_101 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [265 319 169]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 30962.1647\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28245.6904\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27521.1291\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25892.4095\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24128.3641\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22872.9653\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 23214.5130\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22167.7226\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20778.3265\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19703.7124\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 18501.8720\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17830.1096\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16965.1638\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16434.9420\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16034.4591\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15173.5756\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14498.5455\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13839.4534\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13346.2994\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12751.5234\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11817.1369\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11390.0412\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11549.7006\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10668.1740\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10402.1631\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10092.1280\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10273.3082\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9320.2283\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9030.7825\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8863.3373\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8901.5443\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8578.0814\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8797.3944\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8423.6976\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8475.2064\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8281.5774\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8153.8702\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7712.5940\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8066.9694\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8016.5940\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7991.6697\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7631.5831\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7394.6929\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6901.2153\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6892.5762\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6487.9183\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5757.6696\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5667.2617\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5025.7192\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4973.1272\n",
            "mean,rmse,rmse/mean,bldg: 148.73384346526427 46.875003430324 0.31516030473098966 Eagle_education_Teresa\n",
            "Example prediction:\n",
            " 0 [180 180 180]\n",
            "Example prediction:\n",
            " 2 [180 180 180]\n",
            "Example prediction:\n",
            " 4 [180 180 180]\n",
            "Example prediction:\n",
            " 6 [179 179 179]\n",
            "Example prediction:\n",
            " 8 [179 180 179]\n",
            "Example prediction:\n",
            " 10 [179 180 180]\n",
            "Example prediction:\n",
            " 12 [180 180 180]\n",
            "Example prediction:\n",
            " 14 [180 180 180]\n",
            "Example prediction:\n",
            " 16 [180 180 180]\n",
            "Example prediction:\n",
            " 18 [180 180 180]\n",
            "Example prediction:\n",
            " 20 [180 180 180]\n",
            "Example prediction:\n",
            " 22 [180 180 180]\n",
            "Building Eagle_office_Norbert\n",
            " Count bad values before pseudofill: 52\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_102 (GRU)                (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_103 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_104 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [616 643 690]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 151469.1094\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 145659.1595\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 143572.8076\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 139152.9249\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 136684.8009\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 133895.3979\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 129284.0569\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 127077.3865\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 124739.5558\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 122358.7568\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 119120.9303\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 117384.1614\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 114648.3673\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 109845.7800\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 108552.5439\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 104812.0643\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 103529.8864\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 100536.6365\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 98278.1772\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 96347.8001\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 93136.8456\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 92366.7278\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 88237.8773\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 85287.9149\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 83647.7573\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 81271.6753\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 79496.2112\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 77788.3737\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 74120.8160\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 72942.1556\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 70783.2686\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 68641.8423\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 67512.5996\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 65486.7525\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 62770.5787\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 62354.4582\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 59787.9970\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 57708.9524\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 56622.2904\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 54277.4933\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 51975.7702\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 51131.2407\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 50369.7057\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 47700.0901\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 45879.7765\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 45651.5959\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 44340.6176\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 42014.1354\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 41255.2053\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 40305.7021\n",
            "mean,rmse,rmse/mean,bldg: 390.8100632860704 227.16528712783955 0.581267752467152 Eagle_office_Norbert\n",
            "Example prediction:\n",
            " 0 [223 224 220]\n",
            "Example prediction:\n",
            " 2 [223 224 220]\n",
            "Example prediction:\n",
            " 4 [223 224 220]\n",
            "Example prediction:\n",
            " 6 [223 224 220]\n",
            "Example prediction:\n",
            " 8 [223 224 220]\n",
            "Example prediction:\n",
            " 10 [223 224 220]\n",
            "Example prediction:\n",
            " 12 [223 224 220]\n",
            "Example prediction:\n",
            " 14 [223 224 220]\n",
            "Example prediction:\n",
            " 16 [223 224 220]\n",
            "Example prediction:\n",
            " 18 [223 224 220]\n",
            "Example prediction:\n",
            " 20 [223 224 220]\n",
            "Example prediction:\n",
            " 22 [223 224 220]\n",
            "Building Eagle_lodging_Casey\n",
            "Building Eagle_office_Tia\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_105 (GRU)                (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_106 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_107 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [452 417 281]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 6s 6ms/step - loss: 50854.8599\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 48154.6233\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 46110.0480\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 44322.2664\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 42872.1910\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 41027.6232\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 39682.0669\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 38604.0485\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 36475.6255\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 36394.2161\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 33897.3165\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 33620.7844\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 31690.4678\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30633.4049\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30316.0599\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 28593.5654\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27861.9514\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25776.0478\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 25766.7215\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24715.4924\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 23390.8296\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22228.9714\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21458.6363\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21384.1944\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21212.8387\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20140.2282\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19159.8838\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 18387.6409\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17398.1792\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17505.9269\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16240.1981\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16235.7249\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15767.9774\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15200.5907\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14675.8213\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14515.0108\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13929.1897\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13084.4239\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13170.4379\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12677.7354\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12759.9998\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12426.5189\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11862.1016\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11666.2904\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11766.5458\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11559.5619\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11704.6478\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11572.2726\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11008.4275\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11393.6549\n",
            "mean,rmse,rmse/mean,bldg: 174.6359145783468 81.68774797714698 0.4677603010490689 Eagle_office_Tia\n",
            "Example prediction:\n",
            " 0 [192 192 192]\n",
            "Example prediction:\n",
            " 2 [192 192 192]\n",
            "Example prediction:\n",
            " 4 [192 192 192]\n",
            "Example prediction:\n",
            " 6 [192 192 192]\n",
            "Example prediction:\n",
            " 8 [192 192 192]\n",
            "Example prediction:\n",
            " 10 [192 192 192]\n",
            "Example prediction:\n",
            " 12 [192 192 192]\n",
            "Example prediction:\n",
            " 14 [192 192 192]\n",
            "Example prediction:\n",
            " 16 [192 192 192]\n",
            "Example prediction:\n",
            " 18 [192 192 192]\n",
            "Example prediction:\n",
            " 20 [192 192 192]\n",
            "Example prediction:\n",
            " 22 [192 192 192]\n",
            "Building Eagle_office_Remedios\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_108 (GRU)                (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_109 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_110 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [193 192 238]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 13899.4153\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12605.7399\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11971.9213\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11050.4135\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10017.1495\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9422.4943\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8680.5722\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8066.3391\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7562.7998\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7073.7022\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6463.2566\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6001.3367\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5592.1918\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5146.5069\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4802.8303\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4475.4818\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4150.5292\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3891.4022\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3659.1363\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3528.3001\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3288.2409\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3112.4353\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3017.6184\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2866.1148\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2721.9375\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2702.7517\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2577.6716\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2676.2987\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2505.2411\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2537.6656\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2506.4992\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2490.3499\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2499.0920\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2498.5314\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2541.6034\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2481.9820\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2400.3614\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2503.5768\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2468.2661\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2396.4799\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1407.4093\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1275.7888\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1072.3802\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 886.8074\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 752.1196\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 703.7257\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 629.8240\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 608.1174\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 561.8851\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 539.8308\n",
            "mean,rmse,rmse/mean,bldg: 121.48132139556034 24.625658886657774 0.20271148357427848 Eagle_office_Remedios\n",
            "Example prediction:\n",
            " 0 [147 148 147]\n",
            "Example prediction:\n",
            " 2 [147 148 147]\n",
            "Example prediction:\n",
            " 4 [147 148 147]\n",
            "Example prediction:\n",
            " 6 [147 148 147]\n",
            "Example prediction:\n",
            " 8 [147 148 147]\n",
            "Example prediction:\n",
            " 10 [147 148 147]\n",
            "Example prediction:\n",
            " 12 [147 148 147]\n",
            "Example prediction:\n",
            " 14 [147 148 147]\n",
            "Example prediction:\n",
            " 16 [147 148 147]\n",
            "Example prediction:\n",
            " 18 [147 148 147]\n",
            "Example prediction:\n",
            " 20 [147 148 147]\n",
            "Example prediction:\n",
            " 22 [147 148 147]\n",
            "Building Eagle_office_Patrice\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_111 (GRU)                (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_112 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_113 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [710 498 367]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 32631.8994\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 31153.9416\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30189.2240\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 30371.9360\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27922.6791\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27780.7313\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 27509.7800\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 26249.4366\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 24993.2870\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 23754.5955\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22654.1460\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 22113.3721\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21796.4327\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 21221.4136\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 20311.9919\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19413.9545\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 19392.4697\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17771.8486\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17443.9840\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 17075.2799\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16637.9764\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 16419.3261\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 15762.2964\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 14632.1060\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13500.8190\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 13044.1250\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12917.0479\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12328.8329\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12573.6330\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12016.9361\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 12101.4686\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11290.7112\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11053.9366\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10849.1712\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 7ms/step - loss: 9967.0408\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9592.7500\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9643.9619\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9699.1859\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9428.8479\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9267.0697\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9497.6497\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9164.4921\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8534.3115\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9060.5666\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8747.1024\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7902.2732\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7629.4223\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7816.5338\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7240.4623\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7403.1271\n",
            "mean,rmse,rmse/mean,bldg: 165.87984746703071 96.7034031054463 0.5829725827585325 Eagle_office_Patrice\n",
            "Example prediction:\n",
            " 0 [149 150 151]\n",
            "Example prediction:\n",
            " 2 [164 164 165]\n",
            "Example prediction:\n",
            " 4 [196 194 195]\n",
            "Example prediction:\n",
            " 6 [185 184 185]\n",
            "Example prediction:\n",
            " 8 [196 194 195]\n",
            "Example prediction:\n",
            " 10 [196 194 195]\n",
            "Example prediction:\n",
            " 12 [196 194 195]\n",
            "Example prediction:\n",
            " 14 [196 194 195]\n",
            "Example prediction:\n",
            " 16 [196 194 195]\n",
            "Example prediction:\n",
            " 18 [196 194 195]\n",
            "Example prediction:\n",
            " 20 [196 194 195]\n",
            "Example prediction:\n",
            " 22 [196 194 195]\n",
            "Building Eagle_education_Shana\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_114 (GRU)                (None, 7, 16)             960       \n",
            "_________________________________________________________________\n",
            "gru_115 (GRU)                (None, 7, 16)             1632      \n",
            "_________________________________________________________________\n",
            "gru_116 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,275\n",
            "Trainable params: 4,275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [184 182 183]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 6ms/step - loss: 13017.7770\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 11672.6361\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10753.1209\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 10010.9950\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 9244.0885\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 8554.2498\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7965.4622\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 7216.1325\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6852.5291\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 6275.7919\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5747.8431\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 5307.8821\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4875.9702\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4535.0967\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 4225.3060\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3928.7173\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3665.3934\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3379.8081\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 3126.6524\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2922.6582\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2373.0896\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 2s 7ms/step - loss: 2231.7956\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2098.2539\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1946.7589\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1810.5576\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1696.7293\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1719.1457\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1594.1009\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1551.3621\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1520.4492\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1523.9959\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1489.0898\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1436.6574\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1273.2070\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1204.8150\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1181.9690\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1094.1942\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 1026.2111\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 970.6399\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 941.8559\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 801.7063\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 599.9522\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 546.3366\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 506.7085\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 459.4067\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 460.3091\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 433.8930\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 417.2172\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 403.2328\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 392.2164\n",
            "mean,rmse,rmse/mean,bldg: 103.18172944172048 19.938620832356506 0.19323790113072603 Eagle_education_Shana\n",
            "Example prediction:\n",
            " 0 [158 158 158]\n",
            "Example prediction:\n",
            " 2 [158 158 158]\n",
            "Example prediction:\n",
            " 4 [136 135 135]\n",
            "Example prediction:\n",
            " 6 [141 140 140]\n",
            "Example prediction:\n",
            " 8 [155 155 155]\n",
            "Example prediction:\n",
            " 10 [143 142 143]\n",
            "Example prediction:\n",
            " 12 [157 156 156]\n",
            "Example prediction:\n",
            " 14 [156 155 155]\n",
            "Example prediction:\n",
            " 16 [144 143 143]\n",
            "Example prediction:\n",
            " 18 [156 156 156]\n",
            "Example prediction:\n",
            " 20 [158 157 158]\n",
            "Example prediction:\n",
            " 22 [158 158 158]\n",
            "\n",
            "History 7 Future 3\n",
            "Column 1: Mean usage.\n",
            "Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\n",
            "Column 3: RMSE/mean normalized to help understand RMSE.\n",
            "Column 4: Building.\n",
            "      0.00       0.00   inf   Eagle_office_Henriette\n",
            "      0.11       0.03  0.25   Eagle_education_Wesley\n",
            "     15.76      10.78  0.68   Eagle_education_Jewell\n",
            "     35.89       6.02  0.17   Eagle_office_Mandi\n",
            "     36.93       5.59  0.15   Eagle_office_Lamont\n",
            "     43.43      36.39  0.84   Eagle_lodging_Blake\n",
            "     46.46      15.97  0.34   Eagle_education_Eileen\n",
            "     56.50      48.26  0.85   Eagle_office_Dallas\n",
            "     57.04      24.05  0.42   Eagle_education_Petra\n",
            "     62.02      40.18  0.65   Eagle_office_Sheree\n",
            "     81.96      44.37  0.54   Eagle_lodging_Edgardo\n",
            "     87.21      15.86  0.18   Eagle_office_Phyllis\n",
            "     91.27      52.28  0.57   Eagle_lodging_Trina\n",
            "     92.81      39.78  0.43   Eagle_lodging_Dawn\n",
            "    101.56      54.35  0.54   Eagle_office_Freida\n",
            "    103.18      19.94  0.19   Eagle_education_Shana\n",
            "    121.48      24.63  0.20   Eagle_office_Remedios\n",
            "    122.36      46.13  0.38   Eagle_health_Vincenza\n",
            "    148.73      46.88  0.32   Eagle_education_Teresa\n",
            "    165.88      96.70  0.58   Eagle_office_Patrice\n",
            "    174.64      81.69  0.47   Eagle_office_Tia\n",
            "    182.06      77.34  0.42   Eagle_public_Alvin\n",
            "    192.42      75.98  0.39   Eagle_health_Jodi\n",
            "    226.17      53.48  0.24   Eagle_education_Will\n",
            "    273.02     121.13  0.44   Eagle_office_Nereida\n",
            "    276.27     175.86  0.64   Eagle_food_Kay\n",
            "    336.49     204.22  0.61   Eagle_office_Francis\n",
            "    390.81     227.17  0.58   Eagle_office_Norbert\n",
            "    477.67     312.65  0.65   Eagle_health_Athena\n",
            "    659.51     757.38  1.15   Eagle_health_Gregoria\n",
            "    694.96     519.59  0.75   Eagle_education_Alberto\n",
            "    712.01     658.91  0.93   Eagle_education_Norah\n",
            "   1003.99    1856.54  1.85   Eagle_education_Shante\n",
            "   1037.64     932.82  0.90   Eagle_office_Chauncey\n",
            "   1084.43     922.95  0.85   Eagle_health_Reba\n",
            "   1199.38    1067.79  0.89   Eagle_education_Roman\n",
            "   1639.36    1632.21  1.00   Eagle_education_Brooke\n",
            "   2032.48    2073.61  1.02   Eagle_education_Sherrill\n",
            "   3154.83    3032.63  0.96   Eagle_education_Peter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8eEJdHbz9v"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY4snIvJbz9z"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}