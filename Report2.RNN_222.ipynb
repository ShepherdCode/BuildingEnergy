{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNRPftWw9pK"
   },
   "source": [
    "# RNN \n",
    "Restructured code. Smooth steam (3hr window mean) for training but not testing. Compare to RNN 220.\n",
    "\n",
    "Train on hours 1-12, predict hours 25-36 \n",
    "(e.g. yesterday AM predicts today AM).\n",
    "\n",
    "Predictors: steam\n",
    "Predicted variable: steam\n",
    "\n",
    "Test just one building (Edgardo). Train for 50 epochs.\n",
    "\n",
    "Predictions vary by day and 2 units by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5deM-us2w9pZ"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZgkgsP6w9pg",
    "outputId": "4ef7df9a-c09f-4a7b-9c8b-6aad1950ef7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTORS= 1 ['meter']\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "EPOCHS=50  # use 5 for software testing, 50 for model testing\n",
    "SITE = 'Eagle'\n",
    "PREDICTORS = ['hour','month','doy','meter','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "PREDICTORS = ['meter'] # short list for testing\n",
    "NUM_PREDICTORS=len(PREDICTORS)\n",
    "print(\"PREDICTORS=\",NUM_PREDICTORS,PREDICTORS)\n",
    "PREDICTED_VARIABLE = 'meter'  \n",
    "STEPS_HISTORY = 24\n",
    "STEPS_FORWARD = 12 \n",
    "STEPS_FUTURE =  12 \n",
    "METER_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "EXAMPLE='Eagle_lodging_Edgardo'\n",
    "SITE_BUILDINGS = None\n",
    "SMOOTHING_WINDOW=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgeDotTmw9pX",
    "outputId": "bd4586d0-fba9-4763-8b86-5633b1af9a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ONdk510Cw9pc"
   },
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "6YVYM_bqw9pi",
    "outputId": "752bc959-974b-43fd-9208-166762db18c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>doy</th>\n",
       "      <th>airTemperature</th>\n",
       "      <th>cloudCoverage</th>\n",
       "      <th>dewTemperature</th>\n",
       "      <th>precipDepth1HR</th>\n",
       "      <th>precipDepth6HR</th>\n",
       "      <th>seaLvlPressure</th>\n",
       "      <th>windDirection</th>\n",
       "      <th>windSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 18:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  month  doy  ...  seaLvlPressure  windDirection  windSpeed\n",
       "timestamp                              ...                                          \n",
       "2017-12-31 18:00:00    18     12  365  ...          1026.2          330.0        2.6\n",
       "2017-12-31 20:00:00    20     12  365  ...          1027.0          320.0        1.5\n",
       "2017-12-31 21:00:00    21     12  365  ...          1027.2          310.0        2.6\n",
       "2017-12-31 22:00:00    22     12  365  ...          1027.4          330.0        3.1\n",
       "2017-12-31 23:00:00    23     12  365  ...          1027.4          320.0        4.6\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_weather_for_site(site):\n",
    "    wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "    wet_df = fix_date_type(wet_df)\n",
    "    site_df = wet_df.loc[wet_df['site_id'] == site]\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    site_df = site_df.drop(['site_id'],axis=1)\n",
    "    site_df.insert(0,'hour',0)\n",
    "    site_df.insert(1,'month',0)\n",
    "    site_df.insert(2,'doy',0)\n",
    "    L=len(site_df)\n",
    "    for i in range(0,L):\n",
    "        dt=site_df.index[i]\n",
    "        hour=dt.hour\n",
    "        month=dt.month\n",
    "        doy=dt.dayofyear\n",
    "        site_df.iat[i,0] = hour\n",
    "        site_df.iat[i,1] = month\n",
    "        site_df.iat[i,2] = doy\n",
    "    return site_df\n",
    "\n",
    "one_site_weather = load_weather_for_site(SITE)\n",
    "one_site_weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "s-EKuCBibz9d",
    "outputId": "3217d35e-2148-4f17-b657-3ea6dc65844f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 19:00:00</th>\n",
       "      <td>92.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>277.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>280.5331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>289.3302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>164.3474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        meter\n",
       "timestamp                    \n",
       "2017-12-31 19:00:00   92.2957\n",
       "2017-12-31 20:00:00  277.5584\n",
       "2017-12-31 21:00:00  280.5331\n",
       "2017-12-31 22:00:00  289.3302\n",
       "2017-12-31 23:00:00  164.3474"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_meter_for_building(bldg,smooth=0):\n",
    "    all_df = read_zip_to_panda(ZIP_PATH,METER_FILE)\n",
    "    all_df = fix_date_type(all_df)\n",
    "    global SITE_BUILDINGS\n",
    "    SITE_BUILDINGS = [x for x in all_df.columns if x.startswith(SITE)]\n",
    "    site_series = all_df[bldg]\n",
    "    site_df = site_series.to_frame()\n",
    "    #site_df = all_df.loc[all_df['site_id'] == site]\n",
    "    # Change column name from building name to meter.\n",
    "    site_df = site_df.rename(columns={bldg : PREDICTED_VARIABLE})\n",
    "    if smooth>0:\n",
    "        site_df = site_df.rolling(smooth).mean()\n",
    "    return site_df\n",
    "\n",
    "one_bldg_meter = load_meter_for_building(EXAMPLE)\n",
    "print(type(one_bldg_meter))\n",
    "one_bldg_meter.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VynRgLt9w9pk",
    "outputId": "27cfa026-b6b0-444b-df66-a15aee4e8a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (17508, 12, 1)\n",
      "y shape: (17508, 12)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: add smoothing to X\n",
    "def prepare_for_learning(wdf,mdf):\n",
    "    # Concatenate weather and meter.\n",
    "    df = pd.concat([wdf,mdf],axis=1)\n",
    "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
    "    X_shape = (num_samples,STEPS_FUTURE,NUM_PREDICTORS)\n",
    "    Y_shape = (num_samples,STEPS_FUTURE)\n",
    "    X=np.zeros(X_shape)\n",
    "    y=np.zeros(Y_shape)\n",
    "    predictor_series = df[PREDICTORS].values  # selected features\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values  # meter\n",
    "    # TO DO: can we take predicted from mdf instead?\n",
    "    for sam in range (0,num_samples): \n",
    "        prev_val = 0\n",
    "        one_sample = predictor_series[sam:sam+STEPS_FORWARD]\n",
    "        for time in range (0,STEPS_FORWARD): \n",
    "            one_period = one_sample[time]\n",
    "            for feat in range (0,NUM_PREDICTORS):\n",
    "                val = one_period[feat]\n",
    "                if np.isnan(val):\n",
    "                    val = prev_val\n",
    "                else:\n",
    "                    prev_val = val\n",
    "                X[sam,time,feat] = val\n",
    "        for time in range (0,STEPS_FUTURE):  \n",
    "            y[sam,time]=predicted_series[sam+STEPS_HISTORY+time]\n",
    "    return X,y \n",
    "X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1cK_1RMiVfC",
    "outputId": "c7c0dd25-5404-4999-e7b4-a77e641c8d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X columns: ['meter']\n",
      "X example:\n",
      " [[232]\n",
      " [253]\n",
      " [251]\n",
      " [135]\n",
      " [259]\n",
      " [326]\n",
      " [320]\n",
      " [364]\n",
      " [342]\n",
      " [296]\n",
      " [ 45]\n",
      " [ 56]]\n",
      "y example:\n",
      " [ 43 119 327 322 273  92 328 363 346 168 266  27]\n"
     ]
    }
   ],
   "source": [
    "print(\"X columns:\",PREDICTORS)\n",
    "print(\"X example:\\n\",X[100].astype(int))\n",
    "print(\"y example:\\n\",y[100].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z_8rzumTw9p2"
   },
   "outputs": [],
   "source": [
    "def make_RNN():\n",
    "    # The GRU in Keras is optimized for speed on CoLab GPU.\n",
    "    rnn = Sequential([\n",
    "        GRU(16,return_sequences=True, \n",
    "                  input_shape=(STEPS_FORWARD,NUM_PREDICTORS)), \n",
    "        GRU(16,return_sequences=True),\n",
    "        GRU(16,return_sequences=False),\n",
    "        Dense(STEPS_FUTURE)\n",
    "    ])\n",
    "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypnRqq9w9p4",
    "outputId": "f1626b45-be48-429c-de35-4e5c33344fda",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 0 Eagle_office_Lamont\n",
      " Count bad values before pseudofill: 17\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [58 64 68 72 72 72 74 73 71 69 70 71]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 19s 5ms/step - loss: 1225.8656\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 918.5839\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 713.1637\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 539.9073\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 419.0155\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 338.3328\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 278.1804\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 226.0811\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 198.8028\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 186.7112\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 171.5568\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 168.9443\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 164.1405\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 160.9195\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 160.4601\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 104.5048\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 81.4274\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 70.3724\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 61.5478\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58.8551\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58.1240\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 52.0230\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.7891\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48.6620\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48.2104\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50.5519\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50.9079\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.3922\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50.7964\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.0275\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.1316\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49.2601\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.9869\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47.8018\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47.3795\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48.9432\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47.0491\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49.6088\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49.1848\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47.8715\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47.7528\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 46.7799\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.4133\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48.4655\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51.3743\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49.1752\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50.5184\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 46.6120\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48.5170\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 46.7873\n",
      "mean,rmse,rmse/mean,bldg: 36.93460755405991 6.519297331356945 0.1765091810388096 Eagle_office_Lamont\n",
      "Example prediction:\n",
      " 0 [48 48 48 48 48 48 48 48 48 48 48 47]\n",
      "Example prediction:\n",
      " 2 [49 49 49 49 49 49 49 49 49 49 49 49]\n",
      "Example prediction:\n",
      " 4 [50 50 50 50 50 50 51 51 50 50 50 50]\n",
      "Example prediction:\n",
      " 6 [49 49 50 50 50 50 50 50 50 50 50 49]\n",
      "Example prediction:\n",
      " 8 [49 49 49 49 49 49 49 49 49 49 49 49]\n",
      "Example prediction:\n",
      " 10 [49 49 49 49 49 49 49 49 49 49 49 49]\n",
      "Example prediction:\n",
      " 12 [47 47 47 47 47 47 47 47 47 47 47 46]\n",
      "Example prediction:\n",
      " 14 [45 45 45 45 45 45 45 44 45 45 44 44]\n",
      "Example prediction:\n",
      " 16 [42 42 42 42 42 42 42 42 42 42 42 42]\n",
      "Example prediction:\n",
      " 18 [42 42 42 42 42 42 41 41 41 41 41 41]\n",
      "Example prediction:\n",
      " 20 [42 42 42 42 42 42 42 42 42 42 42 42]\n",
      "Example prediction:\n",
      " 22 [42 42 42 42 42 42 41 41 41 41 41 41]\n",
      "Building 1 Eagle_health_Athena\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [1341 1348 1320 1187 1052  960  834  819  801  999 1154 1250]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 350701.2772\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 344082.3023\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 340442.6889\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 334397.7515\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 323568.7826\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 323433.8553\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 319866.9033\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 314499.8845\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 306456.4729\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 308654.5173\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 302934.9866\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 302271.7670\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 301605.5372\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 289135.5553\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 282282.4203\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 285218.4264\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 282918.4036\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 271786.6262\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 274344.0305\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 263404.6452\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 261088.5055\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 261344.7327\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 255177.3606\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 255318.1318\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 243669.4449\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 247944.8262\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 242980.9416\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 232036.9869\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 232543.7387\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 228814.5010\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 225335.4031\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 216723.7768\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 220338.8974\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 215018.0161\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 212848.9686\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 212438.4055\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 199007.0832\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 205310.7008\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 201111.9215\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 198199.1678\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 187980.1280\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 189850.6044\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 186133.9060\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 186016.3926\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 180163.9007\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 180236.3197\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 177363.9744\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 172773.1659\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 166808.8540\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 166401.5985\n",
      "mean,rmse,rmse/mean,bldg: 477.6710835157538 314.04936167089653 0.6574594370658383 Eagle_health_Athena\n",
      "Example prediction:\n",
      " 0 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 2 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 4 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 6 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 8 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 10 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 12 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 14 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 16 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 18 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 20 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Example prediction:\n",
      " 22 [226 225 224 225 225 226 223 226 224 225 224 226]\n",
      "Building 2 Eagle_assembly_Herbert\n",
      "Building 3 Eagle_public_Alvin\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [560 549 468 422 314 298 296 434 517 515 470 450]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 56346.9401\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53103.9229\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 52456.3239\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49718.5094\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 48170.5915\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47272.9033\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 44773.7270\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 43865.5001\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 41571.4353\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 40700.7893\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 40036.8228\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 36779.7375\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 36436.8263\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 36074.3542\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 33308.4694\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 32797.4718\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 32164.6638\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 30194.4809\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 29475.6154\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28481.2156\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28245.0756\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26506.7903\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 24663.4049\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 24089.4451\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 23897.2852\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 23192.8666\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 22116.1467\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 21767.8418\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20540.3718\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18773.1684\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 19588.2216\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17876.2668\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17765.9921\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17561.9864\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17282.6751\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16592.2463\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16108.7166\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15207.5569\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15254.9798\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15047.8090\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14518.5396\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14518.9701\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14164.5500\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13997.8915\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13945.4769\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13495.8987\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13511.6644\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12884.9888\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13555.5912\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12733.9287\n",
      "mean,rmse,rmse/mean,bldg: 182.0635582126762 76.87237025393028 0.42222820979985676 Eagle_public_Alvin\n",
      "Example prediction:\n",
      " 0 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 2 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 4 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 6 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 8 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 10 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 12 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 14 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 16 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 18 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 20 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Example prediction:\n",
      " 22 [193 193 192 192 194 192 192 193 194 192 193 191]\n",
      "Building 4 Eagle_education_Raul\n",
      "Building 5 Eagle_education_Roman\n",
      " Count bad values before pseudofill: 35\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [2589 2505 2475 2437 2673 2987 3111 2693 2817 3019 3655 3750]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 1705768.6000\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1685387.0932\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1692872.4218\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1649004.2814\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1666252.8245\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1687893.8405\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1661066.8268\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1620180.3264\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1640465.1473\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1615118.7023\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1587726.4959\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1598887.4759\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1574296.1323\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1535221.9805\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1570967.3141\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1539054.4323\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1570225.0800\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1505740.0377\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1531444.0218\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1522665.2823\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1501533.1968\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1487644.2582\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1468011.6291\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1468279.8359\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1481787.7809\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1437231.9359\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1441744.5809\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1399644.9855\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1416904.0400\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1411307.5155\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1394144.9027\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1367176.9600\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1361008.6641\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1380222.6041\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1359134.7455\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1344071.6145\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1355810.1205\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1307787.1245\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1334562.1680\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1317960.3618\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1269575.1709\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1295132.3582\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1296149.9518\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1267830.3548\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1248293.1700\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1250966.7168\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1250655.2268\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1242516.0614\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1235232.7073\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1221006.5882\n",
      "mean,rmse,rmse/mean,bldg: 1199.3775815637814 1069.5035873159943 0.8917155062391163 Eagle_education_Roman\n",
      "Example prediction:\n",
      " 0 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 2 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 4 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 6 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 8 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 10 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 12 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 14 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 16 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 18 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 20 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Example prediction:\n",
      " 22 [233 232 228 229 232 230 230 230 229 230 229 230]\n",
      "Building 6 Eagle_office_Mandi\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_12 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [63 63 63 63 63 63 63 63 63 63 63 63]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 1524.9479\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1161.1658\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 919.0695\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 731.6396\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 569.8909\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 448.7168\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 367.5220\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 296.7256\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 261.6549\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 222.8349\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 198.5822\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 195.4510\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 188.7882\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 186.3226\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 180.4868\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 179.7034\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 185.4529\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 183.4757\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 182.4058\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 178.6458\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 180.3690\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 154.9485\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 99.5277\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 77.8896\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 71.2066\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 64.4589\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 63.0271\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58.7462\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 57.0389\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58.1633\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 57.6474\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.7069\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.3359\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.4329\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53.4652\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.4050\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.5467\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.9390\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.1289\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 52.2826\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53.3719\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53.9532\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53.2282\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 54.0843\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53.7852\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.3317\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50.1513\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.7040\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55.4186\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56.2678\n",
      "mean,rmse,rmse/mean,bldg: 35.89274527609939 7.831121493505178 0.2181811793237181 Eagle_office_Mandi\n",
      "Example prediction:\n",
      " 0 [57 57 57 57 57 57 57 57 57 57 57 57]\n",
      "Example prediction:\n",
      " 2 [57 58 57 57 57 57 57 57 57 57 57 57]\n",
      "Example prediction:\n",
      " 4 [55 55 55 55 55 55 55 55 55 55 55 55]\n",
      "Example prediction:\n",
      " 6 [52 52 52 52 52 52 52 52 52 52 52 52]\n",
      "Example prediction:\n",
      " 8 [56 56 56 56 55 56 56 55 55 55 55 55]\n",
      "Example prediction:\n",
      " 10 [54 54 54 54 54 54 54 54 53 53 54 53]\n",
      "Example prediction:\n",
      " 12 [50 50 50 50 50 50 50 50 50 50 50 50]\n",
      "Example prediction:\n",
      " 14 [44 44 44 44 44 44 44 44 44 44 44 44]\n",
      "Example prediction:\n",
      " 16 [43 43 43 43 43 43 43 43 43 43 43 43]\n",
      "Example prediction:\n",
      " 18 [45 45 45 45 45 45 45 45 45 45 45 45]\n",
      "Example prediction:\n",
      " 20 [41 41 41 41 41 41 41 41 41 41 41 41]\n",
      "Example prediction:\n",
      " 22 [38 38 38 38 38 38 38 38 38 38 38 38]\n",
      "Building 7 Eagle_education_Jewell\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [223 207 206 207 205 205 196 203 210 217 222 222]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 4098.0310\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3917.4769\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3862.0889\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3525.3003\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3457.2007\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3213.9707\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3100.0613\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2999.0501\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2905.7780\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2856.4764\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2599.1784\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2537.8936\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2508.9417\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2353.4532\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2360.7314\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2137.4177\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2215.1451\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2030.6306\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2047.5582\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1899.7298\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1911.1066\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1840.1979\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1870.8103\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1771.0648\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1716.3326\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1661.6512\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1663.9184\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1648.8863\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1578.6567\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1564.8391\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1561.7513\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1465.8346\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1395.7169\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1380.6062\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1435.4024\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1363.4446\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1383.5987\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1281.3011\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1357.6416\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1337.1528\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1352.5863\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1309.3256\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1310.7713\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1356.5631\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1262.1099\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1265.5233\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1260.8109\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1208.9914\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1236.0479\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1220.1956\n",
      "mean,rmse,rmse/mean,bldg: 15.763918737885179 5.743300121471865 0.36433200506604246 Eagle_education_Jewell\n",
      "Example prediction:\n",
      " 0 [3 3 4 4 4 4 4 4 4 5 5 5]\n",
      "Example prediction:\n",
      " 2 [3 3 4 4 4 4 4 4 4 5 5 5]\n",
      "Example prediction:\n",
      " 4 [3 3 4 4 4 4 4 4 4 5 5 5]\n",
      "Example prediction:\n",
      " 6 [3 3 4 4 4 4 4 4 4 5 5 5]\n",
      "Example prediction:\n",
      " 8 [7 7 7 7 7 7 7 8 8 8 8 8]\n",
      "Example prediction:\n",
      " 10 [5 5 5 5 6 6 6 6 6 6 7 7]\n",
      "Example prediction:\n",
      " 12 [6 6 6 6 6 6 6 6 7 7 7 7]\n",
      "Example prediction:\n",
      " 14 [5 5 5 5 6 6 6 6 6 6 7 7]\n",
      "Example prediction:\n",
      " 16 [6 6 6 6 6 6 6 6 6 7 7 7]\n",
      "Example prediction:\n",
      " 18 [5 5 5 5 5 5 5 6 6 6 6 6]\n",
      "Example prediction:\n",
      " 20 [7 7 7 7 7 7 7 8 8 8 8 8]\n",
      "Example prediction:\n",
      " 22 [3 3 4 4 4 4 4 4 4 5 5 5]\n",
      "Building 8 Eagle_office_Henriette\n",
      " Count bad values before pseudofill: 162\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_18 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean,rmse,rmse/mean,bldg: 0.0 0.0 nan Eagle_office_Henriette\n",
      "Example prediction:\n",
      " 0 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 2 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 4 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 6 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 8 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 10 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 12 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 14 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 16 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 18 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 20 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 22 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Building 9 Eagle_health_Reba\n",
      " Count bad values before pseudofill: 36\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_21 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [1765 1738 1266 1758 2276 3012 2801 2550 2612 2622 2627 2592]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 4ms/step - loss: 1470865.5918\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1437431.1064\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1424301.1668\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1422592.2900\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1426537.1995\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1385231.5443\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1414834.3700\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1370544.0718\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1363379.3802\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1338521.9186\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1341753.4952\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1313260.3636\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1341345.9336\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1326862.5986\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1309970.9166\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1312978.8605\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1294834.6873\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1283906.4468\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1264859.4689\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1272449.6145\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1264181.1573\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1246766.6586\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1234680.7582\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1204371.1275\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1207679.3655\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1203134.6823\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1182626.8327\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1204266.3291\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1164199.1993\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1151681.2986\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1165739.2800\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1142729.0800\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1136849.5905\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1160868.0177\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1106654.0125\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1131889.7966\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1108865.4418\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1123056.7027\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1127666.2125\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1100567.9109\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1079247.6207\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1074311.6661\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1066684.6473\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1060543.4452\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1045483.3405\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1053347.4493\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1038607.9382\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 1007982.1709\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1008241.8982\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1000590.3941\n",
      "mean,rmse,rmse/mean,bldg: 1084.4328846508208 923.94605551219 0.8520085185444128 Eagle_health_Reba\n",
      "Example prediction:\n",
      " 0 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 2 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 4 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 6 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 8 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 10 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 12 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 14 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 16 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 18 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 20 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Example prediction:\n",
      " 22 [229 231 230 230 231 231 229 231 228 230 231 230]\n",
      "Building 10 Eagle_lodging_Edgardo\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_24 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [203 120 203 174 176 184 226 258 235 184 243 259]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 9802.2986\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8725.0933\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8390.1354\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7627.6003\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7299.1036\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6594.1695\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6410.9172\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5681.4757\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5252.7734\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5097.7537\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4710.7855\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4597.7151\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4465.2529\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4153.9600\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3904.9139\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3893.3344\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3674.3871\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3511.3103\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3465.0636\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3441.7014\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3340.9264\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3286.2758\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3306.2620\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3251.7292\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3244.1459\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3214.3665\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3160.4853\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3112.2197\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3170.9836\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3240.1031\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3205.2197\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3051.1720\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2802.0088\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2610.9404\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2482.0290\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2435.4754\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2314.9308\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2337.4840\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2236.3343\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2253.7148\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2231.6086\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2212.4010\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2103.0251\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2136.5128\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2064.5029\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2053.5720\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2056.7373\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2027.0381\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2028.0598\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2033.6137\n",
      "mean,rmse,rmse/mean,bldg: 81.9636656538589 46.123761475370905 0.5627342445877953 Eagle_lodging_Edgardo\n",
      "Example prediction:\n",
      " 0 [100 101 102 102 101 100 101 100 101 101 100 101]\n",
      "Example prediction:\n",
      " 2 [108 108 109 109 108 108 108 108 108 108 108 108]\n",
      "Example prediction:\n",
      " 4 [97 98 98 98 97 97 97 98 98 97 97 97]\n",
      "Example prediction:\n",
      " 6 [116 116 115 115 116 116 116 116 115 115 115 115]\n",
      "Example prediction:\n",
      " 8 [102 103 101 101 102 102 102 103 102 102 102 102]\n",
      "Example prediction:\n",
      " 10 [59 60 60 60 60 61 60 61 61 62 61 61]\n",
      "Example prediction:\n",
      " 12 [68 69 69 69 69 69 69 70 69 70 70 70]\n",
      "Example prediction:\n",
      " 14 [105 106 105 104 106 106 105 106 105 105 105 105]\n",
      "Example prediction:\n",
      " 16 [125 125 124 124 125 125 124 125 124 123 124 123]\n",
      "Example prediction:\n",
      " 18 [133 133 132 133 133 132 132 132 131 131 131 131]\n",
      "Example prediction:\n",
      " 20 [132 132 132 132 132 132 132 132 131 131 131 130]\n",
      "Example prediction:\n",
      " 22 [133 133 132 133 133 132 133 132 131 131 131 131]\n",
      "Building 11 Eagle_education_Cassie\n",
      "Building 12 Eagle_education_Peter\n",
      " Count bad values before pseudofill: 34\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_27 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_28 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [7938 7923 8023 8046 8049 8002 8064 8097 8187 8160 8224 8161]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 13153801.5818\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12918937.5855\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13010902.4000\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12909538.8218\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12756843.9964\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12975230.1273\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12695589.5855\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12751273.2364\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12635879.8873\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12944761.3964\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12762773.3491\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12636625.0873\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12650744.7273\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12669431.4145\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12469506.5091\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12477007.7491\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12638229.4291\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12885548.2036\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12398143.8800\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12367011.3236\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12351008.3345\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12412522.7673\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12411208.6909\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12235899.4436\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12213721.8618\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12264013.0764\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12095386.9127\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12068881.1964\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12232759.0400\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12080700.2255\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12114493.5891\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12061201.2109\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12097829.2982\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11878387.1564\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11893096.0036\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11801643.9745\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11869701.2800\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11951901.7418\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11786594.0218\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11957554.3818\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12053982.9455\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11717489.6109\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11658158.2945\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11847841.0036\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11678852.5200\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11667556.3600\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11500563.6109\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11483610.6582\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11815757.1491\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11913659.7927\n",
      "mean,rmse,rmse/mean,bldg: 3154.8298985018228 3032.5724118114576 0.9612475186860555 Eagle_education_Peter\n",
      "Example prediction:\n",
      " 0 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 2 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 4 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 6 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 8 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 10 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 12 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 14 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 16 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 18 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 20 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Example prediction:\n",
      " 22 [231 233 234 233 232 233 235 232 233 233 232 230]\n",
      "Building 13 Eagle_health_Gregoria\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_30 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_31 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 5ms/step - loss: 650818.6940\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 679207.0518\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 667886.3689\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 637475.6616\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 636573.8836\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 642562.4373\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 604977.1391\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 634054.2488\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 622449.5425\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 615606.6747\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 612852.5799\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 596739.0726\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 606691.8790\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 611784.6955\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 596116.7839\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 601017.7937\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 571249.6574\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 586637.6239\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 561709.3134\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 566010.2266\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 590300.7011\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 577128.4375\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 554996.9910\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 569241.9341\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 589237.2639\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 546120.4168\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 554994.4168\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 534524.5976\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 551883.4893\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 546088.5203\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 525567.0364\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 530258.6445\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 533844.6151\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 525134.1723\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 523179.5756\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 499679.5581\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 522341.2648\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 538068.9885\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 496696.8840\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 510088.8783\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 473030.2556\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 464824.0280\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 510748.6315\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 481107.8534\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 487306.3902\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 477088.0651\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 483932.0453\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 492461.5862\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 498058.4911\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 472142.8847\n",
      "mean,rmse,rmse/mean,bldg: 659.5054129061737 759.756395341814 1.152009339838281 Eagle_health_Gregoria\n",
      "Example prediction:\n",
      " 0 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 2 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 4 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 6 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 8 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 10 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 12 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 14 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 16 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 18 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 20 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Example prediction:\n",
      " 22 [222 222 223 224 221 223 222 223 222 223 223 223]\n",
      "Building 14 Eagle_lodging_Dawn\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_33 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_34 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_35 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [305 286 264 281 322 322 322 293 305 300 312 293]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 13745.2903\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12555.6907\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11633.8050\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10870.0628\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10371.3702\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9773.2591\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9017.6441\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8560.0459\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7841.1551\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7538.2236\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6926.4301\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6381.0719\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6240.8419\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5774.6816\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5362.1383\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5262.4477\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4928.5462\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4668.8179\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4494.5792\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4391.9227\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4028.2206\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4135.7158\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3845.3531\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3745.7379\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3718.2265\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3638.4448\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3556.2554\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3555.5971\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3551.0591\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3589.9742\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3563.9339\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3632.7665\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3521.4422\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3608.6039\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3496.8022\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3545.9569\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3405.2029\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3113.2898\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2816.8684\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2713.7664\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2526.4536\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2430.2903\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2342.2496\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2337.6070\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2190.8976\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2185.4830\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2157.4801\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2082.1225\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1999.9471\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2003.8381\n",
      "mean,rmse,rmse/mean,bldg: 92.8091523125402 42.06822529114983 0.453276689237314 Eagle_lodging_Dawn\n",
      "Example prediction:\n",
      " 0 [107 107 107 107 107 107 107 107 107 107 107 107]\n",
      "Example prediction:\n",
      " 2 [104 104 104 104 104 104 104 104 104 104 104 104]\n",
      "Example prediction:\n",
      " 4 [102 102 102 102 102 102 102 102 102 102 102 102]\n",
      "Example prediction:\n",
      " 6 [99 99 99 99 99 99 99 99 99 99 99 99]\n",
      "Example prediction:\n",
      " 8 [110 110 110 110 110 111 111 110 110 110 111 110]\n",
      "Example prediction:\n",
      " 10 [122 122 122 122 122 122 122 122 122 122 122 122]\n",
      "Example prediction:\n",
      " 12 [137 137 137 137 137 137 137 137 137 137 137 137]\n",
      "Example prediction:\n",
      " 14 [137 137 137 137 137 137 137 137 137 137 136 136]\n",
      "Example prediction:\n",
      " 16 [119 119 119 119 119 119 119 119 119 119 119 119]\n",
      "Example prediction:\n",
      " 18 [121 121 121 121 121 120 121 120 121 120 121 120]\n",
      "Example prediction:\n",
      " 20 [117 117 117 117 117 117 117 117 117 117 117 117]\n",
      "Example prediction:\n",
      " 22 [116 116 116 116 116 115 116 115 116 116 116 115]\n",
      "Building 15 Eagle_office_Nereida\n",
      " Count bad values before pseudofill: 17\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_36 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_37 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_38 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [433 474 507 535 536 537 550 540 527 515 523 530]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 5ms/step - loss: 72471.1822\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 70372.5547\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 67097.8717\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 65969.4310\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 63175.7846\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 62292.3523\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 59489.3280\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 57428.0555\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56597.3420\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 54485.8432\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 51975.0024\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50585.9599\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49318.5215\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47683.7797\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 46049.8099\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 43629.9643\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 43368.8428\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 41368.3059\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 39663.2841\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 38823.4643\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 37155.1704\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 35705.7503\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 34846.2448\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 33332.3770\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 31784.6296\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 30707.3570\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 30169.5774\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28854.6455\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28024.8479\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26664.9197\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26205.4617\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 24482.0607\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 23111.1837\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 22477.8709\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20858.2915\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20337.9165\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 19290.8408\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18612.6179\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18319.1075\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17113.8859\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16324.7393\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15745.0315\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14984.8989\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14333.5134\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13832.2324\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13523.7888\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13306.5853\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12634.0575\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12178.6878\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12170.2442\n",
      "mean,rmse,rmse/mean,bldg: 273.01729748007574 122.24027392114016 0.4477382021190837 Eagle_office_Nereida\n",
      "Example prediction:\n",
      " 0 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 2 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 4 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 6 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 8 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 10 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 12 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 14 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 16 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 18 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 20 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Example prediction:\n",
      " 22 [210 209 209 209 208 209 209 209 207 208 210 208]\n",
      "Building 16 Eagle_lodging_Tressa\n",
      "Building 17 Eagle_education_Eileen\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_39 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_40 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_41 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [ 95  89  84  64  47  38  35  69  92 112  99  88]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 2530.5685\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2059.9782\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1770.7693\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1505.9332\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1304.2978\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1101.9170\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 998.8822\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 868.2686\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 802.3249\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 735.6884\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 669.4193\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 645.2265\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 607.8674\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 613.2771\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 588.2836\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 590.8615\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 596.6691\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 600.4073\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 582.9540\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 609.6511\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 590.0496\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 577.2437\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 587.6568\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 588.5042\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 595.2812\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 575.7774\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 586.7068\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 591.5644\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 581.0186\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 565.6119\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 584.7284\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 608.8208\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 587.2196\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 582.1969\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 588.8143\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 576.9839\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 577.7413\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 598.8734\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 602.9700\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 593.6501\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 592.9509\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 602.7245\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 578.9906\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 572.9351\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 596.3987\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 593.4262\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 572.0632\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 590.1541\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 588.7461\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 584.5746\n",
      "mean,rmse,rmse/mean,bldg: 46.462781809371094 20.768877964938497 0.447000311994871 Eagle_education_Eileen\n",
      "Example prediction:\n",
      " 0 [42 42 42 42 42 42 42 42 41 42 42 43]\n",
      "Example prediction:\n",
      " 2 [42 42 41 42 42 41 41 42 41 41 41 43]\n",
      "Example prediction:\n",
      " 4 [41 42 41 42 42 41 41 42 41 41 41 43]\n",
      "Example prediction:\n",
      " 6 [42 42 42 42 42 41 42 42 41 42 42 43]\n",
      "Example prediction:\n",
      " 8 [47 47 47 47 47 47 46 46 46 46 46 46]\n",
      "Example prediction:\n",
      " 10 [47 47 47 47 47 47 47 47 47 47 47 47]\n",
      "Example prediction:\n",
      " 12 [47 47 47 47 47 47 47 47 47 47 47 47]\n",
      "Example prediction:\n",
      " 14 [47 47 47 47 47 47 47 47 47 47 47 47]\n",
      "Example prediction:\n",
      " 16 [47 47 47 47 47 47 47 47 47 47 47 47]\n",
      "Example prediction:\n",
      " 18 [46 46 46 46 46 46 46 46 46 46 46 46]\n",
      "Example prediction:\n",
      " 20 [43 43 43 43 43 43 43 43 43 43 43 44]\n",
      "Example prediction:\n",
      " 22 [42 42 42 42 42 42 42 42 41 42 42 43]\n",
      "Building 18 Eagle_education_Wesley\n",
      " Count bad values before pseudofill: 112\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_42 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_43 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_44 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 0.0019\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.4305e-04\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.2361e-04\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0618e-04\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.1051e-04\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0087e-04\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0669e-04\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.1291e-04\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8871e-04\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.1063e-04\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0206e-04\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8335e-04\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0162e-04\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0008e-04\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0459e-04\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.9232e-04\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0228e-04\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0936e-04\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8888e-04\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5.0369e-04\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6755e-04\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8489e-04\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7143e-04\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.5871e-04\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8315e-04\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.9039e-04\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7219e-04\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8286e-04\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.9044e-04\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8376e-04\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8558e-04\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6834e-04\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7359e-04\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.5863e-04\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8533e-04\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8273e-04\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6567e-04\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7855e-04\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6037e-04\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7690e-04\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7257e-04\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8832e-04\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6469e-04\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7379e-04\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6056e-04\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.5337e-04\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.5743e-04\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.8112e-04\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.6615e-04\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4.7187e-04\n",
      "mean,rmse,rmse/mean,bldg: 0.10558919611442527 0.023106791162993797 0.21883669933383476 Eagle_education_Wesley\n",
      "Example prediction:\n",
      " 0 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 2 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 4 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 6 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 8 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 10 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 12 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 14 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 16 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 18 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 20 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Example prediction:\n",
      " 22 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Building 19 Eagle_health_Vincenza\n",
      " Count bad values before pseudofill: 75\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_45 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_46 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_47 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [249 254 202 138  82  79  84  86 160 230 306 296]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 17246.5425\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15964.9802\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15152.4672\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14226.0912\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13220.9185\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12388.4985\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11486.7176\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10739.5825\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10137.7580\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9775.2822\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8997.4236\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8502.9984\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7875.2605\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7353.0366\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6986.8151\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6459.8900\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6117.0129\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5672.0008\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5450.3348\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5157.7248\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4795.7265\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4677.3364\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4400.4797\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4232.6707\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4046.5218\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3948.1960\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3862.3811\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3729.1393\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3594.4705\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3540.8096\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3571.1845\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3492.6522\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3478.2584\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3496.6801\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3430.1003\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3462.6769\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2871.6901\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2782.0847\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2648.1305\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2581.4212\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2498.7661\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2490.9588\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2486.0611\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2390.2626\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2379.1937\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2279.0712\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2288.8942\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2290.1285\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2251.7337\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2206.3708\n",
      "mean,rmse,rmse/mean,bldg: 122.36347174423398 46.96869332002304 0.38384570697861314 Eagle_health_Vincenza\n",
      "Example prediction:\n",
      " 0 [150 151 152 153 153 153 153 153 153 152 152 150]\n",
      "Example prediction:\n",
      " 2 [134 135 136 136 136 136 136 135 135 134 134 133]\n",
      "Example prediction:\n",
      " 4 [111 112 112 112 112 112 111 111 110 110 110 110]\n",
      "Example prediction:\n",
      " 6 [133 133 133 134 134 134 135 135 135 135 134 133]\n",
      "Example prediction:\n",
      " 8 [151 152 153 153 153 154 154 154 154 153 153 151]\n",
      "Example prediction:\n",
      " 10 [152 153 154 154 155 155 155 155 155 154 154 152]\n",
      "Example prediction:\n",
      " 12 [153 154 154 155 155 155 155 155 156 155 154 153]\n",
      "Example prediction:\n",
      " 14 [150 151 152 152 153 153 153 153 153 152 152 150]\n",
      "Example prediction:\n",
      " 16 [150 151 152 152 153 153 153 153 153 152 152 150]\n",
      "Example prediction:\n",
      " 18 [152 153 154 155 155 155 155 155 156 154 154 152]\n",
      "Example prediction:\n",
      " 20 [152 153 154 155 155 155 155 155 155 154 154 152]\n",
      "Example prediction:\n",
      " 22 [139 139 140 140 140 140 141 141 140 140 139 139]\n",
      "Building 20 Eagle_office_Dallas\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_48 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_49 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_50 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [113 154 154 154 117 109 105 137 178 215 219 219]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 4468.1755\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4271.2292\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3780.0054\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3596.4347\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3306.0690\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3257.8481\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3219.3160\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3168.9755\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2782.6128\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2730.3444\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2767.9990\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2641.5251\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2558.5078\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2651.6210\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2414.1748\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2238.1910\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2365.9207\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2058.2755\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2365.3339\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2127.4352\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2127.5663\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2113.2640\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2046.0464\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2134.5146\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2149.9618\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2093.5383\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2049.2734\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2060.9979\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2062.3084\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2209.9479\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2012.8501\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1852.5214\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2090.4993\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1929.1164\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1927.9116\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1928.8628\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2087.9207\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1966.2751\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1780.8946\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2013.5916\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1945.5297\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1894.9518\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1992.5588\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1862.9324\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1948.8721\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1819.7508\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2132.6854\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1982.4223\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1771.7539\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1804.9470\n",
      "mean,rmse,rmse/mean,bldg: 56.5030097936379 50.32005073515862 0.8905729255651887 Eagle_office_Dallas\n",
      "Example prediction:\n",
      " 0 [46 46 46 46 46 46 45 46 46 45 46 46]\n",
      "Example prediction:\n",
      " 2 [48 47 48 47 47 47 47 47 47 47 47 47]\n",
      "Example prediction:\n",
      " 4 [38 38 38 38 38 37 37 37 37 37 37 38]\n",
      "Example prediction:\n",
      " 6 [25 24 24 24 24 24 24 24 24 24 25 25]\n",
      "Example prediction:\n",
      " 8 [26 26 25 25 25 25 25 25 26 26 26 27]\n",
      "Example prediction:\n",
      " 10 [27 27 27 27 26 27 27 27 27 27 28 28]\n",
      "Example prediction:\n",
      " 12 [36 36 36 36 35 36 35 36 36 36 36 37]\n",
      "Example prediction:\n",
      " 14 [27 27 27 27 27 27 27 27 27 27 28 28]\n",
      "Example prediction:\n",
      " 16 [37 37 37 37 37 37 37 37 37 37 38 38]\n",
      "Example prediction:\n",
      " 18 [52 52 52 52 51 52 52 52 52 52 52 52]\n",
      "Example prediction:\n",
      " 20 [30 30 30 29 29 29 29 29 30 30 30 30]\n",
      "Example prediction:\n",
      " 22 [38 37 37 37 37 37 38 37 38 38 38 38]\n",
      "Building 21 Eagle_education_Shante\n",
      " Count bad values before pseudofill: 23\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_51 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_52 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_53 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 182936.8761\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 175785.6453\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 169293.4437\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 164853.3850\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 166010.9069\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 155071.8525\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 172006.0190\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 157986.2854\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 175886.6443\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 177273.7754\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 185225.7610\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 178218.3547\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 159862.6023\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 177557.1560\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 189403.6931\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 167465.7908\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 146650.2038\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 162880.1218\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 159238.8611\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 167214.1956\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 142077.6096\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 162810.7719\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 165017.2469\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 168331.2591\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 163098.4773\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 144245.3268\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 152709.0954\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 161211.9957\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 161549.8794\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 163358.3137\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 150447.8098\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 165258.4681\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 155019.8614\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 183215.4346\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 155646.5803\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 155073.9930\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 152383.5425\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 146075.0251\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 150065.7026\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 141654.1468\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 175877.8824\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 175141.8811\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 151597.9070\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 157930.0198\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 166122.5598\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 153670.6592\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 152277.1870\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 146594.5449\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 148145.0036\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 167925.1674\n",
      "mean,rmse,rmse/mean,bldg: 1003.9941709339338 1860.6941910715582 1.8532918267251555 Eagle_education_Shante\n",
      "Example prediction:\n",
      " 0 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 2 [123 121 122 122 122 121 121 121 121 121 121 119]\n",
      "Example prediction:\n",
      " 4 [-7 -7 -8 -8 -8 -7 -7 -6 -7 -7 -7 -7]\n",
      "Example prediction:\n",
      " 6 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 8 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 10 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 12 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 14 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 16 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 18 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 20 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Example prediction:\n",
      " 22 [159 157 159 159 158 157 157 156 156 156 156 156]\n",
      "Building 22 Eagle_office_Chauncey\n",
      " Count bad values before pseudofill: 116\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_54 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_55 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_56 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [1735 1706 1698 1718 1726 1771 1713 1731 1755 1796 1823 1753]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 1093889.1127\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1087212.5577\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1085818.3445\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1061793.1091\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1057845.8691\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1048200.3175\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1045892.5430\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1036653.0850\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1019482.5577\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1004892.3930\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 990239.1643\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 990015.4593\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 993969.0120\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 978142.0032\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 968553.2452\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 971300.1677\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 959089.0961\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 948399.8136\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 944727.2986\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 931317.8070\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 920597.5048\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 915520.4666\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 912341.2625\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 913591.2282\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 894984.1980\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 880328.4764\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 878471.9327\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 855127.3839\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 853398.5450\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 851840.1900\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 839537.5802\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 827645.9080\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 830472.5648\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 814053.5175\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 816412.1368\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 813826.3302\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 792515.5200\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 795696.3207\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 786521.3811\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 769997.6027\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 766192.2598\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 762818.0234\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 752285.7252\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 746366.0450\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 738198.0052\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 739997.6845\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 730850.7811\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 712403.4827\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 714636.7466\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 706433.6059\n",
      "mean,rmse,rmse/mean,bldg: 1037.6368908901366 933.799593265587 0.8999290613737984 Eagle_office_Chauncey\n",
      "Example prediction:\n",
      " 0 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 2 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 4 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 6 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 8 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 10 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 12 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 14 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 16 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 18 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 20 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Example prediction:\n",
      " 22 [230 231 229 232 230 230 229 231 230 229 228 231]\n",
      "Building 23 Eagle_office_Phyllis\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_57 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_58 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_59 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [154 154 154 154 154 154 154 154 155 155 154 153]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 9425.6780\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8483.4070\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7753.2156\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7097.9883\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6446.4526\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5873.1133\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5238.2761\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4789.0729\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4360.0930\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3914.3324\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3547.5641\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3176.7548\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2919.5372\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2629.6899\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2428.6192\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2146.0899\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1977.0887\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1769.9608\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1637.6291\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1512.8672\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1407.2551\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1317.6986\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1309.8849\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1175.6778\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1160.3994\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1144.0441\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1104.9979\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1089.2396\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1078.0236\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1045.0888\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1106.3572\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1089.6352\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1084.5495\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1095.6077\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1053.7025\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1109.1925\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1074.5794\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1091.5300\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1055.4307\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1034.1122\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 689.3544\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 576.1071\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 506.9801\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 491.3917\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 446.0652\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 430.3495\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 405.5985\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 389.4461\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 385.2983\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 353.6122\n",
      "mean,rmse,rmse/mean,bldg: 87.20950227834119 19.171891372034043 0.21983718369179886 Eagle_office_Phyllis\n",
      "Example prediction:\n",
      " 0 [129 129 129 130 129 129 129 129 129 129 129 129]\n",
      "Example prediction:\n",
      " 2 [129 129 129 130 129 129 129 129 129 129 129 129]\n",
      "Example prediction:\n",
      " 4 [129 129 129 129 129 129 129 129 129 129 128 129]\n",
      "Example prediction:\n",
      " 6 [123 123 123 123 123 123 123 123 123 123 123 123]\n",
      "Example prediction:\n",
      " 8 [128 128 128 128 128 128 128 128 128 128 128 128]\n",
      "Example prediction:\n",
      " 10 [129 128 128 129 128 129 128 129 128 128 128 128]\n",
      "Example prediction:\n",
      " 12 [124 124 124 124 124 124 124 124 124 124 124 124]\n",
      "Example prediction:\n",
      " 14 [112 111 111 111 112 111 111 111 111 112 112 111]\n",
      "Example prediction:\n",
      " 16 [107 106 106 106 107 106 107 106 106 107 107 106]\n",
      "Example prediction:\n",
      " 18 [104 104 104 104 104 104 104 104 104 104 104 104]\n",
      "Example prediction:\n",
      " 20 [93 93 93 93 94 93 93 93 93 94 93 93]\n",
      "Example prediction:\n",
      " 22 [83 84 84 83 84 84 84 83 83 84 83 83]\n",
      "Building 24 Eagle_office_Freida\n",
      " Count bad values before pseudofill: 63\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_60 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_61 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_62 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [417 437 390 223 148  54  65  75 200 350 504 409]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 20406.6609\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 19331.2086\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17951.6155\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16960.7792\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16260.7961\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 15396.9789\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14466.3447\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13737.0939\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13131.4457\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12399.6288\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11650.0729\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10930.6797\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10380.1704\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10051.2041\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9459.6789\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9022.0248\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8719.8793\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 8253.8921\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7989.9221\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7474.5989\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7247.4813\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7161.4089\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6802.1119\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6389.5090\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6545.8908\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6269.5839\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6223.2491\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6209.6157\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6031.3452\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5838.2537\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5873.2153\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5660.5082\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5615.0533\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5637.7726\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5628.8387\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5620.0734\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5579.9717\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5550.7623\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5600.6627\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5278.7656\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4719.2282\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4601.5897\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4410.2449\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4407.6592\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4460.4808\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4236.9559\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4152.7657\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4144.5109\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4084.0987\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4036.6749\n",
      "mean,rmse,rmse/mean,bldg: 101.557715031556 45.750981573332815 0.4504924274745358 Eagle_office_Freida\n",
      "Example prediction:\n",
      " 0 [88 86 86 87 85 86 86 86 86 86 87 88]\n",
      "Example prediction:\n",
      " 2 [82 79 78 79 77 78 79 78 79 79 80 81]\n",
      "Example prediction:\n",
      " 4 [86 84 84 85 83 83 84 83 84 84 85 86]\n",
      "Example prediction:\n",
      " 6 [80 77 77 78 76 76 77 76 77 77 78 80]\n",
      "Example prediction:\n",
      " 8 [78 75 74 75 73 73 74 74 75 75 76 77]\n",
      "Example prediction:\n",
      " 10 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 12 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 14 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 16 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 18 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 20 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Example prediction:\n",
      " 22 [71 67 66 67 65 66 66 66 67 67 68 70]\n",
      "Building 25 Eagle_office_Francis\n",
      " Count bad values before pseudofill: 20\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_63 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_64 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_65 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [396 408 439 451 463 432 451 481 487 475 475 469]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 89542.3825\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 85575.7370\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 82245.8455\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 80178.6220\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 77845.7791\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 76422.3807\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 74101.6478\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 71259.9426\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 69353.1298\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 67075.0957\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 64000.8866\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 62268.7047\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 60975.3065\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58988.1236\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56647.9827\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 54480.6528\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 53108.9797\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50648.6816\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 49467.8168\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 47857.5010\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 45918.7939\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 43664.4564\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 42538.8926\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 40725.3181\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 39897.5179\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 38157.1002\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 36671.0348\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 34815.5183\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 33925.3008\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 31550.8060\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 31357.6266\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 30103.8677\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28681.7423\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 27866.0022\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26893.9960\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 25751.4580\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 24462.6172\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 23661.4109\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 22280.6304\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 21532.6199\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20858.0671\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20004.0565\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18642.7724\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18131.1895\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 17743.6348\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16355.1224\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15997.5827\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15381.3277\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 15065.3580\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 14505.7573\n",
      "mean,rmse,rmse/mean,bldg: 336.48649201094844 205.40432534363475 0.6104385472239148 Eagle_office_Francis\n",
      "Example prediction:\n",
      " 0 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 2 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 4 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 6 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 8 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 10 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 12 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 14 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 16 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 18 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 20 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Example prediction:\n",
      " 22 [212 214 214 212 212 215 213 213 213 211 212 212]\n",
      "Building 26 Eagle_office_Sheree\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_66 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_67 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_68 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [165 214 171 103  35  49  79  81 125 157 170 169]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 4899.8110\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4368.3199\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4021.0537\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3492.2073\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3160.5702\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3047.4320\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2774.1759\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2573.0319\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2366.4145\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2291.8744\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2113.9323\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 2032.4596\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1911.1106\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1808.1602\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1698.7158\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1639.1340\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1641.0748\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1520.2792\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1534.4711\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1478.5343\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1437.8302\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1396.7037\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1372.3110\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1385.5513\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1315.4451\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1331.4020\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1328.1785\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1291.7317\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1298.6575\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1269.8552\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1250.3638\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1267.2600\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1267.2135\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1223.9366\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1220.2632\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1208.7033\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1240.7720\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1200.5244\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1228.5794\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1215.0094\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1197.0356\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1208.5389\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1221.9516\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1167.9162\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1172.9661\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1161.0070\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1195.4564\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1165.2310\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 1169.8185\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1161.1411\n",
      "mean,rmse,rmse/mean,bldg: 62.02257521757287 41.8634366384316 0.6749709519731523 Eagle_office_Sheree\n",
      "Example prediction:\n",
      " 0 [32 34 35 34 33 29 26 21 17 15 16 18]\n",
      "Example prediction:\n",
      " 2 [22 23 24 23 22 18 16 12  8  6  7 10]\n",
      "Example prediction:\n",
      " 4 [18 19 20 19 18 14 13  9  6  5  5  8]\n",
      "Example prediction:\n",
      " 6 [14 14 14 13 12 11 10  9  9  8  9 11]\n",
      "Example prediction:\n",
      " 8 [26 25 25 24 25 26 27 28 30 31 32 32]\n",
      "Example prediction:\n",
      " 10 [40 40 41 41 41 42 41 42 43 43 44 43]\n",
      "Example prediction:\n",
      " 12 [50 50 51 50 51 52 52 53 54 55 55 54]\n",
      "Example prediction:\n",
      " 14 [63 63 63 63 63 64 65 67 69 70 70 69]\n",
      "Example prediction:\n",
      " 16 [ 98 100  99  99  99  98  99 100 100 100 100  98]\n",
      "Example prediction:\n",
      " 18 [ 99 100 100  99  99  99  99 100 101 100 100  99]\n",
      "Example prediction:\n",
      " 20 [ 98 100  99  99  99  98  99 100 100 100 100  98]\n",
      "Example prediction:\n",
      " 22 [91 93 93 93 93 92 92 91 90 89 88 87]\n",
      "Building 27 Eagle_education_Sherrill\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_69 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_70 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_71 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [4351 4417 4462 4503 4501 4299 4100 3898 3908 3882 3982 3918]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 5584682.4209\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5414678.0182\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5392454.7655\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5529779.4545\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5442718.0545\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5486617.3436\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5425821.1055\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5254782.1309\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5400691.8655\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5427661.2327\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5405957.0600\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5325710.2455\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5292941.3873\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5233570.7727\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5166322.7055\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5250513.0636\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5249560.8418\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5263530.8745\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5199232.7364\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5106499.5927\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5128653.8127\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5139681.0509\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5054121.0436\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5169420.3145\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5099017.6327\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5047419.6291\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5039434.3564\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5036570.6709\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4951550.5091\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5101872.0582\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5004230.7418\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4887735.2345\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4975520.4709\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5029715.0782\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4857216.1764\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4911913.1636\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4830095.7491\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4899067.2818\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4798175.3400\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4796925.1664\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4777072.9909\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4851666.0782\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4753063.5636\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4851717.5600\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4717073.0164\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4784505.9564\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4723899.5400\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4765093.0891\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4758128.4982\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4676913.9709\n",
      "mean,rmse,rmse/mean,bldg: 2032.483907505765 2073.983379814485 1.0204181062174547 Eagle_education_Sherrill\n",
      "Example prediction:\n",
      " 0 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 2 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 4 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 6 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 8 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 10 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 12 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 14 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 16 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 18 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 20 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Example prediction:\n",
      " 22 [231 232 231 230 231 232 231 232 232 231 230 230]\n",
      "Building 28 Eagle_education_Brooke\n",
      " Count bad values before pseudofill: 56\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_72 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_73 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_74 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [3417 3599 4324 4893 5456 4802 4206 3638 4293 4751 4707 4611]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 4668204.5382\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4722878.0327\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4694944.0945\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4572589.3700\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4638379.2782\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4613877.2391\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4523753.9445\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4591014.0518\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4470741.0309\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4584359.0818\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4527187.6582\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4537158.0945\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4466379.2255\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4424632.1764\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4485076.0509\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4424205.1773\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4493250.2782\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4502599.2200\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4442929.1436\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4353556.5855\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4297455.9527\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4353532.6991\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4353953.4118\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4317542.8255\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4264459.0273\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4308776.2282\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4265094.5236\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4220564.5836\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4224860.6245\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4266203.7382\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4216876.0364\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4167309.4427\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4142226.5564\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4181764.7291\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4162883.8145\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4154606.6445\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4158782.4464\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4168158.1273\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4086125.2836\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3993994.9082\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4009989.3745\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4042862.2764\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4145236.1555\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3993690.7073\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4010325.5082\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 3918443.0736\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3974061.6973\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3954892.6255\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4013680.3336\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3856851.3036\n",
      "mean,rmse,rmse/mean,bldg: 1639.356375181079 1632.6565163198447 0.9959131162920605 Eagle_education_Brooke\n",
      "Example prediction:\n",
      " 0 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 2 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 4 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 6 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 8 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 10 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 12 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 14 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 16 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 18 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 20 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Example prediction:\n",
      " 22 [230 229 231 231 231 232 232 232 232 232 230 230]\n",
      "Building 29 Eagle_education_Alberto\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_75 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_76 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_77 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [1231 1231 1231 1234 1234 1234 1233 1234 1238 1238 1230 1225]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 612011.9409\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 611436.6564\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 590369.9470\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 594275.5489\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 591212.1080\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 580139.8636\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 565230.5561\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 570469.6825\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 562443.2118\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 548631.9780\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 546218.3751\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 547584.8348\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 538489.0132\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 528696.6215\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 521924.0270\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 523516.0642\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 505853.5426\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 505733.4290\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 500417.2111\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 497858.8269\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 483631.6716\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 481158.8097\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 474117.7116\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 471469.3158\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 460151.5557\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 465120.7042\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 454948.6252\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 453421.2787\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 438146.3286\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 442145.7782\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 435765.2086\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 427289.2052\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 425694.3353\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 422010.8094\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 411313.9075\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 405659.8631\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 403980.7148\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 394557.6701\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 390357.7363\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 383465.1414\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 388381.5910\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 376625.3805\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 370723.8286\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 360176.9031\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 362707.5425\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 360147.6235\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 353229.5642\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 348620.7659\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 349126.4693\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 337537.4512\n",
      "mean,rmse,rmse/mean,bldg: 694.962522886029 522.0055709790299 0.7511276562241856 Eagle_education_Alberto\n",
      "Example prediction:\n",
      " 0 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 2 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 4 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 6 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 8 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 10 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 12 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 14 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 16 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 18 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 20 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Example prediction:\n",
      " 22 [229 227 228 229 227 228 228 226 228 229 228 228]\n",
      "Building 30 Eagle_food_Kay\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_78 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_79 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_80 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [769 710 591 484 385 366 332 292 254 420 593 804]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 126586.0139\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 122504.8877\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 124030.7645\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 119333.7623\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 116024.7838\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 113264.4436\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 111503.3811\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 108251.0079\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 107118.0991\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 106775.9942\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 102126.2561\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 98937.5798\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 96440.0609\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 96181.0966\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 93002.7761\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 93220.3100\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 87505.3686\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 89304.3878\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 84679.8896\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 82814.3699\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 84307.3703\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 79146.7929\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 79134.8041\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 76116.3890\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 74355.6229\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 73031.1951\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 71046.8873\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 72275.2869\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 67901.8869\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 67259.3586\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 66964.5912\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 63959.7000\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 66451.0562\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 61115.3566\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 60507.0803\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 59932.8114\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 58368.1331\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 55530.1537\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 55477.3934\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 54503.3875\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 54222.0483\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 51919.4459\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 52179.4353\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 50315.7832\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 48801.4949\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 51245.2160\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 47254.8931\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 47814.0911\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 48009.2763\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 45534.1544\n",
      "mean,rmse,rmse/mean,bldg: 276.2706673678431 175.20688419949505 0.6341856190118593 Eagle_food_Kay\n",
      "Example prediction:\n",
      " 0 [167 168 167 166 166 166 167 165 166 166 166 164]\n",
      "Example prediction:\n",
      " 2 [128 128 127 128 126 126 128 126 127 127 126 124]\n",
      "Example prediction:\n",
      " 4 [114 115 113 114 112 113 114 112 113 113 112 111]\n",
      "Example prediction:\n",
      " 6 [191 192 191 190 190 190 191 188 191 190 190 188]\n",
      "Example prediction:\n",
      " 8 [210 210 210 209 209 208 210 207 209 209 209 206]\n",
      "Example prediction:\n",
      " 10 [213 213 213 212 211 211 213 209 212 211 212 209]\n",
      "Example prediction:\n",
      " 12 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Example prediction:\n",
      " 14 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Example prediction:\n",
      " 16 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Example prediction:\n",
      " 18 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Example prediction:\n",
      " 20 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Example prediction:\n",
      " 22 [214 214 214 213 212 212 214 210 213 212 213 210]\n",
      "Building 31 Eagle_health_Jodi\n",
      " Count bad values before pseudofill: 41\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_81 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_82 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_83 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [355 365 365 365 365 365 365 365 365 365 365 353]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 5ms/step - loss: 35332.9668\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 34022.7088\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 32027.2076\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 30934.2549\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 29053.7226\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 28119.1550\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 27468.5559\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25667.6975\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 24306.9196\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 23640.2071\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 22309.4681\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20998.1390\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 20110.3772\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 19290.1350\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 18311.2857\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17371.7954\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16518.7797\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15730.9377\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 14902.4115\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14119.9765\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 13197.7598\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12760.4462\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 12035.3580\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11501.1172\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 11001.3725\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 10366.9172\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 9817.9020\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9281.4975\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 8710.5827\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8242.3242\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 8149.7909\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 7609.3220\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 7347.1158\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6925.0283\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 6704.7810\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6297.8937\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6179.2927\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 5844.5806\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5328.6914\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5114.3438\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4824.2391\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4613.5375\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4332.9223\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4061.8559\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4041.3004\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 3806.8801\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3710.4945\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3587.8777\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3412.6519\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3432.5842\n",
      "mean,rmse,rmse/mean,bldg: 192.4223112628316 72.70813859251224 0.37785711082744167 Eagle_health_Jodi\n",
      "Example prediction:\n",
      " 0 [63 63 64 62 64 63 63 62 62 62 62 63]\n",
      "Example prediction:\n",
      " 2 [43 43 45 43 45 44 44 42 42 42 43 43]\n",
      "Example prediction:\n",
      " 4 [19 19 20 19 20 20 19 17 18 18 19 19]\n",
      "Example prediction:\n",
      " 6 [162 163 163 162 162 163 163 163 164 163 163 163]\n",
      "Example prediction:\n",
      " 8 [183 183 184 182 183 183 184 184 184 183 183 183]\n",
      "Example prediction:\n",
      " 10 [191 192 192 191 192 192 192 193 192 192 192 192]\n",
      "Example prediction:\n",
      " 12 [192 193 193 192 193 193 193 194 193 192 193 193]\n",
      "Example prediction:\n",
      " 14 [190 191 191 190 191 191 192 192 191 191 191 191]\n",
      "Example prediction:\n",
      " 16 [171 171 172 171 171 172 171 172 172 172 171 172]\n",
      "Example prediction:\n",
      " 18 [179 179 179 178 179 179 179 180 179 179 179 179]\n",
      "Example prediction:\n",
      " 20 [165 166 166 165 166 166 166 166 166 166 165 166]\n",
      "Example prediction:\n",
      " 22 [155 155 156 155 155 156 155 155 156 156 155 156]\n",
      "Building 32 Eagle_education_Norah\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_84 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_85 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_86 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [1834 1841 2051 2083 2227 2267 2373 2379 2382 2320 2133 2034]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 639194.4520\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 617087.1518\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 617404.2827\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 606883.8266\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 604821.6977\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 584034.0389\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 590509.5682\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 587820.4427\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 565894.4645\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 556560.2115\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 553584.0385\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 563551.9355\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 543682.5442\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 551602.8534\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 541390.0094\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 531403.6119\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 524824.7247\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 511727.2832\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 515959.6417\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 520955.8703\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 520653.4156\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 506900.7519\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 502512.4300\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 494107.4060\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 489143.0641\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 474163.8920\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 483718.2944\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 478602.1057\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 468123.3335\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 462875.2875\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 455095.4120\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 445974.1078\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 433930.0020\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 440323.9540\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 437486.0891\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 435601.6217\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 439366.9995\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 429535.5506\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 417553.4359\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 420382.7614\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 411332.7080\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 410401.3732\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 393860.5914\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 394342.7028\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 400184.7008\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 392713.5816\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 387570.5575\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 377580.9380\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 368026.6306\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 370139.5560\n",
      "mean,rmse,rmse/mean,bldg: 712.0113639930826 660.1639908298445 0.9271818178961793 Eagle_education_Norah\n",
      "Example prediction:\n",
      " 0 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 2 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 4 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 6 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 8 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 10 [227 227 227 226 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 12 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 14 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 16 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 18 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 20 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Example prediction:\n",
      " 22 [227 227 228 227 227 228 227 227 225 226 228 224]\n",
      "Building 33 Eagle_education_Will\n",
      " Count bad values before pseudofill: 15\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_87 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_88 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_89 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [440 418 442 391 383 361 362 370 360 362 363 373]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 77791.1664\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 75090.5260\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 72174.9556\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 69102.8830\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 66427.8325\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 64570.7335\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 63095.7001\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 61633.2306\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 58047.4704\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 56690.8386\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 54811.0431\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 52536.2853\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 51481.5320\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 49632.6721\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 47382.0758\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 45896.9762\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 44779.2938\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 42892.2447\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 41563.7746\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 40415.8976\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 38769.2460\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 36676.3698\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 36302.1651\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 34405.4502\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 33051.5532\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 31658.9024\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29894.5592\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 29618.9537\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 28199.2185\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26681.4453\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25668.6680\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 25122.3019\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23979.8952\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23389.9061\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 22029.4393\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 20973.3934\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 19313.7376\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 19281.5634\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 18033.7806\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17555.1423\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 16581.2281\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16341.2166\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15800.7776\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15069.9155\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14792.0983\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13250.3783\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13146.3969\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13039.9040\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 12138.4117\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 11847.1952\n",
      "mean,rmse,rmse/mean,bldg: 226.17039013254305 52.80726200165388 0.23348441840997464 Eagle_education_Will\n",
      "Example prediction:\n",
      " 0 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 2 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 4 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 6 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 8 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 10 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 12 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 14 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 16 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 18 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 20 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Example prediction:\n",
      " 22 [212 211 209 210 208 210 211 211 210 207 207 209]\n",
      "Building 34 Eagle_lodging_Blake\n",
      " Count bad values before pseudofill: 8\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_90 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_91 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_92 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [  8   8   8   8   8   8   8   8 296 296 297   6]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 31534.3544\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29766.9469\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29252.1812\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 30260.1757\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 28507.9663\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 28923.0229\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29012.5628\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 28504.2139\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27626.2950\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27051.7344\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27590.2693\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 26898.1921\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26546.2809\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26024.0909\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 26329.8877\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27532.2053\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 27159.1096\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26030.7662\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26138.1632\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26064.5414\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 26986.1442\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26375.4403\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 27126.5220\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26548.7759\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 24865.2356\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 27375.3855\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26937.9864\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26220.1369\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 26157.1627\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25888.8601\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25881.0919\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 26621.3249\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26090.9150\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25770.1395\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 25863.1041\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 25598.7467\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26491.1957\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26762.6925\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 26572.7687\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26317.1587\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 24638.2325\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25310.3997\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26118.0860\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 27430.3459\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26509.3798\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 27294.6417\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 25949.0359\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 25670.9856\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25304.2025\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26636.4408\n",
      "mean,rmse,rmse/mean,bldg: 43.43471997795112 27.51337475595995 0.6334419738385936 Eagle_lodging_Blake\n",
      "Example prediction:\n",
      " 0 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 2 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 4 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 6 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 8 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 10 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 12 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 14 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 16 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 18 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 20 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Example prediction:\n",
      " 22 [82 82 82 83 83 83 83 82 83 83 83 83]\n",
      "Building 35 Eagle_education_Petra\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_93 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_94 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_95 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [166 175 180 184 182 180 184 190 193 193 192 190]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 4341.8262\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3895.6540\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 3302.9685\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3004.0896\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2756.5333\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2413.0407\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 2156.7992\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1971.1359\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1832.5460\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1727.5338\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1596.3690\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1547.3079\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1520.7564\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1425.7538\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1391.8903\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1363.7367\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1370.2211\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1402.5972\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 1354.2047\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1372.2637\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1348.5585\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1366.0602\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1368.2757\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1280.3519\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 894.8614\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 825.4182\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 705.6257\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 647.4960\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 572.9804\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 544.6412\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 493.0806\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 468.2981\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 473.8832\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 451.2078\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 420.6933\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 408.2587\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 388.1908\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 376.0472\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 363.8835\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 348.5429\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 355.8913\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 339.7032\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 338.9463\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 331.9751\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 336.2353\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 326.9423\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 338.7661\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 331.8764\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 314.4461\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 322.7058\n",
      "mean,rmse,rmse/mean,bldg: 57.04381605290169 24.934361535766634 0.4371089324150901 Eagle_education_Petra\n",
      "Example prediction:\n",
      " 0 [72 72 72 71 72 72 72 72 72 72 72 72]\n",
      "Example prediction:\n",
      " 2 [56 56 56 56 56 56 56 56 56 56 56 56]\n",
      "Example prediction:\n",
      " 4 [49 49 49 49 49 49 48 49 49 49 49 49]\n",
      "Example prediction:\n",
      " 6 [46 46 46 46 45 45 45 46 46 46 46 46]\n",
      "Example prediction:\n",
      " 8 [49 49 49 49 49 49 49 49 49 49 49 49]\n",
      "Example prediction:\n",
      " 10 [49 48 49 48 49 49 48 48 49 49 48 49]\n",
      "Example prediction:\n",
      " 12 [56 56 57 56 57 56 56 56 57 57 56 57]\n",
      "Example prediction:\n",
      " 14 [78 78 78 78 78 78 78 78 78 78 78 78]\n",
      "Example prediction:\n",
      " 16 [96 96 96 96 96 96 96 96 96 96 96 95]\n",
      "Example prediction:\n",
      " 18 [93 94 94 94 94 94 94 94 94 93 93 93]\n",
      "Example prediction:\n",
      " 20 [78 79 78 78 79 78 78 79 78 78 78 78]\n",
      "Example prediction:\n",
      " 22 [69 68 68 68 68 68 68 69 68 68 68 68]\n",
      "Building 36 Eagle_lodging_Trina\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_96 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_97 (GRU)                 (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_98 (GRU)                 (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [316 317 318 331 326 327 320 325 335 365 381 365]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 13071.9490\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 12392.5571\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 11365.9029\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10753.0447\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10367.6545\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 9521.7124\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 8938.2106\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8565.0538\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8190.3381\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 7916.7395\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7384.7383\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 7053.2497\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 6947.6137\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 6516.4628\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6461.5763\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6135.6828\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5901.0239\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6016.0767\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5944.7654\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5713.7311\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5670.9458\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5795.3165\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5428.0873\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 5476.2465\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 5407.5032\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5315.5363\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5300.7260\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 5258.8603\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5409.7965\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 5394.7252\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5381.8029\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 4939.1080\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4533.6863\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4442.2356\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4216.4998\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 4285.6439\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4098.6491\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4042.1728\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3740.5969\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3689.1259\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3752.5909\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3595.1130\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3553.2128\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3553.4223\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3439.2534\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3489.9902\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3344.6256\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3280.1783\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3205.5491\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3107.3156\n",
      "mean,rmse,rmse/mean,bldg: 91.27234855584753 53.800900062903025 0.5894545381395927 Eagle_lodging_Trina\n",
      "Example prediction:\n",
      " 0 [75 74 74 74 74 74 74 73 75 74 74 75]\n",
      "Example prediction:\n",
      " 2 [68 67 67 67 67 67 67 66 67 67 66 68]\n",
      "Example prediction:\n",
      " 4 [59 58 58 59 58 59 58 58 59 58 58 59]\n",
      "Example prediction:\n",
      " 6 [57 56 56 56 56 56 56 55 56 56 56 57]\n",
      "Example prediction:\n",
      " 8 [61 60 61 60 60 60 61 60 60 60 61 61]\n",
      "Example prediction:\n",
      " 10 [74 74 74 74 74 74 74 74 74 73 74 74]\n",
      "Example prediction:\n",
      " 12 [85 85 85 84 85 84 85 85 84 84 85 84]\n",
      "Example prediction:\n",
      " 14 [115 115 115 114 115 115 115 115 115 114 114 114]\n",
      "Example prediction:\n",
      " 16 [139 140 139 139 140 140 139 140 139 139 138 138]\n",
      "Example prediction:\n",
      " 18 [150 151 150 151 151 151 150 150 150 150 149 149]\n",
      "Example prediction:\n",
      " 20 [148 149 148 149 149 149 148 149 148 148 147 147]\n",
      "Example prediction:\n",
      " 22 [143 144 143 143 144 144 143 143 143 143 142 142]\n",
      "Building 37 Eagle_health_Reuben\n",
      "Building 38 Eagle_education_Teresa\n",
      " Count bad values before pseudofill: 35\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_99 (GRU)                 (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_100 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_101 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [319 328 253 169 146 189 234 284 352 432 447 463]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 30725.9271\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 28984.9512\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27535.7878\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26337.9094\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25234.0712\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 24105.2247\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23208.7434\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 21913.9523\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 20402.5119\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 20335.6489\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18892.7948\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18020.0910\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17676.7047\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17044.3434\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16123.9173\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15116.1928\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14747.1529\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14184.3227\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13212.8776\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13336.1154\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12220.3856\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11953.5419\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11660.3381\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10914.3105\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10516.0520\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9951.0931\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9905.5320\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9555.0406\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8972.3564\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8989.6668\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8528.3575\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8413.1563\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7915.6848\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7486.0981\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7540.6562\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7236.2397\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7114.6538\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6777.6511\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6416.4510\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6289.4178\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5939.1013\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6130.3569\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5854.1577\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5362.5470\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5427.8742\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5127.7183\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5008.2800\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4891.5753\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4686.5514\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4833.9035\n",
      "mean,rmse,rmse/mean,bldg: 148.73384346526427 46.34517753076329 0.31159806302986365 Eagle_education_Teresa\n",
      "Example prediction:\n",
      " 0 [132 132 133 132 133 131 133 132 132 131 132 131]\n",
      "Example prediction:\n",
      " 2 [132 132 133 131 132 130 133 130 132 130 131 131]\n",
      "Example prediction:\n",
      " 4 [103 103 104 103 103 102 103 102 102 101 102 102]\n",
      "Example prediction:\n",
      " 6 [89 87 89 88 88 88 89 88 88 88 88 88]\n",
      "Example prediction:\n",
      " 8 [104 103 104 103 104 103 105 103 104 103 104 104]\n",
      "Example prediction:\n",
      " 10 [96 94 96 95 95 94 96 94 95 94 95 95]\n",
      "Example prediction:\n",
      " 12 [111 109 111 110 110 109 111 109 110 110 110 110]\n",
      "Example prediction:\n",
      " 14 [131 130 131 131 131 130 132 130 131 131 132 131]\n",
      "Example prediction:\n",
      " 16 [187 187 188 187 188 186 187 186 188 188 188 187]\n",
      "Example prediction:\n",
      " 18 [191 191 192 191 192 190 191 190 192 191 191 191]\n",
      "Example prediction:\n",
      " 20 [191 191 192 191 192 190 191 190 192 191 191 191]\n",
      "Example prediction:\n",
      " 22 [178 178 178 178 178 177 178 177 178 178 178 178]\n",
      "Building 39 Eagle_office_Norbert\n",
      " Count bad values before pseudofill: 52\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_102 (GRU)                (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_103 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_104 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [643 656 671 690 692 704 696 696 695 699 709 696]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 6s 7ms/step - loss: 152882.8255\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 146391.0540\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 144247.0526\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 140424.8975\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 138244.9224\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 131375.9403\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 132203.0288\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 127241.0772\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 127762.7274\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 120449.9778\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 120181.3018\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 116554.3308\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 112319.3546\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 111683.8925\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 108781.2529\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 105213.5196\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 103132.0814\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 101445.0134\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 98231.8459\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 96888.3456\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 95374.2123\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 90379.6822\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 88671.4443\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 87255.3386\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 84058.6491\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 81375.3110\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 79380.1056\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 78285.5759\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 76321.7260\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 74548.0398\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 71379.5037\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 69944.3801\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 66435.6257\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 67537.1113\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 65215.4195\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 62981.7529\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 58255.3131\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 58411.4811\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 56753.9359\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 55328.5672\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 53124.0044\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 51638.6213\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 50682.4577\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 48258.2811\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 46604.6790\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 45634.4054\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 44792.7823\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 43689.1303\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 42219.1388\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 39761.0503\n",
      "mean,rmse,rmse/mean,bldg: 390.8100632860704 228.3212149673783 0.5842255264554145 Eagle_office_Norbert\n",
      "Example prediction:\n",
      " 0 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 2 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 4 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 6 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 8 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 10 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 12 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 14 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 16 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 18 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 20 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Example prediction:\n",
      " 22 [221 221 222 220 220 221 220 221 221 222 222 219]\n",
      "Building 40 Eagle_lodging_Casey\n",
      "Building 41 Eagle_office_Tia\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_105 (GRU)                (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_106 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_107 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [417 393 372 281 208 166 153 304 405 493 436 388]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 49474.2318\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 49480.4877\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 45806.4078\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 44574.8209\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 43323.1734\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 41612.7563\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 40269.1353\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 39126.4648\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 37558.6250\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 35740.5222\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 34829.0079\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 33139.8492\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 33011.7429\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 30958.8516\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29846.8945\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 28695.9043\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27701.6713\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27174.2084\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25470.3051\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 24932.7235\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 24338.1748\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23230.6974\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 22567.1402\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 21241.2067\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 21137.0854\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 20238.9816\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 19297.7368\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18757.8167\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18157.0859\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18160.3675\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16698.1688\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16088.5542\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16209.9559\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15196.6801\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14920.6801\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14436.8969\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13613.0414\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13825.7977\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13558.2995\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13478.3917\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12933.9913\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12361.8789\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12192.8925\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12250.7204\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12149.6668\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11686.3334\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12058.5639\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11738.5365\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11630.1843\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11011.9173\n",
      "mean,rmse,rmse/mean,bldg: 174.6359145783468 83.18529792949293 0.47633557009359356 Eagle_office_Tia\n",
      "Example prediction:\n",
      " 0 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 2 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 4 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 6 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 8 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 10 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 12 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 14 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 16 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 18 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 20 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Example prediction:\n",
      " 22 [190 190 190 190 191 190 191 191 191 191 190 191]\n",
      "Building 42 Eagle_office_Remedios\n",
      " Count bad values before pseudofill: 17\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_108 (GRU)                (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_109 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_110 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [192 211 225 238 238 238 244 240 234 229 232 236]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 14228.8242\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13026.3821\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12049.2724\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11382.7026\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10489.7889\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9677.0874\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8981.0370\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8262.1463\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7677.4508\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7077.3257\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6516.4350\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6040.2104\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5459.9365\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5127.3706\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4702.1378\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4318.9211\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4015.7546\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3678.6292\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3431.1471\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3137.7964\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2928.9372\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2658.3605\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2498.9858\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2374.7362\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2225.1704\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2095.9566\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1998.4903\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1958.4415\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1928.3169\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1897.2334\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1848.0894\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1866.9132\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1794.6078\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1812.2878\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1812.7599\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1816.4932\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1767.5310\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1746.9991\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1793.0886\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1760.8353\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1810.6957\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1763.7375\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1734.2382\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1805.0739\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1750.7814\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1784.9601\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1794.0030\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1778.7602\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1761.1553\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1754.7141\n",
      "mean,rmse,rmse/mean,bldg: 121.48132139556034 37.32343424266942 0.30723599162326404 Eagle_office_Remedios\n",
      "Example prediction:\n",
      " 0 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 2 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 4 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 6 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 8 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 10 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 12 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 14 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 16 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 18 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 20 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Example prediction:\n",
      " 22 [116 116 116 116 116 116 116 116 116 116 116 116]\n",
      "Building 43 Eagle_office_Patrice\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_111 (GRU)                (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_112 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_113 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [498 460 394 367 320 292 239 212 212 221 295 459]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 32809.7948\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 32196.9938\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 30975.6783\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29281.2950\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 29284.5178\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27783.0917\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 27815.4892\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 25979.7899\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 26187.8902\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23962.4070\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 23916.8920\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 22393.4889\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 22006.9412\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 20843.5081\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 21490.1401\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 20087.8983\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 19021.6986\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 18163.2566\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17502.6714\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 17419.8555\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 16613.0022\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15175.4779\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 15195.3646\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14309.6411\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13658.5911\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 14576.0706\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 13420.5245\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12924.4490\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12697.9620\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11851.9560\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11595.2344\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11693.3155\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11376.6891\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11028.4222\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10725.6767\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10745.6478\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10147.6677\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9929.4738\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9512.1391\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8758.9764\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8484.9023\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9342.3282\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9033.9014\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9144.8870\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8185.3104\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8230.4278\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9172.9449\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8415.7615\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8525.5741\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8919.4157\n",
      "mean,rmse,rmse/mean,bldg: 165.87984746703071 101.96259689850395 0.6146774213713297 Eagle_office_Patrice\n",
      "Example prediction:\n",
      " 0 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 2 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 4 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 6 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 8 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 10 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 12 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 14 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 16 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 18 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 20 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Example prediction:\n",
      " 22 [185 185 185 184 185 185 185 186 185 185 184 185]\n",
      "Building 44 Eagle_education_Shana\n",
      " Count bad values before pseudofill: 2\n",
      " Count bad values after pseudofill: 0\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_114 (GRU)                (None, 12, 16)            912       \n",
      "_________________________________________________________________\n",
      "gru_115 (GRU)                (None, 12, 16)            1632      \n",
      "_________________________________________________________________\n",
      "gru_116 (GRU)                (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 12)                204       \n",
      "=================================================================\n",
      "Total params: 4,380\n",
      "Trainable params: 4,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example y train:\n",
      " [182 182 182 183 183 183 183 183 183 183 182 181]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 6ms/step - loss: 13155.9033\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 12068.4612\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 11320.7845\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 10248.9910\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 9397.7039\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8776.0100\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 8180.5905\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 7567.3499\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6917.4956\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 6433.3747\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5810.4448\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 5362.6414\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4915.8076\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4460.8381\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 4234.5694\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3778.2105\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3391.9684\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 3155.1177\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2940.2754\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2617.1226\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2521.2627\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2304.8744\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 2130.7349\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1944.5104\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1875.2308\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1773.7419\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1727.0918\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1605.3728\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1617.3780\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1577.8530\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1568.2516\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1540.6110\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1543.3564\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1514.3083\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1495.8194\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1491.6389\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1503.9663\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1480.6330\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1493.6411\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1515.5909\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1533.7065\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1479.3162\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1498.9942\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1497.2562\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1495.4558\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1495.3300\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1545.9118\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1515.0424\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1536.5026\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 6ms/step - loss: 1526.8356\n",
      "mean,rmse,rmse/mean,bldg: 103.18172944172048 36.39369513059908 0.35271452928258107 Eagle_education_Shana\n",
      "Example prediction:\n",
      " 0 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 2 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 4 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 6 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 8 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 10 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 12 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 14 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 16 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 18 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 20 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "Example prediction:\n",
      " 22 [113 113 113 113 113 113 113 113 113 113 113 113]\n",
      "\n",
      "History 24 Future 12\n",
      "Column 1: Mean usage.\n",
      "Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 3: RMSE/mean normalized to help understand RMSE.\n",
      "Column 4: Building.\n",
      "      0.00       0.00   nan   Eagle_office_Henriette\n",
      "      0.11       0.02  0.22   Eagle_education_Wesley\n",
      "     15.76       5.74  0.36   Eagle_education_Jewell\n",
      "     35.89       7.83  0.22   Eagle_office_Mandi\n",
      "     36.93       6.52  0.18   Eagle_office_Lamont\n",
      "     43.43      27.51  0.63   Eagle_lodging_Blake\n",
      "     46.46      20.77  0.45   Eagle_education_Eileen\n",
      "     56.50      50.32  0.89   Eagle_office_Dallas\n",
      "     57.04      24.93  0.44   Eagle_education_Petra\n",
      "     62.02      41.86  0.67   Eagle_office_Sheree\n",
      "     81.96      46.12  0.56   Eagle_lodging_Edgardo\n",
      "     87.21      19.17  0.22   Eagle_office_Phyllis\n",
      "     91.27      53.80  0.59   Eagle_lodging_Trina\n",
      "     92.81      42.07  0.45   Eagle_lodging_Dawn\n",
      "    101.56      45.75  0.45   Eagle_office_Freida\n",
      "    103.18      36.39  0.35   Eagle_education_Shana\n",
      "    121.48      37.32  0.31   Eagle_office_Remedios\n",
      "    122.36      46.97  0.38   Eagle_health_Vincenza\n",
      "    148.73      46.35  0.31   Eagle_education_Teresa\n",
      "    165.88     101.96  0.61   Eagle_office_Patrice\n",
      "    174.64      83.19  0.48   Eagle_office_Tia\n",
      "    182.06      76.87  0.42   Eagle_public_Alvin\n",
      "    192.42      72.71  0.38   Eagle_health_Jodi\n",
      "    226.17      52.81  0.23   Eagle_education_Will\n",
      "    273.02     122.24  0.45   Eagle_office_Nereida\n",
      "    276.27     175.21  0.63   Eagle_food_Kay\n",
      "    336.49     205.40  0.61   Eagle_office_Francis\n",
      "    390.81     228.32  0.58   Eagle_office_Norbert\n",
      "    477.67     314.05  0.66   Eagle_health_Athena\n",
      "    659.51     759.76  1.15   Eagle_health_Gregoria\n",
      "    694.96     522.01  0.75   Eagle_education_Alberto\n",
      "    712.01     660.16  0.93   Eagle_education_Norah\n",
      "   1003.99    1860.69  1.85   Eagle_education_Shante\n",
      "   1037.64     933.80  0.90   Eagle_office_Chauncey\n",
      "   1084.43     923.95  0.85   Eagle_health_Reba\n",
      "   1199.38    1069.50  0.89   Eagle_education_Roman\n",
      "   1639.36    1632.66  1.00   Eagle_education_Brooke\n",
      "   2032.48    2073.98  1.02   Eagle_education_Sherrill\n",
      "   3154.83    3032.57  0.96   Eagle_education_Peter\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "one_site_weather = load_weather_for_site(SITE)\n",
    "num_processed = 0\n",
    "for BLDG in SITE_BUILDINGS:\n",
    "    print(\"Building\",num_processed,BLDG)\n",
    "    num_processed += 1\n",
    "    one_bldg_meter = load_meter_for_building(BLDG,SMOOTHING_WINDOW)\n",
    "    count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
    "    MAX_BAD = 500\n",
    "    if count_bad<=MAX_BAD:\n",
    "        # Must get rid of Nan labels, else loss hits NaN during training.\n",
    "        print(\" Count bad values before pseudofill:\",count_bad)\n",
    "        pseudovalue = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
    "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
    "        count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
    "        print(\" Count bad values after pseudofill:\",count_bad)\n",
    "        # Smoothed\n",
    "        X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
    "        split = len(X)//2   # year 1 vs year 2\n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        # Not smoothed\n",
    "        unsmoothed = load_meter_for_building(BLDG,0)\n",
    "        unsmoothed = unsmoothed.fillna(pseudovalue)\n",
    "        X_raw,y_raw = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
    "        y_test = np.asarray(y_raw[split:])\n",
    "        #\n",
    "        model = make_RNN()\n",
    "        print(model.summary())\n",
    "        #print(\"Example X train:\\n\",X_train[example].astype(int))\n",
    "        example=411\n",
    "        print(\"Example y train:\\n\",y_train[example].astype(int))\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        # Keep a table for reporting later.\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        mean = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
    "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"mean,rmse,rmse/mean,bldg:\",mean,rmse,rmse/mean,BLDG)\n",
    "        for hr in range(0,24,2):\n",
    "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))\n",
    "print()\n",
    "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "print(\"Column 1: Mean usage.\")\n",
    "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
    "print(\"Column 4: Building.\")\n",
    "for cor in sorted(cors):\n",
    "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm8eEJdHbz9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY4snIvJbz9z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_222.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
