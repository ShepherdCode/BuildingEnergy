{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN_229.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNRPftWw9pK"
      },
      "source": [
        "# RNN \n",
        "Test effect of scaling on RNN. Compare to RNN 227.\n",
        "\n",
        "Input weather + time, output steam. Given 12 hour, predict same 12 hr next day. With smoothing, window 3.\n",
        "\n",
        "With standard scaler on inputs. RMSE/mean = 0.83. Not great."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5deM-us2w9pZ"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredError\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZgkgsP6w9pg",
        "outputId": "96eb5bbe-e7d1-4434-b8b0-47cb4f53621a"
      },
      "source": [
        "# Constants\n",
        "EPOCHS=50  # use 5 for software testing, 50 for model testing\n",
        "SITE = 'Eagle'\n",
        "PREDICTORS = ['hour','month','doy','meter','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
        "PREDICTORS = ['hour','month','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
        "NUM_PREDICTORS=len(PREDICTORS)\n",
        "print(\"PREDICTORS=\",NUM_PREDICTORS,PREDICTORS)\n",
        "PREDICTED_VARIABLE = 'meter'  \n",
        "STEPS_HISTORY = 24\n",
        "STEPS_FORWARD = 12 \n",
        "STEPS_FUTURE =  12 \n",
        "METER_FILE='steam.csv'\n",
        "WEATHER_FILE='weather.csv'\n",
        "EXAMPLE='Eagle_lodging_Edgardo'\n",
        "SITE_BUILDINGS = None\n",
        "SMOOTHING_WINDOW=3\n",
        "SCALING=1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTORS= 10 ['hour', 'month', 'cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeDotTmw9pX",
        "outputId": "c3b543a2-3281-4763-cf1f-5ca07aacb6df"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvXGAH2wzBWS"
      },
      "source": [
        "def scale(df):\n",
        "    scaler=StandardScaler()\n",
        "    #scaler=MinMaxScaler()\n",
        "    scaled=scaler.fit_transform(df.values)\n",
        "    scaled = pd.DataFrame(scaled,index=df.index,columns=df.columns)\n",
        "    return scaled"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdk510Cw9pc"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "6YVYM_bqw9pi",
        "outputId": "52d4e05b-dfd0-44c9-af94-1f353945aaef"
      },
      "source": [
        "DATE_PARSE=True  # must be true if we use one of these as predictor\n",
        "def load_weather_for_site(site):\n",
        "    wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
        "    wet_df = fix_date_type(wet_df)\n",
        "    site_df = wet_df.loc[wet_df['site_id'] == site]\n",
        "    # Drop the site, which is constant (we selected for one site).\n",
        "    site_df = site_df.drop(['site_id'],axis=1)\n",
        "    if DATE_PARSE:\n",
        "        site_df.insert(0,'hour',0)\n",
        "        site_df.insert(1,'month',0)\n",
        "        site_df.insert(2,'doy',0)\n",
        "        L=len(site_df)\n",
        "        for i in range(0,L):\n",
        "            dt=site_df.index[i]\n",
        "            hour=dt.hour\n",
        "            month=dt.month\n",
        "            doy=dt.dayofyear\n",
        "            site_df.iat[i,0] = hour\n",
        "            site_df.iat[i,1] = month\n",
        "            site_df.iat[i,2] = doy\n",
        "    if SCALING==1:\n",
        "        site_df = scale(site_df) # could break if any column is empty\n",
        "    return site_df\n",
        "\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "one_site_weather.tail()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>doy</th>\n",
              "      <th>airTemperature</th>\n",
              "      <th>cloudCoverage</th>\n",
              "      <th>dewTemperature</th>\n",
              "      <th>precipDepth1HR</th>\n",
              "      <th>precipDepth6HR</th>\n",
              "      <th>seaLvlPressure</th>\n",
              "      <th>windDirection</th>\n",
              "      <th>windSpeed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 18:00:00</th>\n",
              "      <td>0.938811</td>\n",
              "      <td>1.588662</td>\n",
              "      <td>1.722611</td>\n",
              "      <td>-2.403469</td>\n",
              "      <td>-0.399371</td>\n",
              "      <td>-2.519146</td>\n",
              "      <td>-0.125044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.317034</td>\n",
              "      <td>1.172113</td>\n",
              "      <td>-0.231861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>1.227759</td>\n",
              "      <td>1.588662</td>\n",
              "      <td>1.722611</td>\n",
              "      <td>-2.512407</td>\n",
              "      <td>-0.399371</td>\n",
              "      <td>-2.566121</td>\n",
              "      <td>-0.125044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.422443</td>\n",
              "      <td>1.090560</td>\n",
              "      <td>-0.764679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>1.372234</td>\n",
              "      <td>1.588662</td>\n",
              "      <td>1.722611</td>\n",
              "      <td>-2.571828</td>\n",
              "      <td>-0.399371</td>\n",
              "      <td>-2.566121</td>\n",
              "      <td>-0.125044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.448795</td>\n",
              "      <td>1.009007</td>\n",
              "      <td>-0.231861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>1.516708</td>\n",
              "      <td>1.588662</td>\n",
              "      <td>1.722611</td>\n",
              "      <td>-2.571828</td>\n",
              "      <td>-0.399371</td>\n",
              "      <td>-2.519146</td>\n",
              "      <td>-0.125044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.475147</td>\n",
              "      <td>1.172113</td>\n",
              "      <td>0.010328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>1.661182</td>\n",
              "      <td>1.588662</td>\n",
              "      <td>1.722611</td>\n",
              "      <td>-2.571828</td>\n",
              "      <td>-0.399371</td>\n",
              "      <td>-2.519146</td>\n",
              "      <td>-0.125044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.475147</td>\n",
              "      <td>1.090560</td>\n",
              "      <td>0.736897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         hour     month  ...  windDirection  windSpeed\n",
              "timestamp                                ...                          \n",
              "2017-12-31 18:00:00  0.938811  1.588662  ...       1.172113  -0.231861\n",
              "2017-12-31 20:00:00  1.227759  1.588662  ...       1.090560  -0.764679\n",
              "2017-12-31 21:00:00  1.372234  1.588662  ...       1.009007  -0.231861\n",
              "2017-12-31 22:00:00  1.516708  1.588662  ...       1.172113   0.010328\n",
              "2017-12-31 23:00:00  1.661182  1.588662  ...       1.090560   0.736897\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "s-EKuCBibz9d",
        "outputId": "2ac052da-c665-4bdf-d5f8-fa881d5eae45"
      },
      "source": [
        "def load_meter_for_building(bldg,smooth=0):\n",
        "    all_df = read_zip_to_panda(ZIP_PATH,METER_FILE)\n",
        "    all_df = fix_date_type(all_df)\n",
        "    global SITE_BUILDINGS\n",
        "    SITE_BUILDINGS = [x for x in all_df.columns if x.startswith(SITE)]\n",
        "    site_series = all_df[bldg]\n",
        "    site_df = site_series.to_frame()\n",
        "    #site_df = all_df.loc[all_df['site_id'] == site]\n",
        "    # Change column name from building name to meter.\n",
        "    site_df = site_df.rename(columns={bldg : PREDICTED_VARIABLE})\n",
        "    if smooth>0:\n",
        "        site_df = site_df.rolling(smooth).mean()\n",
        "    return site_df\n",
        "\n",
        "one_bldg_meter = load_meter_for_building(EXAMPLE)\n",
        "print(type(one_bldg_meter))\n",
        "one_bldg_meter.tail()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meter</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 19:00:00</th>\n",
              "      <td>92.2957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>277.5584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>280.5331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>289.3302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>164.3474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        meter\n",
              "timestamp                    \n",
              "2017-12-31 19:00:00   92.2957\n",
              "2017-12-31 20:00:00  277.5584\n",
              "2017-12-31 21:00:00  280.5331\n",
              "2017-12-31 22:00:00  289.3302\n",
              "2017-12-31 23:00:00  164.3474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynRgLt9w9pk",
        "outputId": "eeee07ad-dd6a-49a7-8d71-146fee080c0a"
      },
      "source": [
        "def prepare_for_learning(wdf,mdf):\n",
        "    # Concatenate weather and meter.\n",
        "    df = pd.concat([wdf,mdf],axis=1)\n",
        "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
        "    X_shape = (num_samples,STEPS_FUTURE,NUM_PREDICTORS)\n",
        "    Y_shape = (num_samples,STEPS_FUTURE)\n",
        "    X=np.zeros(X_shape)\n",
        "    y=np.zeros(Y_shape)\n",
        "    predictor_series = df[PREDICTORS].values  # selected features\n",
        "    predicted_series = df[PREDICTED_VARIABLE].values  # meter\n",
        "    # TO DO: can we take predicted from mdf instead?\n",
        "    for sam in range (0,num_samples): \n",
        "        prev_val = 0\n",
        "        one_sample = predictor_series[sam:sam+STEPS_FORWARD]\n",
        "        for time in range (0,STEPS_FORWARD): \n",
        "            one_period = one_sample[time]\n",
        "            for feat in range (0,NUM_PREDICTORS):\n",
        "                val = one_period[feat]\n",
        "                if np.isnan(val):\n",
        "                    val = prev_val\n",
        "                else:\n",
        "                    prev_val = val\n",
        "                X[sam,time,feat] = val\n",
        "        for time in range (0,STEPS_FUTURE):  \n",
        "            y[sam,time]=predicted_series[sam+STEPS_HISTORY+time]\n",
        "    return X,y \n",
        "print(one_bldg_meter.head())\n",
        "X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "print(\"X shape:\",X.shape)\n",
        "print(\"y shape:\",y.shape)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       meter\n",
            "timestamp                   \n",
            "2016-01-01 00:00:00  31.7661\n",
            "2016-01-01 01:00:00  27.4004\n",
            "2016-01-01 02:00:00  38.4989\n",
            "2016-01-01 03:00:00  59.1697\n",
            "2016-01-01 04:00:00  39.9556\n",
            "X shape: (17508, 12, 10)\n",
            "y shape: (17508, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mObWmpMDVuNQ",
        "outputId": "832fe55a-6a37-43b1-a147-109bc910b424"
      },
      "source": [
        "print(\"X columns:\",PREDICTORS)\n",
        "print(\"X example:\\n\",X[100].astype(int))\n",
        "print(\"y example:\\n\",y[100].astype(int))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X columns: ['hour', 'month', 'cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
            "X example:\n",
            " [[-1 -1  0 -2 -2  0  0  2  1  1]\n",
            " [ 0 -1  0 -2 -2  0  0  2  1  1]\n",
            " [ 0 -1  0 -2 -2  0  0  2 -1  1]\n",
            " [ 0 -1  0 -2 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -2 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -2 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -2 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -1 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -1 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -1 -2  0  0  2  1  0]\n",
            " [ 0 -1 -1 -1 -2  0  0  2  1  0]\n",
            " [ 0 -1  0 -1 -2  0  0  2  1  0]]\n",
            "y example:\n",
            " [ 43 119 327 322 273  92 328 363 346 168 266  27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8rzumTw9p2"
      },
      "source": [
        "def make_RNN():\n",
        "    # The GRU in Keras is optimized for speed on CoLab GPU.\n",
        "    rnn = Sequential([\n",
        "        GRU(16,return_sequences=True, \n",
        "                  input_shape=(STEPS_FORWARD,NUM_PREDICTORS)), \n",
        "        GRU(16,return_sequences=True),\n",
        "        GRU(16,return_sequences=False),\n",
        "        Dense(STEPS_FUTURE)\n",
        "    ])\n",
        "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
        "    return rnn"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypnRqq9w9p4",
        "scrolled": false,
        "outputId": "3dd69178-b934-4515-8412-04c4da58dc8a"
      },
      "source": [
        "cors = []\n",
        "overall = 0\n",
        "cnt = 0\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "for BLDG in SITE_BUILDINGS:\n",
        "    print(\"Building\",BLDG)\n",
        "    one_bldg_meter = load_meter_for_building(BLDG,SMOOTHING_WINDOW)\n",
        "    count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "    MAX_BAD = 500\n",
        "    if count_bad<=MAX_BAD:\n",
        "        # Must get rid of Nan labels, else loss hits NaN during training.\n",
        "        print(\" Count bad values before pseudofill:\",count_bad)\n",
        "        pseudovalue = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
        "        count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "        print(\" Count bad values after pseudofill:\",count_bad)\n",
        "        # Smoothing window applies to inputs\n",
        "        X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "        split = len(X)//2   # year 1 vs year 2\n",
        "        X_train = np.asarray(X[0:split])\n",
        "        y_train = np.asarray(y[0:split])\n",
        "        X_test = np.asarray(X[split:])\n",
        "        # Smoothing does not apply to truth\n",
        "        one_bldg_meter = load_meter_for_building(BLDG,0)\n",
        "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
        "        X_raw,y_raw = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "        y_test = np.asarray(y_raw[split:])\n",
        "        # Train and predict\n",
        "        model = make_RNN()\n",
        "        print(model.summary())\n",
        "        example=411\n",
        "        print(\"Example y train:\\n\",y_train[example].astype(int))\n",
        "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Reporting\n",
        "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
        "        mean = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
        "        cnt += 1\n",
        "        print(\"i,mean,rmse,rmse/mean,bldg:\",cnt,mean,rmse,rmse/mean,BLDG)\n",
        "        overall += overall\n",
        "        for hr in range(0,24,2):\n",
        "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))\n",
        "print()\n",
        "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
        "print(\"Column 1: Mean usage.\")\n",
        "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
        "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
        "print(\"Column 4: Building.\")\n",
        "for cor in sorted(cors):\n",
        "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))  \n",
        "print (\"overall = \",overall)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_123 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_124 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_125 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [58 64 68 72 72 72 74 73 71 69 70 71]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 4s 5ms/step - loss: 1239.7105\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 905.5526\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 697.8844\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 545.4374\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 432.2829\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 353.2650\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 309.3292\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 270.5739\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 248.7876\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 243.3248\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 238.2881\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 232.1911\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 228.7953\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 222.1246\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 159.1460\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 110.2486\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 95.0329\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 76.7811\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 71.6424\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 61.8329\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 59.1869\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 52.5903\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 49.9778\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47.8546\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 45.8052\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44.2096\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47.7553\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 42.4714\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 40.7961\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 40.8921\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 39.1294\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.6306\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.2766\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.8325\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.9197\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 38.1613\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 35.5186\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 35.9587\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.8447\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.0065\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.1535\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.9480\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 33.9762\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.6401\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.5080\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.1808\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.8731\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29.0460\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.2793\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30.4943\n",
            "i,mean,rmse,rmse/mean,bldg: 1 36.92671326723864 21.612782831290783 0.5852885599343506 Eagle_office_Lamont\n",
            "Example prediction:\n",
            " 0 [40 40 40 40 40 40 40 41 41 41 41 41]\n",
            "Example prediction:\n",
            " 2 [41 41 41 41 41 41 41 41 42 42 42 42]\n",
            "Example prediction:\n",
            " 4 [41 41 41 41 41 41 41 41 42 42 42 42]\n",
            "Example prediction:\n",
            " 6 [40 40 40 40 40 40 40 40 41 41 41 41]\n",
            "Example prediction:\n",
            " 8 [42 42 42 42 42 42 42 42 42 42 42 42]\n",
            "Example prediction:\n",
            " 10 [43 43 43 43 43 43 43 43 43 43 43 43]\n",
            "Example prediction:\n",
            " 12 [44 44 43 43 44 44 44 44 44 44 44 44]\n",
            "Example prediction:\n",
            " 14 [43 43 43 43 43 43 43 43 43 44 44 43]\n",
            "Example prediction:\n",
            " 16 [42 41 41 41 41 41 42 42 42 42 42 42]\n",
            "Example prediction:\n",
            " 18 [39 39 39 38 38 39 39 39 39 39 39 39]\n",
            "Example prediction:\n",
            " 20 [39 38 38 38 38 38 38 38 39 39 39 39]\n",
            "Example prediction:\n",
            " 22 [41 41 40 40 40 41 41 41 41 41 41 41]\n",
            "Building Eagle_health_Athena\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_126 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_127 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_128 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1341 1348 1320 1187 1052  960  834  819  801  999 1154 1250]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 351238.8265\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 347233.0205\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 340338.5606\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 339015.1140\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 333678.5045\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 332080.1968\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 322279.7854\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 317964.7228\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 313214.6973\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 305234.3671\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 305495.9372\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 300491.1842\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 294744.5323\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 289230.2145\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 279564.1628\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 286041.5433\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 275314.8164\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 271384.3886\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 274770.3391\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 264696.2153\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 268075.5784\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 257290.0359\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 258758.9135\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 251143.9751\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 246354.7814\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 237902.5377\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 242858.2462\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 233351.8130\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 231972.6281\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 233047.6945\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 228367.4818\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 219600.7952\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 211043.0436\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 217384.6076\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 207323.4137\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 209505.6703\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 205810.5890\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 200659.4531\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 196684.8603\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 200577.5407\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 188173.9354\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 188565.5922\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 189482.3013\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 184892.7296\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 178882.1144\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 178147.0376\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 175048.4206\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 171711.7448\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 167620.0928\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 165533.0035\n",
            "i,mean,rmse,rmse/mean,bldg: 2 477.70168061445776 325.41807369391466 0.6812160955250066 Eagle_health_Athena\n",
            "Example prediction:\n",
            " 0 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 2 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 4 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 6 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 8 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 10 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 12 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 14 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 16 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 18 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 20 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Example prediction:\n",
            " 22 [225 225 227 225 226 224 224 225 225 227 224 226]\n",
            "Building Eagle_assembly_Herbert\n",
            "Building Eagle_public_Alvin\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_129 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_130 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_131 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [560 549 468 422 314 298 296 434 517 515 470 450]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 57561.8629\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 53295.8065\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 51895.4903\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 49406.2147\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47982.5103\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 46917.2416\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44639.2150\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 43679.4256\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 41741.4660\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 40653.0404\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39192.8940\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37870.2903\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 35112.5293\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34802.3065\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34041.7897\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31951.7292\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30607.9175\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 30230.7332\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 29120.4156\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28302.4111\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 27236.0424\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 26224.8646\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25965.2803\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 23920.3620\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 24050.8518\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 23150.4962\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 21268.7275\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 20847.1574\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 20241.5865\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 19587.4236\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 19349.1775\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 18344.2813\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 18022.5241\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 17481.9228\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16675.5166\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16286.9375\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16002.0729\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 16166.3615\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15757.4950\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 15060.3238\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14727.3146\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14641.3295\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14281.8395\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 14256.6839\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13847.9871\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13903.4553\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13526.9929\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13217.5298\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12957.3540\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12929.5629\n",
            "i,mean,rmse,rmse/mean,bldg: 3 182.08293646830808 78.75876409638272 0.4325433542757635 Eagle_public_Alvin\n",
            "Example prediction:\n",
            " 0 [193 192 193 193 193 192 194 194 193 192 193 193]\n",
            "Example prediction:\n",
            " 2 [193 191 193 193 192 192 193 193 192 191 192 192]\n",
            "Example prediction:\n",
            " 4 [192 190 191 191 191 190 192 192 191 190 191 191]\n",
            "Example prediction:\n",
            " 6 [191 190 191 191 191 190 192 192 191 190 191 191]\n",
            "Example prediction:\n",
            " 8 [192 190 192 192 192 191 192 192 192 190 192 191]\n",
            "Example prediction:\n",
            " 10 [192 191 192 192 192 191 193 193 192 191 192 192]\n",
            "Example prediction:\n",
            " 12 [193 191 193 193 193 192 193 193 193 191 192 192]\n",
            "Example prediction:\n",
            " 14 [193 192 193 193 193 192 194 194 193 192 193 193]\n",
            "Example prediction:\n",
            " 16 [193 192 193 193 193 192 194 194 193 192 193 193]\n",
            "Example prediction:\n",
            " 18 [193 192 193 193 193 192 194 193 193 192 193 193]\n",
            "Example prediction:\n",
            " 20 [192 191 192 192 192 191 193 193 192 191 192 192]\n",
            "Example prediction:\n",
            " 22 [192 190 192 192 191 191 192 192 191 190 191 191]\n",
            "Building Eagle_education_Raul\n",
            "Building Eagle_education_Roman\n",
            " Count bad values before pseudofill: 35\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_132 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_133 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_134 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [2589 2505 2475 2437 2673 2987 3111 2693 2817 3019 3655 3750]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1738746.3205\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1697081.4568\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1645851.8591\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1674104.8086\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1672147.4636\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1669798.6200\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1649243.1355\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1633870.4318\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1650556.2586\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1604333.0673\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1568700.6427\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1606154.7550\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1600540.9723\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1532767.0355\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1557317.8400\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1555005.8005\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1524330.6086\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1528962.3905\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1497874.7377\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1498259.0559\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1500474.3218\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1479310.0782\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1490344.9382\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1471559.8577\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1482338.8864\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1457426.8200\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1422371.6909\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1411077.2695\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1390690.5759\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1378252.3614\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1377167.3859\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1375921.9995\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1369966.9577\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1380357.8395\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1318427.3427\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1336097.2023\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1356727.5877\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1340339.0255\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1311012.2441\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1304819.5314\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1309724.0559\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1276666.9209\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1269587.8309\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1268923.1405\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1252437.8895\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1226650.0948\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1236243.4027\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1231088.0755\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1246605.9384\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1227650.0418\n",
            "i,mean,rmse,rmse/mean,bldg: 4 1199.4083427425896 1084.566927344075 0.9042516119773555 Eagle_education_Roman\n",
            "Example prediction:\n",
            " 0 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 2 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 4 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 6 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 8 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 10 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 12 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 14 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 16 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 18 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 20 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Example prediction:\n",
            " 22 [234 230 230 232 230 231 232 230 230 232 231 231]\n",
            "Building Eagle_office_Mandi\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_135 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_136 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_137 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [63 63 63 63 63 63 63 63 63 63 63 63]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1511.5949\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1126.6806\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 895.4296\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 707.4071\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 568.6010\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 481.5875\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 402.1372\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 343.3368\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 308.5945\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 294.5931\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 275.5631\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 270.7008\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 270.7337\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 267.0933\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 260.8445\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 254.6999\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 166.6344\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 124.4934\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 102.7185\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 85.5159\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 73.4238\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 66.0022\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 61.0497\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 54.7183\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 51.0488\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 47.9542\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 44.5047\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 41.1015\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 42.4386\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 39.9722\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 40.5305\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.8849\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 38.3247\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 37.8339\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 34.9501\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.8573\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.7033\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.1847\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.4966\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 32.8737\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 33.6436\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 31.0083\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 27.9757\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28.8428\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 28.3266\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25.5792\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 26.4799\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 25.9114\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 24.7529\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 26.7129\n",
            "i,mean,rmse,rmse/mean,bldg: 5 35.89375163018761 15.909058133308912 0.4432263948672606 Eagle_office_Mandi\n",
            "Example prediction:\n",
            " 0 [54 54 54 54 54 54 54 54 54 54 54 54]\n",
            "Example prediction:\n",
            " 2 [54 54 54 54 54 55 54 54 54 54 54 54]\n",
            "Example prediction:\n",
            " 4 [52 52 52 52 52 52 52 52 52 52 52 52]\n",
            "Example prediction:\n",
            " 6 [50 50 50 49 49 49 50 49 50 49 49 49]\n",
            "Example prediction:\n",
            " 8 [47 47 47 47 46 46 47 46 47 46 46 46]\n",
            "Example prediction:\n",
            " 10 [47 47 47 47 47 47 47 46 47 46 47 46]\n",
            "Example prediction:\n",
            " 12 [42 42 42 42 42 42 42 42 42 42 42 42]\n",
            "Example prediction:\n",
            " 14 [41 41 41 41 41 41 41 41 41 41 41 41]\n",
            "Example prediction:\n",
            " 16 [43 43 43 43 43 43 43 42 43 42 43 43]\n",
            "Example prediction:\n",
            " 18 [46 46 46 46 46 46 46 46 46 46 46 46]\n",
            "Example prediction:\n",
            " 20 [55 55 55 56 56 56 55 55 55 55 55 55]\n",
            "Example prediction:\n",
            " 22 [59 59 59 60 60 60 59 59 59 59 59 59]\n",
            "Building Eagle_education_Jewell\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_138 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_139 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_140 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [223 207 206 207 205 205 196 203 210 217 222 222]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 4071.3582\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3994.5965\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3613.6949\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3526.4451\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3193.1461\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3154.2993\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2939.2236\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2774.5749\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2780.8271\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2603.4313\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2499.0969\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2345.1463\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2172.6589\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2156.3008\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1964.3800\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1930.8237\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1881.8295\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1714.2580\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1654.4104\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1529.2826\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1424.0609\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1385.7507\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1384.0616\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1251.1579\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1167.7567\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1162.0756\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1123.7134\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1040.1828\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 997.8719\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 932.4569\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 933.8051\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 898.8058\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 839.9044\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 802.0523\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 774.1257\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 746.9693\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 672.7195\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 667.7874\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 615.0848\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 594.8094\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 579.1747\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 571.9969\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 523.9394\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 502.7097\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 510.6364\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 496.5502\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 466.0402\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 490.8250\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 459.9113\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 430.5150\n",
            "i,mean,rmse,rmse/mean,bldg: 6 15.763073324212357 54.40102654975718 3.451168781039434 Eagle_education_Jewell\n",
            "Example prediction:\n",
            " 0 [7 7 6 5 6 5 6 6 6 7 8 9]\n",
            "Example prediction:\n",
            " 2 [3 3 1 1 1 0 2 1 2 2 3 5]\n",
            "Example prediction:\n",
            " 4 [-3 -3 -4 -4 -3 -4 -3 -4 -3 -2 -2 -1]\n",
            "Example prediction:\n",
            " 6 [1 1 1 1 1 0 1 0 1 2 2 3]\n",
            "Example prediction:\n",
            " 8 [2 2 1 2 2 1 2 1 2 3 3 4]\n",
            "Example prediction:\n",
            " 10 [4 5 4 4 4 4 4 4 4 5 5 6]\n",
            "Example prediction:\n",
            " 12 [3 3 3 3 3 2 3 2 3 4 4 5]\n",
            "Example prediction:\n",
            " 14 [5 5 4 4 5 4 5 4 5 6 6 7]\n",
            "Example prediction:\n",
            " 16 [15 15 14 14 15 14 15 14 15 16 16 17]\n",
            "Example prediction:\n",
            " 18 [21 21 20 20 21 20 22 21 21 22 23 24]\n",
            "Example prediction:\n",
            " 20 [27 28 26 26 27 27 28 27 28 29 29 30]\n",
            "Example prediction:\n",
            " 22 [35 36 35 35 35 35 36 36 36 37 38 38]\n",
            "Building Eagle_office_Henriette\n",
            " Count bad values before pseudofill: 162\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_141 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_142 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_143 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 0.0034\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.9926e-05\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.4642e-05\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.3464e-05\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8.8496e-06\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.9443e-06\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.1564e-06\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.2296e-06\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.5105e-06\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.0125e-06\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.5566e-06\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.2987e-06\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.1214e-06\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9.0095e-07\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.8748e-07\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6.2146e-07\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.5208e-07\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.6978e-07\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.1407e-07\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.4096e-07\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.4260e-07\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.8752e-07\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.3144e-07\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.2851e-07\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.9581e-07\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.7209e-07\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.5092e-07\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.4006e-07\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.1319e-07\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.1529e-07\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.1738e-07\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 9.5813e-08\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8.6885e-08\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.0754e-07\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5.6050e-08\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6.6543e-08\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.4875e-08\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7.8364e-08\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.8836e-08\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.7006e-08\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.5673e-08\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.0714e-07\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.9254e-08\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4.4046e-08\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.5668e-08\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.9537e-08\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.6941e-08\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2.7064e-08\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3.0698e-08\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1.9421e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "i,mean,rmse,rmse/mean,bldg: 7 0.0 0.0005209369907947566 inf Eagle_office_Henriette\n",
            "Example prediction:\n",
            " 0 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 2 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 4 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 6 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 8 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 10 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 12 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 14 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 16 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 18 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 20 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Example prediction:\n",
            " 22 [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Building Eagle_health_Reba\n",
            " Count bad values before pseudofill: 36\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_144 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_145 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_146 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1765 1738 1266 1758 2276 3012 2801 2550 2612 2622 2627 2592]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 1466573.9950\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1431472.0432\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1435254.5795\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1439664.3441\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1404586.5382\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1371791.0905\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1395970.1600\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1360247.0795\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1395510.5759\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1375650.5250\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1344354.7959\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1327714.3082\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1336098.2673\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1335871.3132\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1318617.0641\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1296562.4664\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1298093.1695\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1280383.0007\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1276765.3441\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1267793.5832\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1236948.1400\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1256791.3259\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1235962.8255\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1225449.1341\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1229248.4132\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1201328.4223\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1216585.2932\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1196538.9641\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1164199.9814\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1156748.4566\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1161259.6277\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1144001.1209\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1151656.6795\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1113010.2205\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1109768.2030\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1121101.0707\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1118976.2932\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1100887.2495\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1085398.0923\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1084299.7914\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1077783.6468\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1053998.9118\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1054252.0659\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1044305.9148\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1040592.1452\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1029443.5248\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 999988.3023\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1033901.0009\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1000979.6391\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 976241.2891\n",
            "i,mean,rmse,rmse/mean,bldg: 8 1084.2856908630224 927.1741594667374 0.8551013513133847 Eagle_health_Reba\n",
            "Example prediction:\n",
            " 0 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 2 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 4 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 6 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 8 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 10 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 12 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 14 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 16 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 18 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 20 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Example prediction:\n",
            " 22 [230 231 231 230 231 230 232 231 231 231 231 231]\n",
            "Building Eagle_lodging_Edgardo\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_147 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_148 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_149 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [203 120 203 174 176 184 226 258 235 184 243 259]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 9815.7865\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 8697.1559\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7932.8402\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7864.1484\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 7138.8995\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6472.9950\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 6301.3181\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5761.4726\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5429.2437\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 5034.5011\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4988.4041\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4534.1895\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4345.0071\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 4101.1458\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3868.1568\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3771.0901\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3680.0160\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3589.6268\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3601.0743\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3476.6565\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3464.5265\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3396.0722\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3384.6836\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3422.1906\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 3324.3623\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2940.6660\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2813.0653\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2643.4697\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2501.9420\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2395.4418\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2373.9705\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2291.1171\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2251.8118\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2251.5539\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2141.7107\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2097.7730\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2043.1668\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 2012.6118\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1983.2588\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1862.4327\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1869.2856\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1897.3786\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1791.1487\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1818.1995\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1727.5985\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1687.8681\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1667.3777\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1679.4721\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1675.7432\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 1597.5680\n",
            "i,mean,rmse,rmse/mean,bldg: 9 81.9677919573641 69.35831365943022 0.8461654511263064 Eagle_lodging_Edgardo\n",
            "Example prediction:\n",
            " 0 [138 139 139 139 139 139 139 139 139 139 138 138]\n",
            "Example prediction:\n",
            " 2 [141 141 141 142 142 142 142 141 141 141 141 141]\n",
            "Example prediction:\n",
            " 4 [139 140 140 140 140 140 140 140 140 139 139 139]\n",
            "Example prediction:\n",
            " 6 [136 137 137 137 137 137 137 137 137 136 136 136]\n",
            "Example prediction:\n",
            " 8 [136 136 136 137 137 137 137 136 136 136 136 136]\n",
            "Example prediction:\n",
            " 10 [108 108 108 108 109 108 107 108 108 108 107 108]\n",
            "Example prediction:\n",
            " 12 [101 101 100 100 101 100 100 100 101 101 100 101]\n",
            "Example prediction:\n",
            " 14 [98 98 97 97 98 97 96 97 98 97 97 97]\n",
            "Example prediction:\n",
            " 16 [96 95 94 94 95 94 94 95 95 95 95 95]\n",
            "Example prediction:\n",
            " 18 [94 93 92 93 93 93 92 93 93 93 93 93]\n",
            "Example prediction:\n",
            " 20 [89 89 88 88 89 88 87 88 89 89 88 89]\n",
            "Example prediction:\n",
            " 22 [100 100  99 100 100 100  99 100 100 100 100 100]\n",
            "Building Eagle_education_Cassie\n",
            "Building Eagle_education_Peter\n",
            " Count bad values before pseudofill: 34\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_150 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_151 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_152 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [7938 7923 8023 8046 8049 8002 8064 8097 8187 8160 8224 8161]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 13033746.3964\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13139242.6800\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 13011022.2145\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12965828.0436\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12937696.7236\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12482958.5673\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12860541.9564\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12854948.2945\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12837636.8727\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12708870.8945\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12892846.2291\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12638209.0691\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12628146.7382\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12656206.9855\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12521872.6291\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12607803.1345\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12507823.2800\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12569407.9091\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12574798.2400\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12394523.0655\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12369020.1927\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12455905.4436\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12446357.6836\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12359805.0473\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12217112.7200\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12445773.0545\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12137449.2800\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12250749.0982\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12248341.6764\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12243804.1309\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12203403.8509\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11773883.4436\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11924169.5600\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12130412.5455\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11817466.0800\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11942762.6036\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11775081.5891\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11857359.2618\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11758391.7927\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 12026625.3527\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11787822.4255\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11965299.8727\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11716907.0909\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11778471.6400\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11456336.5945\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11558375.0145\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11642622.6400\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11734031.8291\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11418705.6618\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 11408852.9818\n",
            "i,mean,rmse,rmse/mean,bldg: 10 3153.2853604405936 3042.708153450582 0.9649326989630392 Eagle_education_Peter\n",
            "Example prediction:\n",
            " 0 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 2 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 4 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 6 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 8 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 10 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 12 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 14 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 16 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 18 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 20 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Example prediction:\n",
            " 22 [233 233 233 234 232 232 233 234 232 231 233 234]\n",
            "Building Eagle_health_Gregoria\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_153 (GRU)                (None, 12, 16)            1344      \n",
            "_________________________________________________________________\n",
            "gru_154 (GRU)                (None, 12, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_155 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 12)                204       \n",
            "=================================================================\n",
            "Total params: 4,812\n",
            "Trainable params: 4,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Epoch 1/50\n",
            "274/274 [==============================] - 5s 5ms/step - loss: 651655.8705\n",
            "Epoch 2/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 648623.8973\n",
            "Epoch 3/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 614567.5280\n",
            "Epoch 4/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 627620.7480\n",
            "Epoch 5/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 636841.2452\n",
            "Epoch 6/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 656106.9509\n",
            "Epoch 7/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 621661.9725\n",
            "Epoch 8/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 628501.4688\n",
            "Epoch 9/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 617884.3095\n",
            "Epoch 10/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 585134.9756\n",
            "Epoch 11/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 610655.2306\n",
            "Epoch 12/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 598047.2958\n",
            "Epoch 13/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 606361.5616\n",
            "Epoch 14/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 607263.8591\n",
            "Epoch 15/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 588203.8307\n",
            "Epoch 16/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 563087.6245\n",
            "Epoch 17/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 596216.9334\n",
            "Epoch 18/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 554454.3368\n",
            "Epoch 19/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 561363.9315\n",
            "Epoch 20/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 578781.4456\n",
            "Epoch 21/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 574889.3686\n",
            "Epoch 22/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 552126.9939\n",
            "Epoch 23/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 591725.9209\n",
            "Epoch 24/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 559898.5947\n",
            "Epoch 25/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 577566.7514\n",
            "Epoch 26/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 558380.5169\n",
            "Epoch 27/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 543379.7259\n",
            "Epoch 28/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 581545.7566\n",
            "Epoch 29/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 550855.5297\n",
            "Epoch 30/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 516440.7586\n",
            "Epoch 31/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 512324.3091\n",
            "Epoch 32/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 537573.5722\n",
            "Epoch 33/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 523143.5324\n",
            "Epoch 34/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 524622.0190\n",
            "Epoch 35/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 512119.8643\n",
            "Epoch 36/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 520851.5934\n",
            "Epoch 37/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 515921.9476\n",
            "Epoch 38/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 520939.7178\n",
            "Epoch 39/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 541070.7341\n",
            "Epoch 40/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 519558.3655\n",
            "Epoch 41/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 517239.9925\n",
            "Epoch 42/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 541834.8489\n",
            "Epoch 43/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 504450.9322\n",
            "Epoch 44/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 489202.1836\n",
            "Epoch 45/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 494763.5614\n",
            "Epoch 46/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 514368.6003\n",
            "Epoch 47/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 503371.4880\n",
            "Epoch 48/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 471836.7619\n",
            "Epoch 49/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 486926.8140\n",
            "Epoch 50/50\n",
            "274/274 [==============================] - 1s 5ms/step - loss: 471056.9389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8eEJdHbz9v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY4snIvJbz9z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}