{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Assume user downloaded archive.zip from Kaggle, renamed the file BuildingData.zip, and stored the file in the data subdirectory. Assume the zip file contains the weather.csv file.\n",
    "\n",
    "Use a linear univariate model, linear regression,\n",
    "to predict steam usage at time t \n",
    "based on the air temperature at times t-24 to t-1.\n",
    "That is, predict this hour based on the prior 24 hours. \n",
    "\n",
    "The model is isomorphic to season. (Steam usage goes down in Spring and goes up in Fall. So, a better model would use season as a predictor.)\n",
    "\n",
    "Train the model over all of Year 1. \n",
    "Each building is treated separately for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "PREDICTOR_VARIABLE = 'airTemperature'  \n",
    "PREDICTED_VARIABLE = 'steam'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE = False   # if true, use 1 time per day, else 24 times per day\n",
    "STEPS_HISTORY = 24 \n",
    "STEPS_FUTURE =  1    \n",
    "def smooth(df):\n",
    "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
    "    smoothed = None\n",
    "    if DOWNSAMPLE:\n",
    "        # This alternate method samples down to 1/24 time steps.\n",
    "        smoothed = df.resample(\"24H\").mean() \n",
    "    else:\n",
    "        # This method does not reduce the number of time steps.\n",
    "        # Note the first 23 measurements get set to Nan.\n",
    "        smoothed=df.rolling(window=24).mean()\n",
    "        smoothed=smoothed[24:]\n",
    "    return smoothed\n",
    "\n",
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    predictor_series = df[PREDICTOR_VARIABLE].values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values\n",
    "    for i in range(STEPS_HISTORY,len(df)-STEPS_FUTURE):\n",
    "        one_predictor = predictor_series[i-STEPS_HISTORY:i]\n",
    "        one_predicted = predicted_series[i:i+STEPS_FUTURE]\n",
    "        X.append(one_predictor)\n",
    "        y.append(one_predicted)\n",
    "    return X,y  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eagle_office_Lamont\n",
      "Eagle_health_Athena\n",
      "Samples: 8747\n",
      "Model: slope= [826.96] intercepts= [[-34.6   32.54   0.85  -3.18   2.88  -4.37   2.21  -5.64   3.9    3.13\n",
      "   -0.7   -8.46   5.12   1.56  -6.38  10.94  -7.96   0.76  -2.67  -3.6\n",
      "   -3.09  -0.33  26.25 -31.26]]\n",
      "RMSE/mean= 0.3171259508203978\n",
      "Eagle_assembly_Herbert\n",
      "Eagle_public_Alvin\n",
      "Samples: 8747\n",
      "Model: slope= [322.4] intercepts= [[-15.37  14.97   1.2   -1.29  -3.04   0.32  -0.26   0.41   0.83  -1.77\n",
      "    0.76   1.56  -2.72   1.26   0.52  -0.15  -1.41   2.89  -2.94   0.21\n",
      "   -2.49   0.21   0.16  -2.29]]\n",
      "RMSE/mean= 0.3907538049540913\n",
      "Eagle_education_Raul\n",
      "Eagle_education_Roman\n",
      "Samples: 8747\n",
      "Model: slope= [1731.39] intercepts= [[ 49.99 -57.97  -2.89   4.23   8.7   -2.83   5.12   3.88  -7.92  -3.56\n",
      "   -0.72   5.84 -11.07   1.72   7.2  -11.52  -0.44  -0.45  -5.23  -1.89\n",
      "    0.11   2.14 -20.64  -1.58]]\n",
      "RMSE/mean= 0.21333178584947454\n",
      "Eagle_office_Mandi\n",
      "Eagle_education_Jewell\n",
      "Eagle_office_Henriette\n",
      "Eagle_health_Reba\n",
      "Eagle_lodging_Edgardo\n",
      "Samples: 8747\n",
      "Model: slope= [133.69] intercepts= [[ 2.41 -3.18  0.19 -1.59  1.46 -0.99  0.97  0.29 -0.12 -0.69 -0.18  0.45\n",
      "   1.65 -1.84 -0.27 -0.15  0.81 -2.03  1.18 -1.09  0.56  0.22  4.18 -6.11]]\n",
      "RMSE/mean= 0.3521950883517967\n",
      "Eagle_education_Cassie\n",
      "Eagle_education_Peter\n",
      "Samples: 8747\n",
      "Model: slope= [4956.12] intercepts= [[ 272.66 -303.85   -5.83   16.82   12.03   -1.08    3.92   31.26  -25.09\n",
      "   -10.58   -4.33   12.3   -12.85  -10.63    4.97   -6.87  -16.17  -16.81\n",
      "     1.24  -10.2    -2.53   -5.56   83.9  -131.04]]\n",
      "RMSE/mean= 0.2556419285514726\n",
      "Eagle_health_Gregoria\n",
      "Eagle_lodging_Dawn\n",
      "Samples: 8747\n",
      "Model: slope= [158.49] intercepts= [[ 2.39 -3.61 -0.52  1.19  0.45 -1.44  1.75 -0.32 -0.55 -1.74  1.97  0.11\n",
      "  -0.05 -1.6   0.51  0.53 -0.83 -0.68 -0.22  0.8  -1.84  0.16  5.89 -6.52]]\n",
      "RMSE/mean= 0.43161438158095294\n",
      "Eagle_office_Nereida\n",
      "Eagle_lodging_Tressa\n",
      "Eagle_education_Eileen\n",
      "Eagle_education_Wesley\n",
      "Samples: 8747\n",
      "Model: slope= [0.09] intercepts= [[ 5.50e-03 -5.01e-03 -1.83e-03  1.52e-03  8.42e-04 -1.30e-03  9.19e-04\n",
      "   3.18e-04 -2.79e-04 -1.62e-04 -3.42e-04  5.26e-04 -1.82e-04  7.75e-04\n",
      "  -2.48e-04 -1.10e-03  4.46e-04 -2.31e-04  8.17e-04 -3.94e-04 -4.36e-05\n",
      "   4.11e-04  7.88e-04 -6.39e-04]]\n",
      "RMSE/mean= 0.20333911469791144\n",
      "Eagle_health_Vincenza\n",
      "Samples: 8747\n",
      "Model: slope= [166.71] intercepts= [[ 2.3  -3.29 -0.1   0.68 -0.32  0.21  0.21  1.34 -2.16  0.75 -0.14 -0.16\n",
      "   0.48 -0.41 -0.17  0.05 -0.18 -0.31 -0.45  0.13 -0.58 -0.62  4.29 -5.11]]\n",
      "RMSE/mean= 0.17744377401615316\n",
      "Eagle_office_Dallas\n",
      "Eagle_education_Shante\n",
      "Eagle_office_Chauncey\n",
      "Eagle_office_Phyllis\n",
      "Eagle_office_Freida\n",
      "Eagle_office_Francis\n",
      "Samples: 8747\n",
      "Model: slope= [356.41] intercepts= [[  6.24  -6.51   0.68  -0.89  -0.63   0.97   0.19  -0.75   2.98  -2.01\n",
      "   -3.51   3.    -0.54   0.34  -0.75  -0.61  -0.83   1.2   -0.52  -1.41\n",
      "    1.02  -0.97 -10.28   8.18]]\n",
      "RMSE/mean= 0.3604298118329834\n",
      "Eagle_office_Sheree\n",
      "Eagle_education_Sherrill\n",
      "Samples: 8747\n",
      "Model: slope= [3472.45] intercepts= [[-53.5   40.4   11.76 -14.98   2.68  -6.3    6.94 -23.11  31.92  -8.07\n",
      "   -9.85  -1.24   2.4    4.92 -10.1    4.15 -18.9   -7.6   -0.19  -9.89\n",
      "   -3.43 -15.82  65.44 -95.37]]\n",
      "RMSE/mean= 0.1846687151723478\n",
      "Eagle_education_Brooke\n",
      "Samples: 8747\n",
      "Model: slope= [3073.33] intercepts= [[-74.97  64.85   3.19 -21.62  26.12  -2.18 -10.89   8.47  -9.45   4.72\n",
      "  -25.06  28.54   2.01  -8.81  -9.65 -20.77  12.12  35.28 -52.01 -19.25\n",
      "   31.87 -23.94 -64.15  34.32]]\n",
      "RMSE/mean= 0.38694034459540494\n",
      "Eagle_education_Alberto\n",
      "Eagle_food_Kay\n",
      "Eagle_health_Jodi\n",
      "Eagle_education_Norah\n",
      "Samples: 8747\n",
      "Model: slope= [1087.5] intercepts= [[ 23.   -27.64   0.34  -1.93   6.14  -0.63   0.43  -5.67   6.38  -4.48\n",
      "   -0.18  -0.1    0.06  -2.77  -0.69  -2.65   0.52  -5.03   2.11  -2.88\n",
      "    0.19  -1.96 -15.6    2.44]]\n",
      "RMSE/mean= 0.3000498163291296\n",
      "Eagle_education_Will\n",
      "Samples: 8747\n",
      "Model: slope= [288.38] intercepts= [[ 2.08e+01 -2.12e+01 -1.70e-01  9.36e-01  7.80e-01  3.61e-01 -5.11e-01\n",
      "   2.29e+00 -2.27e+00 -7.33e-01  3.31e-01  1.26e+00 -8.08e-01 -8.50e-02\n",
      "  -3.27e-01 -2.27e+00  2.29e+00 -2.04e+00 -5.31e-01  1.08e+00  1.21e-02\n",
      "  -7.41e-01 -6.48e+00  6.18e+00]]\n",
      "RMSE/mean= 0.36019525333948904\n",
      "Eagle_lodging_Blake\n",
      "Eagle_education_Petra\n",
      "Samples: 8747\n",
      "Model: slope= [98.93] intercepts= [[-6.82  6.27  0.5  -1.29  0.38 -0.38  0.47 -1.09  1.32 -0.17 -0.73  0.21\n",
      "   0.31 -0.15 -0.16  0.73 -0.93  0.39 -0.57  0.23 -0.2  -0.06  2.62 -4.08]]\n",
      "RMSE/mean= 0.3119352978380884\n",
      "Eagle_lodging_Trina\n",
      "Samples: 8747\n",
      "Model: slope= [153.31] intercepts= [[ 1.18e+01 -1.43e+01 -1.07e+00  2.55e+00  1.33e+00 -1.83e+00 -4.61e-01\n",
      "   2.91e+00 -2.02e+00  1.04e-02 -2.69e-01  1.67e+00 -6.11e-01 -2.25e+00\n",
      "   5.10e-01  1.99e+00 -2.68e+00 -1.40e-01  1.19e-01 -1.51e-01 -2.51e+00\n",
      "   8.33e-01  2.02e+01 -2.05e+01]]\n",
      "RMSE/mean= 0.3685588953659394\n",
      "Eagle_health_Reuben\n",
      "Eagle_education_Teresa\n",
      "Samples: 8747\n",
      "Model: slope= [242.11] intercepts= [[-12.69  12.16   0.35  -1.75   0.47  -1.05   0.81  -2.74   2.78   0.18\n",
      "   -0.84   0.04  -0.5    0.75  -0.35   0.26  -1.32   0.69  -1.3   -0.08\n",
      "   -0.63  -0.7    9.87 -11.16]]\n",
      "RMSE/mean= 0.29415606825011337\n",
      "Eagle_office_Norbert\n",
      "Eagle_lodging_Casey\n",
      "Eagle_office_Tia\n",
      "Eagle_office_Remedios\n",
      "Eagle_office_Patrice\n",
      "Eagle_education_Shana\n",
      "\n",
      "History 24 Future 1\n",
      "Column 1: Correlation of steam and airTemperature\n",
      "          Using one weather feature as leading correlate.\n",
      "Column 2: Mean usage.\n",
      "          Using mean to help understand the RMSE.\n",
      "Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 4: RMSE/mean normalized to help understand RMSE.\n",
      "Column 5: Building.\n",
      "-0.9192    2030.36     374.94  0.18   Eagle_education_Sherrill\n",
      "-0.8669    1634.28     632.37  0.39   Eagle_education_Brooke\n",
      "-0.8492     477.41     151.40  0.32   Eagle_health_Athena\n",
      "-0.8319      56.96      17.77  0.31   Eagle_education_Petra\n",
      "-0.8267    3147.43     804.62  0.26   Eagle_education_Peter\n",
      "-0.8217     121.91      21.63  0.18   Eagle_health_Vincenza\n",
      "-0.8040    1197.02     255.36  0.21   Eagle_education_Roman\n",
      "-0.8007     711.33     213.43  0.30   Eagle_education_Norah\n",
      "-0.7661      81.87      28.83  0.35   Eagle_lodging_Edgardo\n",
      "-0.7555     181.94      71.09  0.39   Eagle_public_Alvin\n",
      "-0.7302     148.51      43.68  0.29   Eagle_education_Teresa\n",
      "-0.7249      92.73      40.03  0.43   Eagle_lodging_Dawn\n",
      "-0.7103      91.20      33.61  0.37   Eagle_lodging_Trina\n",
      "-0.6122     335.96     121.09  0.36   Eagle_office_Francis\n",
      "-0.3433     226.07      81.43  0.36   Eagle_education_Will\n",
      " 0.7079       0.11       0.02  0.20   Eagle_education_Wesley\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "for BLDG in all_buildings:\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    print(BLDG)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        one_bldg_df = smooth(one_bldg_df) # moving average: 24hr\n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        # Ideally, split Year1 = train, Year2 = test.\n",
    "        # Some data is incomplete, so split 1st half and 2nd half.\n",
    "        split = len(X)//2 \n",
    "        X_train = X[0:split]\n",
    "        y_train = y[0:split]\n",
    "        X_test = X[split:]\n",
    "        y_test = y[split:]\n",
    "        linreg = LinearRegression()\n",
    "        linreg.fit(X_train,y_train)\n",
    "        y_pred = linreg.predict(X_test)\n",
    "        # Keep a table for reporting later.\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][PREDICTOR_VARIABLE] \n",
    "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"Samples:\",len(X_train))\n",
    "        print(\"Model: slope=\",linreg.intercept_,\"intercepts=\",linreg.coef_)\n",
    "        print(\"RMSE/mean=\",rmse/mean)\n",
    "\n",
    "print()\n",
    "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",PREDICTOR_VARIABLE)\n",
    "print(\"          Using one weather feature as leading correlate.\")\n",
    "print(\"Column 2: Mean usage.\")\n",
    "print(\"          Using mean to help understand the RMSE.\")\n",
    "print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
    "print(\"Column 5: Building.\")\n",
    "for cor in sorted(cors):\n",
    "    print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report 1\n",
    "Report 1, Table I, includes the following summary. This is the mean over 16 builings of the normalized RMSE per building.\n",
    "\n",
    "Linear regression using predictions based on 24 times, 1 feature\n",
    "\n",
    "* 0.31 mean RMSE\n",
    "* 0.08 stddev\n",
    "\n",
    "Those results are the same whether outlier Wesley is included or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
