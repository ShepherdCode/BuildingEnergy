{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNN_226.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNRPftWw9pK"
      },
      "source": [
        "# RNN \n",
        "Use non-consecutive predictors. Skip = 3. Use 24 predictors (3 days) to predict next 3 (9 hours). Smoothing window size 3. Predict steam given steam and day of year. Smooth = 3. Model = GRU 3x16. Predictors = all features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5deM-us2w9pZ"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredError\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZgkgsP6w9pg",
        "outputId": "fe7076f4-4b6c-4e0e-cc1e-7f6a3295a3ed"
      },
      "source": [
        "# Constants\n",
        "EPOCHS=50  # use 5 for software testing, 50 for model testing\n",
        "SITE = 'Eagle'\n",
        "PREDICTORS = ['hour','month','doy','meter','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
        "#PREDICTORS = ['hour','doy','meter','airTemperature'] \n",
        "NUM_PREDICTORS=len(PREDICTORS)\n",
        "print(\"PREDICTORS=\",NUM_PREDICTORS,PREDICTORS)\n",
        "PREDICTED_VARIABLE = 'meter'  \n",
        "STEPS_SKIP = 3\n",
        "STEPS_FORWARD = 24 \n",
        "STEPS_FUTURE =  3 \n",
        "METER_FILE='steam.csv'\n",
        "WEATHER_FILE='weather.csv'\n",
        "EXAMPLE='Eagle_lodging_Edgardo'\n",
        "SITE_BUILDINGS = None\n",
        "SMOOTHING_WINDOW=3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTORS= 12 ['hour', 'month', 'doy', 'meter', 'cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeDotTmw9pX",
        "outputId": "7cff7f8e-d4f0-4686-e2e9-aa6521449d8c"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdk510Cw9pc"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "6YVYM_bqw9pi",
        "outputId": "d6ee9e00-ea28-41d7-a890-20b585f102f0"
      },
      "source": [
        "def load_weather_for_site(site):\n",
        "    wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
        "    wet_df = fix_date_type(wet_df)\n",
        "    site_df = wet_df.loc[wet_df['site_id'] == site]\n",
        "    # Drop the site, which is constant (we selected for one site).\n",
        "    site_df = site_df.drop(['site_id'],axis=1)\n",
        "    site_df.insert(0,'hour',0)\n",
        "    site_df.insert(1,'month',0)\n",
        "    site_df.insert(2,'doy',0)\n",
        "    L=len(site_df)\n",
        "    for i in range(0,L):\n",
        "        dt=site_df.index[i]\n",
        "        hour=dt.hour\n",
        "        month=dt.month\n",
        "        doy=dt.dayofyear\n",
        "        site_df.iat[i,0] = hour\n",
        "        site_df.iat[i,1] = month\n",
        "        site_df.iat[i,2] = doy\n",
        "    return site_df\n",
        "\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "one_site_weather.tail()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>month</th>\n",
              "      <th>doy</th>\n",
              "      <th>airTemperature</th>\n",
              "      <th>cloudCoverage</th>\n",
              "      <th>dewTemperature</th>\n",
              "      <th>precipDepth1HR</th>\n",
              "      <th>precipDepth6HR</th>\n",
              "      <th>seaLvlPressure</th>\n",
              "      <th>windDirection</th>\n",
              "      <th>windSpeed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 18:00:00</th>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-11.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1026.2</td>\n",
              "      <td>330.0</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-21.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-21.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.2</td>\n",
              "      <td>310.0</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.4</td>\n",
              "      <td>330.0</td>\n",
              "      <td>3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>23</td>\n",
              "      <td>12</td>\n",
              "      <td>365</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-20.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1027.4</td>\n",
              "      <td>320.0</td>\n",
              "      <td>4.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     hour  month  doy  ...  seaLvlPressure  windDirection  windSpeed\n",
              "timestamp                              ...                                          \n",
              "2017-12-31 18:00:00    18     12  365  ...          1026.2          330.0        2.6\n",
              "2017-12-31 20:00:00    20     12  365  ...          1027.0          320.0        1.5\n",
              "2017-12-31 21:00:00    21     12  365  ...          1027.2          310.0        2.6\n",
              "2017-12-31 22:00:00    22     12  365  ...          1027.4          330.0        3.1\n",
              "2017-12-31 23:00:00    23     12  365  ...          1027.4          320.0        4.6\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "s-EKuCBibz9d",
        "outputId": "62bcf4c4-5a18-4df6-a6d5-733ee5575cd0"
      },
      "source": [
        "def load_meter_for_building(bldg,smooth=0):\n",
        "    all_df = read_zip_to_panda(ZIP_PATH,METER_FILE)\n",
        "    all_df = fix_date_type(all_df)\n",
        "    global SITE_BUILDINGS\n",
        "    SITE_BUILDINGS = [x for x in all_df.columns if x.startswith(SITE)]\n",
        "    site_series = all_df[bldg]\n",
        "    site_df = site_series.to_frame()\n",
        "    #site_df = all_df.loc[all_df['site_id'] == site]\n",
        "    # Change column name from building name to meter.\n",
        "    site_df = site_df.rename(columns={bldg : PREDICTED_VARIABLE})\n",
        "    if smooth>0:\n",
        "        site_df = site_df.rolling(smooth).mean()\n",
        "    return site_df\n",
        "\n",
        "one_bldg_meter = load_meter_for_building(EXAMPLE)\n",
        "print(type(one_bldg_meter))\n",
        "one_bldg_meter.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meter</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31 19:00:00</th>\n",
              "      <td>92.2957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 20:00:00</th>\n",
              "      <td>277.5584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 21:00:00</th>\n",
              "      <td>280.5331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 22:00:00</th>\n",
              "      <td>289.3302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-31 23:00:00</th>\n",
              "      <td>164.3474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        meter\n",
              "timestamp                    \n",
              "2017-12-31 19:00:00   92.2957\n",
              "2017-12-31 20:00:00  277.5584\n",
              "2017-12-31 21:00:00  280.5331\n",
              "2017-12-31 22:00:00  289.3302\n",
              "2017-12-31 23:00:00  164.3474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynRgLt9w9pk",
        "outputId": "b968b9e3-c3b6-46f4-9ae7-ecf8678e8195"
      },
      "source": [
        "# This is the first version that uses STEPS_SKIP.\n",
        "# To retrofit this to older notebooks, set STEPS_SKIP=0.\n",
        "def prepare_for_learning(wdf,mdf):\n",
        "    df = pd.concat([wdf,mdf],axis=1)\n",
        "    num_samples = len(df) - STEPS_FORWARD*STEPS_SKIP - STEPS_FUTURE*STEPS_SKIP\n",
        "    X_shape = (num_samples,STEPS_FORWARD,NUM_PREDICTORS)\n",
        "    Y_shape = (num_samples,STEPS_FUTURE)\n",
        "    X=np.zeros(X_shape)\n",
        "    y=np.zeros(Y_shape)\n",
        "    predictor_series = df[PREDICTORS].values  # selected features\n",
        "    predicted_series = df[PREDICTED_VARIABLE].values  # meter\n",
        "    # TO DO: can we take predicted from mdf instead?\n",
        "    for sam in range (0,num_samples): \n",
        "        prev_val = 0\n",
        "        for time in range (0,STEPS_FORWARD): \n",
        "            one_period = predictor_series[sam+time*STEPS_SKIP]\n",
        "            for feat in range (0,NUM_PREDICTORS):\n",
        "                val = one_period[feat]\n",
        "                if np.isnan(val):\n",
        "                    val = prev_val\n",
        "                else:\n",
        "                    prev_val = val\n",
        "                X[sam,time,feat] = val\n",
        "        for time1 in range (STEPS_FORWARD,STEPS_FORWARD+STEPS_FUTURE): \n",
        "            time0 = time1 - STEPS_FORWARD\n",
        "            y[sam,time0]=predicted_series[sam+time1*STEPS_SKIP]\n",
        "    return X,y \n",
        "X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "print(\"X shape:\",X.shape)\n",
        "print(\"y shape:\",y.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (17463, 24, 12)\n",
            "y shape: (17463, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mObWmpMDVuNQ",
        "outputId": "7c1f8de4-405d-40b1-f9c3-6b27ee7e9271"
      },
      "source": [
        "print(\"X columns:\",PREDICTORS)\n",
        "print(\"X example:\\n\",X[100].astype(int))\n",
        "print(\"y example:\\n\",y[100].astype(int))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X columns: ['hour', 'month', 'doy', 'meter', 'cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
            "X example:\n",
            " [[   4    1    5  232    0  -12  -20    0    0 1031  360    6]\n",
            " [   7    1    5  135    0  -12  -20    0    0 1033  360    3]\n",
            " [  10    1    5  320    0   -8  -20    0    0 1036  340    3]\n",
            " [  13    1    5  296    0   -3  -19    0    0 1035  350    4]\n",
            " [  16    1    5  235    0   -1  -19    0    0 1035  350    2]\n",
            " [  19    1    5  172    0   -3  -16    0    0 1036    0    0]\n",
            " [  22    1    5  225    0   -7  -14    0    0 1036    0    0]\n",
            " [   1    1    6  222    0   -9  -13    0    0 1035    0    0]\n",
            " [   4    1    6   43    0  -11  -13    0    0 1035  240    2]\n",
            " [   7    1    6  322    0  -10  -13    0    0 1035    0    0]\n",
            " [  10    1    6  328    0   -3  -11    0    0 1035  250    2]\n",
            " [  13    1    6  168    0    2  -13    0    0 1032  310    1]\n",
            " [  16    1    6   35    0    3  -15    0    0 1031  200    2]\n",
            " [  19    1    6   95    0    0  -15    0    0 1030  230    1]\n",
            " [  22    1    6  150    0   -2  -12    0    0 1030  230    2]\n",
            " [   1    1    7  158    0   -4  -11    0    0 1028    0    0]\n",
            " [   4    1    7  166    4   -5  -10    0    0 1027  340    3]\n",
            " [   7    1    7  186    0   -5  -10    0    0 1027    0    0]\n",
            " [  10    1    7  152    4    1   -9    0    0 1026    0    0]\n",
            " [  13    1    7  170  170    5   -6    0    0 1024    0    0]\n",
            " [  16    1    7  285  285    7   -2    0    0 1023  190    2]\n",
            " [  19    1    7  117  117    6   -2    0    0 1023    0    0]\n",
            " [  22    1    7  117    0    2   -3    0    0 1022   10    2]\n",
            " [   1    1    8  143  143    0   -4    0    0 1020    0    0]]\n",
            "y example:\n",
            " [173 169 129]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8rzumTw9p2"
      },
      "source": [
        "def make_RNN():\n",
        "    # The GRU in Keras is optimized for speed on CoLab GPU.\n",
        "    rnn = Sequential([\n",
        "        GRU(16,return_sequences=True, \n",
        "                  input_shape=(STEPS_FORWARD,NUM_PREDICTORS)), \n",
        "        GRU(16,return_sequences=True),\n",
        "        GRU(16,return_sequences=False),\n",
        "        Dense(STEPS_FUTURE)\n",
        "    ])\n",
        "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
        "    return rnn"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypnRqq9w9p4",
        "scrolled": false,
        "outputId": "2355f568-1623-4cdd-c2ac-5eadd8d08ae5"
      },
      "source": [
        "cors = []\n",
        "one_site_weather = load_weather_for_site(SITE)\n",
        "for BLDG in SITE_BUILDINGS:\n",
        "    print(\"Building\",BLDG)\n",
        "    one_bldg_meter = load_meter_for_building(BLDG,SMOOTHING_WINDOW)\n",
        "    count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "    MAX_BAD = 500\n",
        "    if count_bad<=MAX_BAD:\n",
        "        # Must get rid of Nan labels, else loss hits NaN during training.\n",
        "        print(\" Count bad values before pseudofill:\",count_bad)\n",
        "        pseudovalue = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        one_bldg_meter = one_bldg_meter.fillna(pseudovalue)\n",
        "        count_bad = one_bldg_meter[PREDICTED_VARIABLE].isna().sum()\n",
        "        print(\" Count bad values after pseudofill:\",count_bad)\n",
        "        # \n",
        "        X,y = prepare_for_learning(one_site_weather,one_bldg_meter)\n",
        "        split = len(X)//2   # year 1 vs year 2\n",
        "        X_train = np.asarray(X[0:split])\n",
        "        y_train = np.asarray(y[0:split])\n",
        "        X_test = np.asarray(X[split:])\n",
        "        y_test = np.asarray(y[split:])\n",
        "        model = make_RNN()\n",
        "        print(model.summary())\n",
        "        #print(\"Example X train:\\n\",X_train[example].astype(int))\n",
        "        example=411\n",
        "        print(\"Example y train:\\n\",y_train[example].astype(int))\n",
        "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
        "        # Keep a table for reporting later.\n",
        "        y_pred = model.predict(X_test)\n",
        "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
        "        mean = one_bldg_meter[PREDICTED_VARIABLE].mean()\n",
        "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
        "        print(\"mean,rmse,rmse/mean,bldg:\",mean,rmse,rmse/mean,BLDG)\n",
        "        for hr in range(0,24,2):\n",
        "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))\n",
        "print()\n",
        "print(\"History\",STEPS_FORWARD,\"Future\",STEPS_FUTURE)\n",
        "print(\"Column 1: Mean usage.\")\n",
        "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
        "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
        "print(\"Column 4: Building.\")\n",
        "for cor in sorted(cors):\n",
        "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [ 0  0 62]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 22s 7ms/step - loss: 1183.9827\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 864.6588\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 681.0433\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 536.3439\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 423.5101\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 354.1621\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 294.0436\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 269.3470\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 252.8323\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 236.8760\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 229.7720\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 231.0830\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 231.9309\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 228.0962\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 230.5238\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 230.3664\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 230.0190\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 227.7798\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 233.3849\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 230.9635\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 231.8977\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 226.1455\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 234.5960\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 233.8074\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 229.2365\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 193.7226\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 147.6067\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 108.9866\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 101.9678\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 95.0289\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 92.0742\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 89.9728\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 85.6460\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 81.5454\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 84.7352\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 81.2098\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 70.8657\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 71.4154\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 73.5264\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 75.6414\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 70.9032\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 70.0075\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 68.6304\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 70.7015\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 65.8663\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 66.6374\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 64.9528\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 67.5128\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 66.3573\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 62.6110\n",
            "mean,rmse,rmse/mean,bldg: 36.93460755405991 11.238283938519157 0.3042751685413218 Eagle_office_Lamont\n",
            "Example prediction:\n",
            " 0 [48 48 47]\n",
            "Example prediction:\n",
            " 2 [44 44 43]\n",
            "Example prediction:\n",
            " 4 [35 35 35]\n",
            "Example prediction:\n",
            " 6 [48 48 48]\n",
            "Example prediction:\n",
            " 8 [43 43 43]\n",
            "Example prediction:\n",
            " 10 [35 35 35]\n",
            "Example prediction:\n",
            " 12 [48 48 47]\n",
            "Example prediction:\n",
            " 14 [44 44 44]\n",
            "Example prediction:\n",
            " 16 [35 35 35]\n",
            "Example prediction:\n",
            " 18 [47 47 47]\n",
            "Example prediction:\n",
            " 20 [44 44 44]\n",
            "Example prediction:\n",
            " 22 [42 42 42]\n",
            "Building Eagle_health_Athena\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_3 (GRU)                  (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1311 1247 1157]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 7ms/step - loss: 344534.9336\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 340761.5350\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 338420.1537\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 338065.2659\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 329717.9308\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 325983.5770\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 316943.0931\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 308907.3651\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 311743.5641\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 303653.0187\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 302456.0316\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 295666.4587\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 295940.8360\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 289127.0159\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 288747.5911\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 277890.1248\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 277193.0182\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 271761.9313\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 267193.0042\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 262941.5212\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 256097.6597\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 260305.2685\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 251920.6909\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 247064.6717\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 245111.0458\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 235838.5556\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 238048.9842\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 234175.9719\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 233042.1267\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 227560.9660\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 224855.0452\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 217107.0683\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 221405.4798\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 215745.1166\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 204737.9459\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 206650.9354\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 201376.0771\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 200238.5514\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 199647.1008\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 195829.4776\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 190111.8701\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 186952.4266\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 181563.9248\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 185984.9057\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 180782.5199\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 177428.6498\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 172269.6584\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 170932.3228\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 166261.5384\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 165510.3239\n",
            "mean,rmse,rmse/mean,bldg: 477.6710835157538 313.8579904464375 0.657058803175567 Eagle_health_Athena\n",
            "Example prediction:\n",
            " 0 [226 226 222]\n",
            "Example prediction:\n",
            " 2 [226 226 222]\n",
            "Example prediction:\n",
            " 4 [226 226 222]\n",
            "Example prediction:\n",
            " 6 [226 226 222]\n",
            "Example prediction:\n",
            " 8 [226 226 222]\n",
            "Example prediction:\n",
            " 10 [226 226 222]\n",
            "Example prediction:\n",
            " 12 [226 226 222]\n",
            "Example prediction:\n",
            " 14 [226 226 222]\n",
            "Example prediction:\n",
            " 16 [226 226 222]\n",
            "Example prediction:\n",
            " 18 [226 226 222]\n",
            "Example prediction:\n",
            " 20 [226 226 222]\n",
            "Example prediction:\n",
            " 22 [226 226 222]\n",
            "Building Eagle_assembly_Herbert\n",
            "Building Eagle_public_Alvin\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_6 (GRU)                  (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [460 330 367]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 7ms/step - loss: 55863.6235\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 54019.3359\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 52054.0701\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 48245.3006\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 47341.3111\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 46317.2117\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 43957.2576\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 41841.5105\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 42038.8142\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 39813.6497\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 39106.5291\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 36699.1427\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 35962.7185\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 34750.6746\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 33490.8979\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 32018.0227\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 31397.2949\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 29703.9389\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 29227.5724\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 28423.5569\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 27474.6953\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 26288.8658\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 25326.7978\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24242.1395\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 23842.4959\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 22734.3057\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 21968.7670\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 21135.0044\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 20815.5092\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19202.9786\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19157.7872\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 18872.0902\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 17799.5400\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16998.1521\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 16990.9290\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16376.3304\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15425.2938\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15403.9330\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14955.8006\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14423.0499\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14410.7375\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 14541.9658\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 14228.3697\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 13877.1211\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 13436.4076\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 13360.8321\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13555.6734\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12892.2353\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13154.6542\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12671.1396\n",
            "mean,rmse,rmse/mean,bldg: 182.0635582126762 77.01093035743155 0.42298926327404734 Eagle_public_Alvin\n",
            "Example prediction:\n",
            " 0 [192 193 193]\n",
            "Example prediction:\n",
            " 2 [192 193 193]\n",
            "Example prediction:\n",
            " 4 [192 193 193]\n",
            "Example prediction:\n",
            " 6 [192 193 193]\n",
            "Example prediction:\n",
            " 8 [192 193 193]\n",
            "Example prediction:\n",
            " 10 [192 193 193]\n",
            "Example prediction:\n",
            " 12 [192 193 193]\n",
            "Example prediction:\n",
            " 14 [192 193 193]\n",
            "Example prediction:\n",
            " 16 [192 193 193]\n",
            "Example prediction:\n",
            " 18 [192 193 193]\n",
            "Example prediction:\n",
            " 20 [192 193 193]\n",
            "Example prediction:\n",
            " 22 [192 193 193]\n",
            "Building Eagle_education_Raul\n",
            "Building Eagle_education_Roman\n",
            " Count bad values before pseudofill: 35\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_9 (GRU)                  (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [2402 2450 2570]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 7ms/step - loss: 1715189.1127\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1711873.0789\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1689128.4840\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1701227.4293\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1640794.9275\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1689497.2609\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1620864.3376\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1637605.3755\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1625154.1442\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1599787.9019\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1596698.3901\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1583189.1040\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1589452.7158\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1567473.8280\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1546033.9576\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1517957.8184\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1519283.6743\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1528549.2778\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1491877.9872\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1497198.2226\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1519939.6724\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1473846.8499\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1468566.4261\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1469283.5297\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1417628.2377\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1444382.9498\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1460179.0762\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1410267.2505\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1401819.6008\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1416403.0500\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1407518.1930\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1376288.7067\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1346647.9104\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1352299.6588\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1382487.0224\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1334175.8978\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1351689.8987\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1358772.7719\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1337337.9056\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1308356.3828\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1315564.7395\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1273179.2470\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1252770.0734\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1264284.8704\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1280590.6756\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1245090.8082\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1254394.6574\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1214243.4459\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1237993.7053\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1231773.5461\n",
            "mean,rmse,rmse/mean,bldg: 1199.3775815637814 1068.6589568786922 0.891011282273048 Eagle_education_Roman\n",
            "Example prediction:\n",
            " 0 [231 231 230]\n",
            "Example prediction:\n",
            " 2 [231 231 230]\n",
            "Example prediction:\n",
            " 4 [231 231 230]\n",
            "Example prediction:\n",
            " 6 [231 231 230]\n",
            "Example prediction:\n",
            " 8 [231 231 230]\n",
            "Example prediction:\n",
            " 10 [231 231 230]\n",
            "Example prediction:\n",
            " 12 [231 231 230]\n",
            "Example prediction:\n",
            " 14 [231 231 230]\n",
            "Example prediction:\n",
            " 16 [231 231 230]\n",
            "Example prediction:\n",
            " 18 [231 231 230]\n",
            "Example prediction:\n",
            " 20 [231 231 230]\n",
            "Example prediction:\n",
            " 22 [231 231 230]\n",
            "Building Eagle_office_Mandi\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_12 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [ 0  0 65]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 1437.5594\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1067.3446\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 838.1029\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 673.4727\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 551.7727\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 459.2692\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 383.4542\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 332.5475\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 295.5209\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 278.1279\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 269.1430\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 261.5674\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 267.1851\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 262.5964\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 268.7798\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 266.7131\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 271.0920\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 261.8739\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 259.0493\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 263.2933\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 259.3180\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 260.9683\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 262.0996\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 257.8814\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 261.9594\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 257.6344\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 259.6031\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 258.2411\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 261.8492\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 160.7403\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 109.2323\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 100.8435\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 67.7130\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 58.6260\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 54.9725\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 48.9287\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 53.8584\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 57.5403\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 58.6656\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 55.4709\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 52.5113\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 53.2148\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 51.5320\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 47.8704\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 45.6291\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 50.6095\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 48.4056\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 46.9342\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 47.6633\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 48.7336\n",
            "mean,rmse,rmse/mean,bldg: 35.89274527609939 7.464528294327134 0.20796760562357114 Eagle_office_Mandi\n",
            "Example prediction:\n",
            " 0 [44 44 44]\n",
            "Example prediction:\n",
            " 2 [59 58 58]\n",
            "Example prediction:\n",
            " 4 [42 42 43]\n",
            "Example prediction:\n",
            " 6 [52 51 52]\n",
            "Example prediction:\n",
            " 8 [60 60 59]\n",
            "Example prediction:\n",
            " 10 [52 52 52]\n",
            "Example prediction:\n",
            " 12 [57 56 56]\n",
            "Example prediction:\n",
            " 14 [60 60 59]\n",
            "Example prediction:\n",
            " 16 [56 56 55]\n",
            "Example prediction:\n",
            " 18 [59 59 58]\n",
            "Example prediction:\n",
            " 20 [60 60 59]\n",
            "Example prediction:\n",
            " 22 [58 58 57]\n",
            "Building Eagle_education_Jewell\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_15 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_16 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_17 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [138 124 128]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 7ms/step - loss: 4125.7016\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3933.8620\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3773.5560\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3576.1126\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3460.6658\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3403.9344\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3289.5054\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2985.2080\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2869.6871\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2564.7787\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2555.1308\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2481.3259\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2324.1574\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2132.2607\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2168.0325\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2141.5539\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2084.4358\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1943.0880\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1712.7536\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1720.8901\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1573.9716\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1544.9231\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1479.1052\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1322.3927\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1355.7091\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1300.7672\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1259.8307\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1215.4885\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1165.1398\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1077.4057\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1100.3557\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1013.9282\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 926.1546\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 972.8211\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 931.1871\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 895.2254\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 898.6651\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 870.1538\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 829.4448\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 794.2492\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 776.4810\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 760.2438\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 760.9148\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 715.1157\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 735.9675\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 744.5665\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 698.9834\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 690.8303\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 669.9303\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 671.7286\n",
            "mean,rmse,rmse/mean,bldg: 15.763918737885179 14.255331591890753 0.9043012609314673 Eagle_education_Jewell\n",
            "Example prediction:\n",
            " 0 [11 12 12]\n",
            "Example prediction:\n",
            " 2 [7 8 8]\n",
            "Example prediction:\n",
            " 4 [ 9 10 10]\n",
            "Example prediction:\n",
            " 6 [10 11 11]\n",
            "Example prediction:\n",
            " 8 [6 7 8]\n",
            "Example prediction:\n",
            " 10 [8 9 9]\n",
            "Example prediction:\n",
            " 12 [10 10 11]\n",
            "Example prediction:\n",
            " 14 [6 7 7]\n",
            "Example prediction:\n",
            " 16 [8 9 9]\n",
            "Example prediction:\n",
            " 18 [ 9  9 10]\n",
            "Example prediction:\n",
            " 20 [8 9 9]\n",
            "Example prediction:\n",
            " 22 [8 8 9]\n",
            "Building Eagle_office_Henriette\n",
            " Count bad values before pseudofill: 162\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_18 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_19 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_20 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 0.0094\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.7962e-05\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.0754e-05\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.4544e-06\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.4985e-06\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3.3441e-06\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.5784e-06\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.2765e-06\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.8489e-06\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.6476e-06\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.5195e-06\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.4645e-06\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.2370e-06\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.2736e-06\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.4531e-06\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.5453e-06\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3128e-06\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3493e-06\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.0230e-06\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3.1094e-06\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.4312e-06\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3443e-06\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3423e-06\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3.4673e-06\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.4623e-06\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3218e-06\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.2251e-06\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.2309e-06\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.7347e-06\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.8368e-07\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.4928e-07\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3.1672e-06\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.0617e-07\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9.4599e-07\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.6510e-06\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8.0098e-07\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.1856e-06\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.3887e-06\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.2137e-06\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7.5004e-07\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.6236e-07\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.4514e-06\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.6302e-06\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9.4165e-07\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1.2329e-06\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.0380e-06\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3.9053e-07\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.7098e-06\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.4610e-07\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2.8198e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean,rmse,rmse/mean,bldg: 0.0 0.0018204029499465384 inf Eagle_office_Henriette\n",
            "Example prediction:\n",
            " 0 [0 0 0]\n",
            "Example prediction:\n",
            " 2 [0 0 0]\n",
            "Example prediction:\n",
            " 4 [0 0 0]\n",
            "Example prediction:\n",
            " 6 [0 0 0]\n",
            "Example prediction:\n",
            " 8 [0 0 0]\n",
            "Example prediction:\n",
            " 10 [0 0 0]\n",
            "Example prediction:\n",
            " 12 [0 0 0]\n",
            "Example prediction:\n",
            " 14 [0 0 0]\n",
            "Example prediction:\n",
            " 16 [0 0 0]\n",
            "Example prediction:\n",
            " 18 [0 0 0]\n",
            "Example prediction:\n",
            " 20 [0 0 0]\n",
            "Example prediction:\n",
            " 22 [0 0 0]\n",
            "Building Eagle_health_Reba\n",
            " Count bad values before pseudofill: 36\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_21 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_22 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_23 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [2796 2732 2710]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 7ms/step - loss: 1453591.2427\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1445539.9279\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1446299.8317\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1402437.2696\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1423282.1930\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1421425.8536\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1413126.6848\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1392961.5233\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1399067.6104\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1380595.0465\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1355505.8837\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1364999.7956\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1354886.7313\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1348294.6154\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1307736.5839\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1324793.6273\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1332954.0689\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1280873.2696\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1277880.1718\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1286245.1077\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1269345.9776\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1256684.6373\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1265003.0027\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1248000.2486\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1243195.0433\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1220266.8536\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1217482.8387\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1200884.4818\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1184512.2799\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1150841.5271\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1190862.8385\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1190679.6729\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1145032.2785\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1133029.9375\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1141825.5046\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1106946.5899\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1097741.3855\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1102813.8987\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1107663.6086\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1096313.8084\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1101519.4316\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1055057.7183\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1057043.3230\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1059633.0570\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1049352.5490\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1013893.9519\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1026737.2797\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1035524.4925\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1031299.0746\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1002093.1045\n",
            "mean,rmse,rmse/mean,bldg: 1084.4328846508208 919.0812045068864 0.847522440084269 Eagle_health_Reba\n",
            "Example prediction:\n",
            " 0 [231 231 229]\n",
            "Example prediction:\n",
            " 2 [231 231 229]\n",
            "Example prediction:\n",
            " 4 [231 231 229]\n",
            "Example prediction:\n",
            " 6 [231 231 229]\n",
            "Example prediction:\n",
            " 8 [231 231 229]\n",
            "Example prediction:\n",
            " 10 [231 231 229]\n",
            "Example prediction:\n",
            " 12 [231 231 229]\n",
            "Example prediction:\n",
            " 14 [231 231 229]\n",
            "Example prediction:\n",
            " 16 [231 231 229]\n",
            "Example prediction:\n",
            " 18 [231 231 229]\n",
            "Example prediction:\n",
            " 20 [231 231 229]\n",
            "Example prediction:\n",
            " 22 [231 231 229]\n",
            "Building Eagle_lodging_Edgardo\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_24 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_25 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_26 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [188 189 196]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 7ms/step - loss: 9955.2230\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 8807.9057\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 8234.6635\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 7596.9244\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 7458.7482\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 6799.4372\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 6038.0541\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 5826.9983\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 5254.6029\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 5122.4482\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 4963.2629\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 4384.1687\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 4430.0399\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 4249.5009\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3982.3290\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3724.2219\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3742.7174\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3652.9403\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3624.7397\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3479.4131\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3489.5095\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3352.3557\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3385.9036\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3290.9769\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3447.5609\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3348.3546\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3367.0650\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3400.0609\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3382.9688\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3336.3069\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3434.0402\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3434.7339\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3345.8840\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3388.4362\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3359.2705\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3327.6517\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3395.1079\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3452.8478\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3351.2438\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2922.0807\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2717.0419\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2575.4127\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2454.6866\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2346.9877\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2264.3168\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2181.6154\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2137.0337\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2122.7792\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2034.8289\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2001.6026\n",
            "mean,rmse,rmse/mean,bldg: 81.9636656538589 46.42998054396747 0.5664702789165886 Eagle_lodging_Edgardo\n",
            "Example prediction:\n",
            " 0 [114 114 114]\n",
            "Example prediction:\n",
            " 2 [121 121 121]\n",
            "Example prediction:\n",
            " 4 [ 99 100  99]\n",
            "Example prediction:\n",
            " 6 [115 115 115]\n",
            "Example prediction:\n",
            " 8 [121 121 121]\n",
            "Example prediction:\n",
            " 10 [ 99 100  99]\n",
            "Example prediction:\n",
            " 12 [121 120 121]\n",
            "Example prediction:\n",
            " 14 [121 121 121]\n",
            "Example prediction:\n",
            " 16 [119 119 119]\n",
            "Example prediction:\n",
            " 18 [121 121 121]\n",
            "Example prediction:\n",
            " 20 [121 121 121]\n",
            "Example prediction:\n",
            " 22 [121 120 121]\n",
            "Building Eagle_education_Cassie\n",
            "Building Eagle_education_Peter\n",
            " Count bad values before pseudofill: 34\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_27 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_28 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_29 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [5919 5794 6162]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 7ms/step - loss: 12972300.8139\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12808388.5693\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12866515.9927\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 13012317.3759\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12781102.5109\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12734749.4672\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12977198.1350\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12660727.7737\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12686651.6314\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12584313.0620\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12683887.1168\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12571012.5292\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12551445.8796\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12638911.1387\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12340784.9672\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12535708.1642\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12728764.0328\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12645732.6387\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12560019.8358\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12521009.2555\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12269010.6752\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12330004.2920\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12335252.8978\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12264517.0219\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12244947.7007\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12362043.1423\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12231297.4635\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12132576.7299\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12089652.7080\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12001829.8942\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12075429.5985\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 12122370.5839\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12261906.9745\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12002170.9380\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 11902066.9781\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11788764.6350\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11890110.2080\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11787812.0693\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11822433.3650\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 11752173.7445\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 11949075.0803\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 11693203.1606\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11653181.8832\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11803433.3212\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11657293.3577\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11564178.3613\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11587724.1241\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11749306.3723\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11503152.7226\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11359955.2117\n",
            "mean,rmse,rmse/mean,bldg: 3154.8298985018228 3028.2619866791506 0.9598812246952594 Eagle_education_Peter\n",
            "Example prediction:\n",
            " 0 [232 233 233]\n",
            "Example prediction:\n",
            " 2 [232 233 233]\n",
            "Example prediction:\n",
            " 4 [232 233 233]\n",
            "Example prediction:\n",
            " 6 [232 233 233]\n",
            "Example prediction:\n",
            " 8 [232 233 233]\n",
            "Example prediction:\n",
            " 10 [232 233 233]\n",
            "Example prediction:\n",
            " 12 [232 233 233]\n",
            "Example prediction:\n",
            " 14 [232 233 233]\n",
            "Example prediction:\n",
            " 16 [232 233 233]\n",
            "Example prediction:\n",
            " 18 [232 233 233]\n",
            "Example prediction:\n",
            " 20 [232 233 233]\n",
            "Example prediction:\n",
            " 22 [232 233 233]\n",
            "Building Eagle_health_Gregoria\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_32 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 637148.1750\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 600335.0496\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 598463.6738\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 600770.2073\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 571577.4998\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 601606.3246\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 580170.8968\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 589187.6685\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 563746.3668\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 571383.0305\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 585113.5703\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 593604.4076\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 539543.0246\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 575490.2042\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 590369.5080\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 545326.3769\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 541966.4364\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 544318.8249\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 553984.6029\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 545333.2345\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 552835.5707\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 523236.8971\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 532408.5328\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 534131.3276\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 522180.0827\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 550708.5412\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 503714.8639\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 496935.3756\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 520266.5798\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 519000.1050\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 497213.1859\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 500256.5351\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 507298.5707\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 511370.9050\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 484660.4662\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 480301.3422\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 483751.7377\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 491085.0596\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 452690.1248\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 468248.3724\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 434606.0339\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 451220.7080\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 467247.0672\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 446762.2271\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 439968.2020\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 461589.0872\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 433039.1857\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 456012.0755\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 427279.8970\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 436014.7113\n",
            "mean,rmse,rmse/mean,bldg: 659.5054129061737 756.758670892579 1.147463926880978 Eagle_health_Gregoria\n",
            "Example prediction:\n",
            " 0 [204 205 207]\n",
            "Example prediction:\n",
            " 2 [214 215 217]\n",
            "Example prediction:\n",
            " 4 [159 160 161]\n",
            "Example prediction:\n",
            " 6 [201 202 203]\n",
            "Example prediction:\n",
            " 8 [214 215 216]\n",
            "Example prediction:\n",
            " 10 [214 214 216]\n",
            "Example prediction:\n",
            " 12 [214 214 216]\n",
            "Example prediction:\n",
            " 14 [214 214 216]\n",
            "Example prediction:\n",
            " 16 [214 214 216]\n",
            "Example prediction:\n",
            " 18 [214 214 216]\n",
            "Example prediction:\n",
            " 20 [214 214 216]\n",
            "Example prediction:\n",
            " 22 [213 214 216]\n",
            "Building Eagle_lodging_Dawn\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_33 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_34 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_35 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [240 242 266]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 7ms/step - loss: 13537.4848\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12332.6275\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11739.6262\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10759.8935\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9921.7865\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9445.3024\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8937.4036\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8318.2062\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7671.7351\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7351.8052\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7032.3991\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6375.6801\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6143.9989\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 5641.6457\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5323.6740\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 5096.1386\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4853.1111\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4447.0150\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4478.9427\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4328.2905\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3927.1517\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3834.0643\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3861.4326\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3728.9867\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3775.3959\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3861.1012\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3570.9449\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3580.2293\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3473.6797\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3554.0627\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3444.6331\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3698.7901\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3608.0561\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3585.3668\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3470.5663\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3695.5578\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 3494.2082\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3246.3598\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2802.6340\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2642.5308\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2550.6562\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2485.0353\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2202.5671\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2359.7698\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 2289.9087\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2158.9094\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2018.3972\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1872.5952\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1963.5677\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 1944.5571\n",
            "mean,rmse,rmse/mean,bldg: 92.8091523125402 45.789525793164124 0.49337295570770046 Eagle_lodging_Dawn\n",
            "Example prediction:\n",
            " 0 [149 149 149]\n",
            "Example prediction:\n",
            " 2 [147 148 147]\n",
            "Example prediction:\n",
            " 4 [147 147 147]\n",
            "Example prediction:\n",
            " 6 [148 149 148]\n",
            "Example prediction:\n",
            " 8 [148 149 149]\n",
            "Example prediction:\n",
            " 10 [149 149 149]\n",
            "Example prediction:\n",
            " 12 [149 149 149]\n",
            "Example prediction:\n",
            " 14 [149 149 149]\n",
            "Example prediction:\n",
            " 16 [149 149 149]\n",
            "Example prediction:\n",
            " 18 [149 149 149]\n",
            "Example prediction:\n",
            " 20 [149 149 149]\n",
            "Example prediction:\n",
            " 22 [149 149 149]\n",
            "Building Eagle_office_Nereida\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_36 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_37 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_38 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [  0   0 461]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 72176.7085\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 69272.5168\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 66969.5620\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 64551.3342\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 63129.6562\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 7ms/step - loss: 61393.9655\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 58930.9087\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 56984.9459\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 54854.5218\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 53678.5140\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 51125.1197\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 50181.8707\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 47890.5444\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 46493.2788\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 44546.0726\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 43686.3050\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 41966.7869\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 40312.4077\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 39695.7041\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 38641.9125\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 35994.0062\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 35843.9724\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 34256.9327\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 33280.4057\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 31736.4902\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 30348.6280\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 28431.8654\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 27683.7123\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 26636.3110\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 25723.0903\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24689.6218\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 23063.7112\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 22461.0652\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 21588.5507\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 21037.4499\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19691.3562\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19416.6501\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 18743.9926\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 17321.9639\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16469.8295\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16108.0181\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15598.7538\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14882.6368\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14050.9848\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13870.0737\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13200.8354\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12855.7758\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11892.0962\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11363.3477\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10678.9373\n",
            "mean,rmse,rmse/mean,bldg: 273.01729748007574 119.69057400710204 0.43839923371828415 Eagle_office_Nereida\n",
            "Example prediction:\n",
            " 0 [210 214 211]\n",
            "Example prediction:\n",
            " 2 [210 214 211]\n",
            "Example prediction:\n",
            " 4 [210 214 211]\n",
            "Example prediction:\n",
            " 6 [210 214 211]\n",
            "Example prediction:\n",
            " 8 [210 214 211]\n",
            "Example prediction:\n",
            " 10 [210 214 211]\n",
            "Example prediction:\n",
            " 12 [210 214 211]\n",
            "Example prediction:\n",
            " 14 [210 214 211]\n",
            "Example prediction:\n",
            " 16 [210 214 211]\n",
            "Example prediction:\n",
            " 18 [210 214 211]\n",
            "Example prediction:\n",
            " 20 [210 214 211]\n",
            "Example prediction:\n",
            " 22 [210 214 211]\n",
            "Building Eagle_lodging_Tressa\n",
            "Building Eagle_education_Eileen\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_39 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_40 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_41 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [ 0  0 17]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 2468.5215\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2012.4116\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1723.2996\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1457.4211\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1288.5228\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1152.7891\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1009.2968\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 934.6180\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 858.6210\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 813.6172\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 767.8390\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 749.7025\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 726.0143\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 741.5542\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 701.0593\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 720.8409\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 677.3651\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 705.9091\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 699.2540\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 700.7858\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 712.7140\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 716.0458\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 714.7847\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 716.9906\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 707.6709\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 696.0583\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 723.0659\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 708.8355\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 716.0644\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 702.1867\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 712.2151\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 679.2375\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 718.1651\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 627.4219\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 536.7956\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 500.6438\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 489.0325\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 489.8751\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 460.8268\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 444.1589\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 453.4542\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 435.4032\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 442.2909\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 440.1644\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 421.4385\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 419.2499\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 415.4782\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 421.1027\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 416.7481\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 414.0757\n",
            "mean,rmse,rmse/mean,bldg: 46.462781809371094 22.622935669843663 0.4869044596309736 Eagle_education_Eileen\n",
            "Example prediction:\n",
            " 0 [50 50 49]\n",
            "Example prediction:\n",
            " 2 [49 49 48]\n",
            "Example prediction:\n",
            " 4 [52 52 51]\n",
            "Example prediction:\n",
            " 6 [48 48 48]\n",
            "Example prediction:\n",
            " 8 [48 47 47]\n",
            "Example prediction:\n",
            " 10 [51 51 50]\n",
            "Example prediction:\n",
            " 12 [47 47 46]\n",
            "Example prediction:\n",
            " 14 [47 46 46]\n",
            "Example prediction:\n",
            " 16 [50 50 50]\n",
            "Example prediction:\n",
            " 18 [45 45 45]\n",
            "Example prediction:\n",
            " 20 [49 48 48]\n",
            "Example prediction:\n",
            " 22 [49 48 48]\n",
            "Building Eagle_education_Wesley\n",
            " Count bad values before pseudofill: 112\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_42 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_43 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_44 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 0.0108\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.8176e-04\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.6161e-04\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.5284e-04\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.2844e-04\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.3052e-04\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.2536e-04\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.2271e-04\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.2041e-04\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.9105e-04\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.0836e-04\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.1875e-04\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.0020e-04\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.7830e-04\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.2225e-04\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.8351e-04\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6.1517e-04\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.9587e-04\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.7755e-04\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.8312e-04\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.8448e-04\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.9097e-04\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.4971e-04\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.4466e-04\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.2711e-04\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.3378e-04\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.2388e-04\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.2636e-04\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.2334e-04\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.2757e-04\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.0722e-04\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5.1134e-04\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.9472e-04\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.8375e-04\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.8969e-04\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.8524e-04\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.6482e-04\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5686e-04\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5383e-04\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.7957e-04\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.6985e-04\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.4717e-04\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5265e-04\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.6986e-04\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.4804e-04\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5584e-04\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5298e-04\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.4828e-04\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.4065e-04\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4.5594e-04\n",
            "mean,rmse,rmse/mean,bldg: 0.10558919611442527 0.02905595610921429 0.27517925297704543 Eagle_education_Wesley\n",
            "Example prediction:\n",
            " 0 [0 0 0]\n",
            "Example prediction:\n",
            " 2 [0 0 0]\n",
            "Example prediction:\n",
            " 4 [0 0 0]\n",
            "Example prediction:\n",
            " 6 [0 0 0]\n",
            "Example prediction:\n",
            " 8 [0 0 0]\n",
            "Example prediction:\n",
            " 10 [0 0 0]\n",
            "Example prediction:\n",
            " 12 [0 0 0]\n",
            "Example prediction:\n",
            " 14 [0 0 0]\n",
            "Example prediction:\n",
            " 16 [0 0 0]\n",
            "Example prediction:\n",
            " 18 [0 0 0]\n",
            "Example prediction:\n",
            " 20 [0 0 0]\n",
            "Example prediction:\n",
            " 22 [0 0 0]\n",
            "Building Eagle_health_Vincenza\n",
            " Count bad values before pseudofill: 75\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_45 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_46 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_47 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [234 121  69]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 17152.9893\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15740.6369\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14678.1229\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13708.3378\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12909.8263\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12101.8799\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11390.8514\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10647.7343\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10008.6803\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9288.4653\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8876.5574\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8133.2673\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7509.9861\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7186.9172\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6917.7798\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6278.7590\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5928.2343\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5571.2944\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5460.3906\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4983.0244\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4712.7745\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4562.1611\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4338.0248\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4224.7107\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4002.7669\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3986.3088\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3755.5342\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3712.5247\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3618.8385\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3574.4018\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3537.2113\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3481.8713\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3477.0126\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3466.7114\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3445.6023\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3480.1218\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3438.5206\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3455.2684\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3439.8054\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3412.3349\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3474.1400\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3410.0165\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3443.8317\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3433.9510\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3455.8176\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3487.7228\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3419.6246\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3415.8222\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3377.5640\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3395.7233\n",
            "mean,rmse,rmse/mean,bldg: 122.36347174423398 56.3235921892051 0.4602974350624306 Eagle_health_Vincenza\n",
            "Example prediction:\n",
            " 0 [119 119 119]\n",
            "Example prediction:\n",
            " 2 [119 119 119]\n",
            "Example prediction:\n",
            " 4 [119 119 119]\n",
            "Example prediction:\n",
            " 6 [119 119 119]\n",
            "Example prediction:\n",
            " 8 [119 119 119]\n",
            "Example prediction:\n",
            " 10 [119 119 119]\n",
            "Example prediction:\n",
            " 12 [119 119 119]\n",
            "Example prediction:\n",
            " 14 [119 119 119]\n",
            "Example prediction:\n",
            " 16 [119 119 119]\n",
            "Example prediction:\n",
            " 18 [119 119 119]\n",
            "Example prediction:\n",
            " 20 [119 119 119]\n",
            "Example prediction:\n",
            " 22 [119 119 119]\n",
            "Building Eagle_office_Dallas\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_48 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_49 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_50 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [109 109 109]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 4206.0440\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3830.1353\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3830.6880\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3649.3785\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3233.9216\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3204.3917\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3259.5561\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3084.9357\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3273.9787\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2995.2713\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2894.6655\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2496.5571\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2803.7798\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2172.6637\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2248.6008\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2183.8584\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2172.5031\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2226.8002\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2050.9964\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1978.2679\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2234.6188\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2042.8892\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2045.0984\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2023.6994\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1928.6209\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1916.3732\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1933.7300\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1987.2328\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1776.8905\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2165.9633\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1732.0707\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2017.6718\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1817.5321\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1758.0970\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1770.0744\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1880.3464\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1895.1948\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1675.7104\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1845.3890\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1662.0271\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1983.2963\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1641.1258\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2011.2657\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1550.2706\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1672.3036\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1593.4642\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1574.8074\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1541.2657\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1453.7133\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1847.1055\n",
            "mean,rmse,rmse/mean,bldg: 56.5030097936379 48.629976496986096 0.8606617005818638 Eagle_office_Dallas\n",
            "Example prediction:\n",
            " 0 [31 33 33]\n",
            "Example prediction:\n",
            " 2 [58 58 58]\n",
            "Example prediction:\n",
            " 4 [30 30 31]\n",
            "Example prediction:\n",
            " 6 [47 46 46]\n",
            "Example prediction:\n",
            " 8 [37 39 40]\n",
            "Example prediction:\n",
            " 10 [16 17 18]\n",
            "Example prediction:\n",
            " 12 [17 18 19]\n",
            "Example prediction:\n",
            " 14 [63 62 62]\n",
            "Example prediction:\n",
            " 16 [53 51 51]\n",
            "Example prediction:\n",
            " 18 [46 45 45]\n",
            "Example prediction:\n",
            " 20 [55 54 54]\n",
            "Example prediction:\n",
            " 22 [52 51 51]\n",
            "Building Eagle_education_Shante\n",
            " Count bad values before pseudofill: 23\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_51 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_52 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_53 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 198218.0036\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 195093.7768\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 188122.9492\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 188546.8359\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 170923.2654\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 178911.1552\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 201177.4329\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 198026.3816\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 180461.8315\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 174096.8342\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 180736.1552\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 188639.3972\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 190129.1203\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 194656.6498\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 186706.7072\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 186388.0128\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 173854.0972\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 188559.2981\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 176670.4162\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 192848.3975\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 162837.3903\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 177222.3667\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 189013.0978\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 186076.0063\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 202452.2870\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 170553.9527\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 175564.5673\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 171065.6453\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 172003.1752\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 175926.6153\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 170530.4837\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 187039.5072\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 199065.5287\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 161788.1602\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 187029.9848\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 162655.2656\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 156550.4073\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 160341.1758\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 180414.5176\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 157692.7794\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 166191.6886\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 162667.5543\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 165120.3528\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 180062.0796\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 156999.9492\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 172147.5017\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 190282.9558\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 163624.3282\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 168382.9362\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 169340.4633\n",
            "mean,rmse,rmse/mean,bldg: 1003.9941709339338 1851.8393390884064 1.8444722018314026 Eagle_education_Shante\n",
            "Example prediction:\n",
            " 0 [167 165 163]\n",
            "Example prediction:\n",
            " 2 [167 165 163]\n",
            "Example prediction:\n",
            " 4 [167 165 163]\n",
            "Example prediction:\n",
            " 6 [167 165 163]\n",
            "Example prediction:\n",
            " 8 [167 165 163]\n",
            "Example prediction:\n",
            " 10 [167 165 163]\n",
            "Example prediction:\n",
            " 12 [167 165 163]\n",
            "Example prediction:\n",
            " 14 [167 165 163]\n",
            "Example prediction:\n",
            " 16 [167 165 163]\n",
            "Example prediction:\n",
            " 18 [167 165 163]\n",
            "Example prediction:\n",
            " 20 [167 165 163]\n",
            "Example prediction:\n",
            " 22 [167 165 163]\n",
            "Building Eagle_office_Chauncey\n",
            " Count bad values before pseudofill: 116\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_54 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_55 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_56 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [   0    0 1530]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 8ms/step - loss: 1098522.0173\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1080367.3830\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1074214.4313\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1071132.5983\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1052558.0075\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1026458.6193\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1031800.8198\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1020008.1606\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1026476.8791\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1002548.4366\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1003768.5931\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 996354.0173\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 983131.6786\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 982426.1159\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 955485.2117\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 958089.5853\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 956999.2787\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 947360.2162\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 936413.3932\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 922012.4615\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 907505.0689\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 908569.0778\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 908440.4840\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 893643.5059\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 885061.1366\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 869780.4183\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 870529.5522\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 856723.6521\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 853320.3994\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 847327.7429\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 831858.2949\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 826416.0465\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 820389.0194\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 821588.9206\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 809753.7030\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 789381.5242\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 804073.0203\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 785395.7213\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 782956.2977\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 774591.6102\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 762789.9973\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 766540.1850\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 754290.4400\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 745532.8248\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 741648.3349\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 729020.1859\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 717368.1349\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 716445.7607\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 712156.4653\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 710832.0328\n",
            "mean,rmse,rmse/mean,bldg: 1037.6368908901366 931.9587999700504 0.8981550368458564 Eagle_office_Chauncey\n",
            "Example prediction:\n",
            " 0 [233 232 229]\n",
            "Example prediction:\n",
            " 2 [233 232 229]\n",
            "Example prediction:\n",
            " 4 [233 232 229]\n",
            "Example prediction:\n",
            " 6 [233 232 229]\n",
            "Example prediction:\n",
            " 8 [233 232 229]\n",
            "Example prediction:\n",
            " 10 [233 232 229]\n",
            "Example prediction:\n",
            " 12 [233 232 229]\n",
            "Example prediction:\n",
            " 14 [233 232 229]\n",
            "Example prediction:\n",
            " 16 [233 232 229]\n",
            "Example prediction:\n",
            " 18 [233 232 229]\n",
            "Example prediction:\n",
            " 20 [233 232 229]\n",
            "Example prediction:\n",
            " 22 [233 232 229]\n",
            "Building Eagle_office_Phyllis\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_57 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_58 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_59 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [  0   0 158]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 9137.6805\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8091.0619\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7480.0173\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6751.0901\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6253.1208\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5698.8159\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5133.4592\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4710.2747\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4308.3036\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3917.3694\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3505.7666\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3268.8621\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2925.0685\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2734.7962\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2536.2376\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2326.2826\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2170.5045\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2053.7534\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1913.8251\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1785.0129\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1740.5363\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1657.0754\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1684.4827\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1578.6392\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1582.6552\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1549.4971\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1549.5649\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1541.1586\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1541.5592\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1564.0290\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1504.6034\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1589.6401\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1510.6894\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1571.1597\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1566.8712\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1522.3566\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1541.2184\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1540.8732\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1584.0367\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1536.9341\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1540.1355\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1539.1686\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1535.4913\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1547.2688\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1517.4015\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1524.2273\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1542.2457\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1602.6266\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1526.9047\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1271.5565\n",
            "mean,rmse,rmse/mean,bldg: 87.20950227834119 33.17920242080361 0.380453982123503 Eagle_office_Phyllis\n",
            "Example prediction:\n",
            " 0 [88 88 88]\n",
            "Example prediction:\n",
            " 2 [88 88 88]\n",
            "Example prediction:\n",
            " 4 [95 94 95]\n",
            "Example prediction:\n",
            " 6 [87 87 87]\n",
            "Example prediction:\n",
            " 8 [88 88 88]\n",
            "Example prediction:\n",
            " 10 [95 94 95]\n",
            "Example prediction:\n",
            " 12 [88 88 88]\n",
            "Example prediction:\n",
            " 14 [88 88 88]\n",
            "Example prediction:\n",
            " 16 [95 94 95]\n",
            "Example prediction:\n",
            " 18 [88 88 88]\n",
            "Example prediction:\n",
            " 20 [95 94 95]\n",
            "Example prediction:\n",
            " 22 [95 94 95]\n",
            "Building Eagle_office_Freida\n",
            " Count bad values before pseudofill: 63\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_60 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_61 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_62 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [433  41  89]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 20033.4619\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 18607.3192\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 17535.1813\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16422.7824\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15768.8294\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14797.8119\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14197.2427\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 13713.2479\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12798.9632\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 12275.2302\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 11270.3916\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10930.8989\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 10283.4627\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9854.3800\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9425.9758\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8749.2631\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8379.4061\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 8221.2947\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7760.2869\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7277.7969\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 7215.7544\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6830.9849\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6912.1183\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6406.1702\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6442.1841\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6042.9194\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6063.8831\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5852.3738\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5838.7768\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5618.0931\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5647.4689\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5610.0860\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5684.3842\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5522.3433\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5646.2635\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5600.0287\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5640.5071\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5470.5688\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5693.8137\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5609.2686\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5661.7871\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5607.0040\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5588.5236\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5629.6304\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5465.8212\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5516.6272\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4980.0935\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4775.5170\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4487.2679\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4428.8895\n",
            "mean,rmse,rmse/mean,bldg: 101.557715031556 55.723591189943065 0.5486889023904156 Eagle_office_Freida\n",
            "Example prediction:\n",
            " 0 [140 139 138]\n",
            "Example prediction:\n",
            " 2 [140 139 138]\n",
            "Example prediction:\n",
            " 4 [140 139 138]\n",
            "Example prediction:\n",
            " 6 [140 139 138]\n",
            "Example prediction:\n",
            " 8 [140 139 138]\n",
            "Example prediction:\n",
            " 10 [140 139 138]\n",
            "Example prediction:\n",
            " 12 [140 139 138]\n",
            "Example prediction:\n",
            " 14 [140 139 138]\n",
            "Example prediction:\n",
            " 16 [140 139 138]\n",
            "Example prediction:\n",
            " 18 [140 139 138]\n",
            "Example prediction:\n",
            " 20 [140 139 138]\n",
            "Example prediction:\n",
            " 22 [140 139 138]\n",
            "Building Eagle_office_Francis\n",
            " Count bad values before pseudofill: 20\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_63 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_64 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_65 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [426 420 390]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 88195.5844\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 84684.0293\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 81805.7867\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 80195.4599\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 78045.8816\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 74877.0062\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 72824.8713\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 71005.8631\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 67906.2168\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 65641.3825\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 63781.5883\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 62595.2837\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 59890.1998\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 57794.2511\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 57311.5886\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 55347.7773\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 52960.1097\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 51024.6673\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 48022.1602\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46526.7682\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 45404.7001\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 43902.9511\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 42159.7313\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 40650.2244\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 39403.3765\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 37335.4806\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 35969.1083\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 35834.1584\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 33540.9497\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 32049.5079\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 30577.9612\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 29946.3673\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 28980.4076\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 27373.4066\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 26180.5737\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 26260.6141\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24224.6394\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 23261.1411\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 22265.4897\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 21390.4000\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20670.5915\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19738.9731\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 19155.7819\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 18293.5384\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 17221.9668\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16498.9303\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 16101.1238\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 15498.7920\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14734.6780\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 14260.9694\n",
            "mean,rmse,rmse/mean,bldg: 336.48649201094844 204.92097962638414 0.6090020981279585 Eagle_office_Francis\n",
            "Example prediction:\n",
            " 0 [214 213 213]\n",
            "Example prediction:\n",
            " 2 [214 213 213]\n",
            "Example prediction:\n",
            " 4 [214 213 213]\n",
            "Example prediction:\n",
            " 6 [214 213 213]\n",
            "Example prediction:\n",
            " 8 [214 213 213]\n",
            "Example prediction:\n",
            " 10 [214 213 213]\n",
            "Example prediction:\n",
            " 12 [214 213 213]\n",
            "Example prediction:\n",
            " 14 [214 213 213]\n",
            "Example prediction:\n",
            " 16 [214 213 213]\n",
            "Example prediction:\n",
            " 18 [214 213 213]\n",
            "Example prediction:\n",
            " 20 [214 213 213]\n",
            "Example prediction:\n",
            " 22 [214 213 213]\n",
            "Building Eagle_office_Sheree\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_66 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_67 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_68 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [105  20  89]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 6s 8ms/step - loss: 4846.8256\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4237.8800\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3753.5393\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3435.5285\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3241.3638\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2896.1652\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2693.6506\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2479.8610\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2295.0954\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2311.7356\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2165.2194\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2124.2036\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2035.5407\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 2015.9410\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1968.9020\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1999.5658\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1946.1980\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1914.5615\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1856.1011\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1659.0833\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1671.6862\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1570.8736\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1520.2957\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1454.3213\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1484.1828\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1406.2734\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1394.1614\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1388.8109\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1346.4099\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1283.8824\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1309.6746\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1273.2214\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1254.2112\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1300.8468\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1269.8061\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1228.6875\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1230.6015\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1250.0683\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1242.7660\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1245.1033\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1251.1838\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1267.2072\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1225.5532\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1228.9379\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1201.5083\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1199.9188\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1214.8095\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1169.8054\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1184.9414\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 1176.8515\n",
            "mean,rmse,rmse/mean,bldg: 62.02257521757287 43.641059533315094 0.703631853082912 Eagle_office_Sheree\n",
            "Example prediction:\n",
            " 0 [101 101 100]\n",
            "Example prediction:\n",
            " 2 [101 101 101]\n",
            "Example prediction:\n",
            " 4 [101 101 101]\n",
            "Example prediction:\n",
            " 6 [94 94 93]\n",
            "Example prediction:\n",
            " 8 [101 101 101]\n",
            "Example prediction:\n",
            " 10 [101 101 101]\n",
            "Example prediction:\n",
            " 12 [101 101 101]\n",
            "Example prediction:\n",
            " 14 [101 101 101]\n",
            "Example prediction:\n",
            " 16 [101 101 101]\n",
            "Example prediction:\n",
            " 18 [101 101 101]\n",
            "Example prediction:\n",
            " 20 [101 101 101]\n",
            "Example prediction:\n",
            " 22 [101 101 101]\n",
            "Building Eagle_education_Sherrill\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_69 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_70 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_71 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [3817 3808 3940]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 5508550.2719\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5626952.2372\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5534740.1277\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5464226.2464\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5490564.5839\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5468777.0566\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5470311.5146\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5349845.8850\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5413802.3704\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5387997.9927\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5315783.6989\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5279152.3276\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5351445.4507\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5187920.9599\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5355190.5438\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5138534.1296\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5260851.5876\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5253402.6880\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5239242.0474\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5103557.3558\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5098890.7883\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5146755.0365\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5189582.0146\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5049750.8978\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5094864.5675\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5028324.3193\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5181964.9507\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5028034.1515\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4995433.8923\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 5089724.6241\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4905491.6597\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4921714.5931\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4894387.4653\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4860647.4234\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4969177.4544\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4905640.5137\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4818582.1615\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4815178.0182\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4789785.3978\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4857036.6825\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4867359.8412\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4660491.0520\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4719474.1305\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4746176.9964\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4740246.0036\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4764523.3577\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4730104.4161\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4622894.7947\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4634334.5839\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4657213.6077\n",
            "mean,rmse,rmse/mean,bldg: 2032.483907505765 2068.783433032509 1.0178596865602199 Eagle_education_Sherrill\n",
            "Example prediction:\n",
            " 0 [231 234 229]\n",
            "Example prediction:\n",
            " 2 [231 234 229]\n",
            "Example prediction:\n",
            " 4 [231 234 229]\n",
            "Example prediction:\n",
            " 6 [231 234 229]\n",
            "Example prediction:\n",
            " 8 [231 234 229]\n",
            "Example prediction:\n",
            " 10 [231 234 229]\n",
            "Example prediction:\n",
            " 12 [231 234 229]\n",
            "Example prediction:\n",
            " 14 [231 234 229]\n",
            "Example prediction:\n",
            " 16 [231 234 229]\n",
            "Example prediction:\n",
            " 18 [231 234 229]\n",
            "Example prediction:\n",
            " 20 [231 234 229]\n",
            "Example prediction:\n",
            " 22 [231 234 229]\n",
            "Building Eagle_education_Brooke\n",
            " Count bad values before pseudofill: 56\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_72 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_73 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_74 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [3184 2594 4551]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 4683007.0858\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4778485.4343\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4622809.7245\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4601390.4434\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4710395.7682\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4617042.1058\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4674019.7573\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4521341.5374\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4543991.8796\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4521268.6077\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4558859.7828\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4503730.2500\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4468258.9489\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4505192.5155\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4415687.6122\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4429201.8431\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4422798.5520\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4414459.3786\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4399420.5593\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4390298.5867\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4389046.8996\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4287377.8832\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4348287.2628\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4338581.8768\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4246012.1688\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4241573.8349\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4234435.0803\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4285246.7509\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4243382.5520\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4134018.6606\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4147895.4498\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4169896.2865\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4225412.1223\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4145990.3887\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4134055.0675\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4117045.0036\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4158047.0520\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4095133.4964\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4002391.8440\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4089476.4662\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4109584.3075\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4001670.9672\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 4111214.4005\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3991530.3403\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4057443.8212\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3866958.3367\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3954923.2245\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3938557.9325\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3982965.9297\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 3944848.3303\n",
            "mean,rmse,rmse/mean,bldg: 1639.356375181079 1628.501555768039 0.993378609082579 Eagle_education_Brooke\n",
            "Example prediction:\n",
            " 0 [232 232 231]\n",
            "Example prediction:\n",
            " 2 [232 232 231]\n",
            "Example prediction:\n",
            " 4 [232 232 231]\n",
            "Example prediction:\n",
            " 6 [232 232 231]\n",
            "Example prediction:\n",
            " 8 [232 232 231]\n",
            "Example prediction:\n",
            " 10 [232 232 231]\n",
            "Example prediction:\n",
            " 12 [232 232 231]\n",
            "Example prediction:\n",
            " 14 [232 232 231]\n",
            "Example prediction:\n",
            " 16 [232 232 231]\n",
            "Example prediction:\n",
            " 18 [232 232 231]\n",
            "Example prediction:\n",
            " 20 [232 232 231]\n",
            "Example prediction:\n",
            " 22 [232 232 231]\n",
            "Building Eagle_education_Alberto\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_75 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_76 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_77 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [   0    0 1259]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 8ms/step - loss: 607515.4726\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 599985.3854\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 590896.6875\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 593428.6250\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 583939.1186\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 568470.5625\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 566707.5918\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 557513.9275\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 563420.3996\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 547133.0809\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 540575.0933\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 534974.2315\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 525684.5977\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 521301.8552\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 521846.6414\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 513921.2396\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 501317.6590\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 502094.0196\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 488988.8651\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 486013.5794\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 480390.3897\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 480644.9992\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 469223.4845\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 470189.0772\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 456944.1243\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 448623.0349\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 446672.0862\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 451652.1175\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 444656.8255\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 437084.2459\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 431552.5347\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 422633.4649\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 416768.9364\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 415556.4401\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 417108.1919\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 402944.8173\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 399564.6034\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 393464.0741\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 390912.5853\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 389456.0950\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 379817.9553\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 373601.1677\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 372282.7905\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 359147.2854\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 359005.2617\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 359391.3628\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 349651.9009\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 348258.5013\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 348561.8774\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 333814.5167\n",
            "mean,rmse,rmse/mean,bldg: 694.962522886029 519.9393487226387 0.7481545142368873 Eagle_education_Alberto\n",
            "Example prediction:\n",
            " 0 [230 230 229]\n",
            "Example prediction:\n",
            " 2 [230 230 229]\n",
            "Example prediction:\n",
            " 4 [230 230 229]\n",
            "Example prediction:\n",
            " 6 [230 230 229]\n",
            "Example prediction:\n",
            " 8 [230 230 229]\n",
            "Example prediction:\n",
            " 10 [230 230 229]\n",
            "Example prediction:\n",
            " 12 [230 230 229]\n",
            "Example prediction:\n",
            " 14 [230 230 229]\n",
            "Example prediction:\n",
            " 16 [230 230 229]\n",
            "Example prediction:\n",
            " 18 [230 230 229]\n",
            "Example prediction:\n",
            " 20 [230 230 229]\n",
            "Example prediction:\n",
            " 22 [230 230 229]\n",
            "Building Eagle_food_Kay\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_78 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_79 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_80 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [656 426 284]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 129442.2140\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 122232.0384\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 120647.3999\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 117650.9462\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 116665.5788\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 110982.7671\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 112621.7069\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 108775.0961\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 104223.2782\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 103334.3406\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 102037.3616\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 100124.9110\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 98027.5087\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 96386.6017\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 92029.2933\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 89753.8140\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 89931.8284\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 90692.7609\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 83572.2623\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 83368.5876\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 81783.7462\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 80594.2126\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 76427.4216\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 76195.4263\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 75131.7087\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 72193.4760\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 71524.4650\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 68641.7206\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 69229.1040\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 67981.0422\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 68027.5950\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 64982.6297\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 63528.2834\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 62300.7536\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 62148.1706\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 60210.9031\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 58320.3910\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 58991.7736\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 57162.3430\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 54840.4740\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 53150.8380\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 51232.9736\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 52196.3543\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 50578.4851\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 50439.9910\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 50243.2356\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 49321.5876\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 47839.2340\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46449.3444\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46048.8647\n",
            "mean,rmse,rmse/mean,bldg: 276.2706673678431 176.0221303484934 0.6371365155249259 Eagle_food_Kay\n",
            "Example prediction:\n",
            " 0 [213 212 213]\n",
            "Example prediction:\n",
            " 2 [213 212 213]\n",
            "Example prediction:\n",
            " 4 [213 212 213]\n",
            "Example prediction:\n",
            " 6 [213 212 213]\n",
            "Example prediction:\n",
            " 8 [213 212 213]\n",
            "Example prediction:\n",
            " 10 [213 212 213]\n",
            "Example prediction:\n",
            " 12 [213 212 213]\n",
            "Example prediction:\n",
            " 14 [213 212 213]\n",
            "Example prediction:\n",
            " 16 [213 212 213]\n",
            "Example prediction:\n",
            " 18 [213 212 213]\n",
            "Example prediction:\n",
            " 20 [213 212 213]\n",
            "Example prediction:\n",
            " 22 [213 212 213]\n",
            "Building Eagle_health_Jodi\n",
            " Count bad values before pseudofill: 41\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_81 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_82 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_83 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [298 290 329]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 35831.6845\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 33394.8474\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 32169.8302\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29923.6576\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28863.1443\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27838.9964\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26474.5817\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25188.8634\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24049.6920\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 23605.9378\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22276.7021\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 21207.3957\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 19984.7488\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 19096.1241\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 18083.0722\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17177.5436\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16569.4614\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15809.7479\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14990.7702\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14287.4724\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 13625.2804\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13224.8780\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12687.2733\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11736.1662\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11327.1429\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10984.8483\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10486.3315\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9799.4005\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 9576.3651\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9072.6434\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8788.4947\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8358.0072\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8187.7738\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8058.3701\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7769.2693\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7463.0886\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7396.4485\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7208.5288\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7061.8453\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7018.2753\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6900.1619\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6791.5200\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6751.2507\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6712.8327\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6610.7136\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6631.4865\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6623.5373\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6602.8973\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 6646.5736\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6848.7422\n",
            "mean,rmse,rmse/mean,bldg: 192.4223112628316 86.16112815016668 0.4477709865592369 Eagle_health_Jodi\n",
            "Example prediction:\n",
            " 0 [170 169 169]\n",
            "Example prediction:\n",
            " 2 [170 169 169]\n",
            "Example prediction:\n",
            " 4 [170 169 169]\n",
            "Example prediction:\n",
            " 6 [170 169 169]\n",
            "Example prediction:\n",
            " 8 [170 169 169]\n",
            "Example prediction:\n",
            " 10 [170 169 169]\n",
            "Example prediction:\n",
            " 12 [170 169 169]\n",
            "Example prediction:\n",
            " 14 [170 169 169]\n",
            "Example prediction:\n",
            " 16 [170 169 169]\n",
            "Example prediction:\n",
            " 18 [170 169 169]\n",
            "Example prediction:\n",
            " 20 [170 169 169]\n",
            "Example prediction:\n",
            " 22 [170 169 169]\n",
            "Building Eagle_education_Norah\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_84 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_85 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_86 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [1668 1744 1718]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 621148.7427\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 621054.5478\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 604790.1143\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 615003.5953\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 599837.0876\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 589911.1458\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 597907.6690\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 585312.0034\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 568409.2292\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 570286.6823\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 553659.5509\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 561405.9478\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 549387.2523\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 568552.7990\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 542492.7906\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 521715.6218\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 527006.4557\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 522005.3947\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 522887.8842\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 509257.2795\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 496275.8011\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 500975.6188\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 491921.3288\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 492189.1594\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 492615.7346\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 475471.1836\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 478000.2040\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 475376.6708\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 461345.7202\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 460951.2806\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 441741.6136\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 464940.0950\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 440798.2885\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 448129.9461\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 440122.6369\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 428091.4607\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 432661.5029\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 433268.7400\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 414952.4595\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 407487.9513\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 402552.6358\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 406179.8286\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 401835.9269\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 396210.8264\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 389216.4140\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 388741.5895\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 391821.6402\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 381056.5942\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 378219.2602\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 389242.2170\n",
            "mean,rmse,rmse/mean,bldg: 712.0113639930826 659.339834879453 0.9260243139684757 Eagle_education_Norah\n",
            "Example prediction:\n",
            " 0 [226 226 228]\n",
            "Example prediction:\n",
            " 2 [226 226 228]\n",
            "Example prediction:\n",
            " 4 [226 226 228]\n",
            "Example prediction:\n",
            " 6 [226 226 228]\n",
            "Example prediction:\n",
            " 8 [226 226 228]\n",
            "Example prediction:\n",
            " 10 [226 226 228]\n",
            "Example prediction:\n",
            " 12 [226 226 228]\n",
            "Example prediction:\n",
            " 14 [226 226 228]\n",
            "Example prediction:\n",
            " 16 [226 226 228]\n",
            "Example prediction:\n",
            " 18 [226 226 228]\n",
            "Example prediction:\n",
            " 20 [226 226 228]\n",
            "Example prediction:\n",
            " 22 [226 226 228]\n",
            "Building Eagle_education_Will\n",
            " Count bad values before pseudofill: 15\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_87 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_88 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_89 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [326 330 345]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 77043.0872\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 74149.0359\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 72126.5524\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 70732.4371\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 67885.9916\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 65580.9153\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 63206.6494\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 60903.3393\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 58746.2372\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 56627.9553\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 54884.1968\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 53614.5273\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 51030.4091\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 49661.3324\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 47854.6838\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46020.6438\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 45554.3294\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 42123.0220\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 41134.5368\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 40199.9090\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 38634.1822\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 36925.4727\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 35419.8686\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 34200.7601\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 33323.7645\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 31336.9653\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 30340.5479\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29356.3991\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27978.8483\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27672.7644\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25267.5161\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24877.5791\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24267.1952\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22628.5433\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 21667.2098\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20943.2076\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20047.0599\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 19101.0356\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 18914.4669\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17870.7056\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17051.4150\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16482.4941\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16269.0542\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15922.3367\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14787.8203\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13842.2061\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13280.0221\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12475.6893\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12338.8793\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11637.9249\n",
            "mean,rmse,rmse/mean,bldg: 226.17039013254305 52.59731376284242 0.23255614376408298 Eagle_education_Will\n",
            "Example prediction:\n",
            " 0 [210 210 208]\n",
            "Example prediction:\n",
            " 2 [210 210 208]\n",
            "Example prediction:\n",
            " 4 [210 210 208]\n",
            "Example prediction:\n",
            " 6 [210 210 208]\n",
            "Example prediction:\n",
            " 8 [210 210 208]\n",
            "Example prediction:\n",
            " 10 [210 210 208]\n",
            "Example prediction:\n",
            " 12 [210 210 208]\n",
            "Example prediction:\n",
            " 14 [210 210 208]\n",
            "Example prediction:\n",
            " 16 [210 210 208]\n",
            "Example prediction:\n",
            " 18 [210 210 208]\n",
            "Example prediction:\n",
            " 20 [210 210 208]\n",
            "Example prediction:\n",
            " 22 [210 210 208]\n",
            "Building Eagle_lodging_Blake\n",
            " Count bad values before pseudofill: 8\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_90 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_91 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_92 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [4 5 6]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 29512.6006\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 31706.8561\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29283.6825\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27575.0009\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28147.7746\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28112.8484\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28907.0990\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28022.8790\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27963.1398\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27366.9640\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27528.0644\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26403.7878\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26797.9822\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26624.7222\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25210.5023\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26565.9197\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27486.8512\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27271.3387\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25370.7522\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27108.8046\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26352.8657\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27211.3511\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26596.7157\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25768.2851\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26684.4334\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26122.7058\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26455.4707\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26342.8057\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25051.3354\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27277.7534\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 24738.3232\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 27705.4266\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26410.0191\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26049.0167\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24467.4812\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25524.0984\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25574.3534\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25654.5510\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25241.1077\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24506.2530\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24797.9039\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24724.3292\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24467.4962\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25859.1268\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24302.5947\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 8ms/step - loss: 24165.4456\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24863.4739\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25302.4855\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26039.4142\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25153.8993\n",
            "mean,rmse,rmse/mean,bldg: 43.43471997795112 33.355557027482405 0.7679468647297548 Eagle_lodging_Blake\n",
            "Example prediction:\n",
            " 0 [101 102 102]\n",
            "Example prediction:\n",
            " 2 [102 102 102]\n",
            "Example prediction:\n",
            " 4 [102 102 102]\n",
            "Example prediction:\n",
            " 6 [102 102 102]\n",
            "Example prediction:\n",
            " 8 [102 102 102]\n",
            "Example prediction:\n",
            " 10 [102 102 102]\n",
            "Example prediction:\n",
            " 12 [102 102 102]\n",
            "Example prediction:\n",
            " 14 [102 102 102]\n",
            "Example prediction:\n",
            " 16 [102 102 102]\n",
            "Example prediction:\n",
            " 18 [102 102 102]\n",
            "Example prediction:\n",
            " 20 [102 102 102]\n",
            "Example prediction:\n",
            " 22 [102 102 102]\n",
            "Building Eagle_education_Petra\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_93 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_94 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_95 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [130 148 132]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 4258.3994\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3769.8783\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3263.4536\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2862.0438\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2654.4260\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2377.4753\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2119.0387\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2014.7565\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1799.0256\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1683.4066\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1628.6835\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1480.5811\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1510.3850\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1401.8257\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1422.7259\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1355.4288\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1349.4037\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1365.2181\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1359.5644\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1382.3078\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1391.1721\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1379.8731\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1383.1978\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1391.8789\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1323.3706\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 922.2524\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 772.5876\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 706.2064\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 636.9633\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 584.1447\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 538.7806\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 460.8958\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 463.3672\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 421.7873\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 371.9267\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 383.2871\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 347.0950\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 347.2337\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 330.7626\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 325.2848\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 301.7266\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 311.8058\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 292.6281\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 289.7547\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 284.6110\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 274.0035\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 259.1812\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 255.8322\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 242.7581\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 251.0563\n",
            "mean,rmse,rmse/mean,bldg: 57.04381605290169 24.532222395290443 0.43005927886275314 Eagle_education_Petra\n",
            "Example prediction:\n",
            " 0 [79 79 79]\n",
            "Example prediction:\n",
            " 2 [86 86 86]\n",
            "Example prediction:\n",
            " 4 [82 82 82]\n",
            "Example prediction:\n",
            " 6 [81 82 82]\n",
            "Example prediction:\n",
            " 8 [90 91 90]\n",
            "Example prediction:\n",
            " 10 [79 80 80]\n",
            "Example prediction:\n",
            " 12 [95 95 94]\n",
            "Example prediction:\n",
            " 14 [86 87 87]\n",
            "Example prediction:\n",
            " 16 [80 80 80]\n",
            "Example prediction:\n",
            " 18 [81 82 82]\n",
            "Example prediction:\n",
            " 20 [86 87 86]\n",
            "Example prediction:\n",
            " 22 [81 82 82]\n",
            "Building Eagle_lodging_Trina\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_96 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_97 (GRU)                 (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_98 (GRU)                 (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [405 275 270]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 12747.3588\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11906.6789\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11240.7432\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10700.7094\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9968.0581\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9345.2924\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8804.5030\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8359.0563\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7866.9083\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 7713.3683\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6991.8013\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6988.7290\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6572.2559\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6616.7982\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6395.6505\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6139.5971\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6133.5660\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5662.9383\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 5850.1461\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6043.0494\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5773.4242\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5380.7587\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5289.7080\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5407.7931\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5161.3299\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5549.7341\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5468.0126\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5229.9862\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5446.6099\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5466.4274\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5489.9653\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4889.8827\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4902.8309\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4371.1871\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4357.9220\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 4052.2140\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3754.1236\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3936.7840\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3718.1062\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3687.0143\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3515.9425\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3496.1069\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3454.4786\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3435.5882\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3264.7533\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3153.1454\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3057.1534\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3168.3367\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3163.1554\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2919.7430\n",
            "mean,rmse,rmse/mean,bldg: 91.27234855584753 53.780216912964555 0.5892279289828686 Eagle_lodging_Trina\n",
            "Example prediction:\n",
            " 0 [91 91 91]\n",
            "Example prediction:\n",
            " 2 [102 102 102]\n",
            "Example prediction:\n",
            " 4 [118 117 117]\n",
            "Example prediction:\n",
            " 6 [118 117 118]\n",
            "Example prediction:\n",
            " 8 [125 124 124]\n",
            "Example prediction:\n",
            " 10 [129 128 128]\n",
            "Example prediction:\n",
            " 12 [130 129 129]\n",
            "Example prediction:\n",
            " 14 [131 130 130]\n",
            "Example prediction:\n",
            " 16 [135 134 134]\n",
            "Example prediction:\n",
            " 18 [135 134 134]\n",
            "Example prediction:\n",
            " 20 [135 134 134]\n",
            "Example prediction:\n",
            " 22 [139 138 138]\n",
            "Building Eagle_health_Reuben\n",
            "Building Eagle_education_Teresa\n",
            " Count bad values before pseudofill: 35\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_99 (GRU)                 (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_100 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_101 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [470 390 405]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 30581.6919\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28888.1564\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26839.5413\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26552.3836\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25316.8390\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 23705.6195\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 23047.4334\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22276.6248\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20646.0844\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20145.0321\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 19093.2433\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 18279.9945\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17504.7531\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16017.4352\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16433.7878\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14614.3242\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14310.0686\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13709.6831\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13018.3489\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12935.8924\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12540.7972\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11442.1392\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11379.2672\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10372.3311\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10035.1230\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10249.4373\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9681.9208\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9683.3343\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9628.1347\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8875.1925\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8977.4727\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8723.4729\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8661.3020\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7978.9900\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8482.2422\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 8272.2029\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8135.4173\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8102.7928\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8011.0523\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8295.2596\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7974.8597\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7892.1827\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8169.0793\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7775.6964\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 7645.0092\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 7859.3823\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6309.7552\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6368.5779\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5912.1864\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5577.9101\n",
            "mean,rmse,rmse/mean,bldg: 148.73384346526427 48.676790840375574 0.32727447705433427 Eagle_education_Teresa\n",
            "Example prediction:\n",
            " 0 [172 172 171]\n",
            "Example prediction:\n",
            " 2 [171 172 170]\n",
            "Example prediction:\n",
            " 4 [172 172 171]\n",
            "Example prediction:\n",
            " 6 [166 166 165]\n",
            "Example prediction:\n",
            " 8 [170 170 169]\n",
            "Example prediction:\n",
            " 10 [172 172 171]\n",
            "Example prediction:\n",
            " 12 [169 170 169]\n",
            "Example prediction:\n",
            " 14 [172 172 171]\n",
            "Example prediction:\n",
            " 16 [172 172 171]\n",
            "Example prediction:\n",
            " 18 [172 172 171]\n",
            "Example prediction:\n",
            " 20 [172 173 171]\n",
            "Example prediction:\n",
            " 22 [172 172 171]\n",
            "Building Eagle_office_Norbert\n",
            " Count bad values before pseudofill: 52\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_102 (GRU)                (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_103 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_104 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [  0   0 607]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 153112.0597\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 146209.5895\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 142213.8914\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 139564.8306\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 135383.3112\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 134853.0145\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 130768.8146\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 128147.3612\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 123981.7938\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 121815.8442\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 119399.9247\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 116699.7749\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 115089.6052\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 111093.2719\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 108399.3954\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 105440.5587\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 103927.9936\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 101986.4278\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 99507.8691\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 96589.8348\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 92860.7036\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 92463.6762\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 90475.0624\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 87281.1941\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 84565.2824\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 83459.5784\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 81268.3165\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 78237.0276\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 76337.2094\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 74877.3965\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 72704.4561\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 70005.6662\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 68900.5197\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 67248.0761\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 64407.4362\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 63874.8894\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 61551.9837\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 59465.1080\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 58501.9180\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 56525.8772\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 56009.6950\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 54287.7373\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 51870.0563\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 50130.6638\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 49030.6987\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 47650.6915\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46378.3895\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 46086.3007\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 43440.6253\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 43433.1506\n",
            "mean,rmse,rmse/mean,bldg: 390.8100632860704 234.07258253660353 0.5989420553003109 Eagle_office_Norbert\n",
            "Example prediction:\n",
            " 0 [219 222 219]\n",
            "Example prediction:\n",
            " 2 [219 222 219]\n",
            "Example prediction:\n",
            " 4 [219 222 219]\n",
            "Example prediction:\n",
            " 6 [219 222 219]\n",
            "Example prediction:\n",
            " 8 [219 222 219]\n",
            "Example prediction:\n",
            " 10 [219 222 219]\n",
            "Example prediction:\n",
            " 12 [219 222 219]\n",
            "Example prediction:\n",
            " 14 [219 222 219]\n",
            "Example prediction:\n",
            " 16 [219 222 219]\n",
            "Example prediction:\n",
            " 18 [219 222 219]\n",
            "Example prediction:\n",
            " 20 [219 222 219]\n",
            "Example prediction:\n",
            " 22 [219 222 219]\n",
            "Building Eagle_lodging_Casey\n",
            "Building Eagle_office_Tia\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_105 (GRU)                (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_106 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_107 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [ 0  0 78]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 50845.1275\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 47284.6782\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 45867.5945\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 44785.1774\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 43024.6957\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 41368.1115\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 40411.2314\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 38265.6613\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 36984.0044\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 36427.5685\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 34813.6307\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 34406.4188\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 32599.8614\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 31014.0143\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29549.1484\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29557.0836\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 28666.7186\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26430.4214\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25638.2013\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 26003.8610\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24069.2075\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24524.5176\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 22857.0773\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22454.9495\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 21114.3768\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20205.3520\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 20264.3461\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 19443.9097\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 18742.9520\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 18064.1954\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17803.0852\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17313.4687\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17547.0820\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16235.1286\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15956.2289\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 16224.1778\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 15626.5578\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15171.6029\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14947.0837\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14909.3556\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14743.2997\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14429.8146\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14369.2419\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14187.4453\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14084.9425\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13668.0314\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13972.3352\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13735.1266\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13635.6159\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 13708.0781\n",
            "mean,rmse,rmse/mean,bldg: 174.6359145783468 129.0604853353637 0.7390260224935769 Eagle_office_Tia\n",
            "Example prediction:\n",
            " 0 [184 184 184]\n",
            "Example prediction:\n",
            " 2 [184 184 184]\n",
            "Example prediction:\n",
            " 4 [184 184 184]\n",
            "Example prediction:\n",
            " 6 [184 184 184]\n",
            "Example prediction:\n",
            " 8 [184 184 184]\n",
            "Example prediction:\n",
            " 10 [184 184 184]\n",
            "Example prediction:\n",
            " 12 [184 184 184]\n",
            "Example prediction:\n",
            " 14 [184 184 184]\n",
            "Example prediction:\n",
            " 16 [184 184 184]\n",
            "Example prediction:\n",
            " 18 [184 184 184]\n",
            "Example prediction:\n",
            " 20 [184 184 184]\n",
            "Example prediction:\n",
            " 22 [184 184 184]\n",
            "Building Eagle_office_Remedios\n",
            " Count bad values before pseudofill: 17\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_108 (GRU)                (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_109 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_110 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [  0   0 205]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 13869.7836\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12617.4921\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 11741.6162\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10853.1692\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 10246.7371\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9325.9276\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8715.3553\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 7991.6397\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7555.0165\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6976.7763\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 6326.0765\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5981.3846\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5653.2524\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5086.9920\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4823.8932\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4471.0989\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4175.0980\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3945.5269\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 3701.0665\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3464.5588\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 3204.6375\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3155.2146\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2951.4873\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2850.7877\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2824.2428\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2742.2300\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2648.4710\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2597.0090\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2565.8750\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2550.1258\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2472.3396\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2520.4816\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2451.6823\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2470.4171\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2498.1601\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2468.8757\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2454.8650\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2425.5118\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2489.1580\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2535.4271\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2493.6554\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2492.1269\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2541.0773\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2408.8643\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2475.5469\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2505.8232\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2526.8487\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2488.5970\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2509.7263\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2496.2431\n",
            "mean,rmse,rmse/mean,bldg: 121.48132139556034 48.13510570435901 0.39623462398490306 Eagle_office_Remedios\n",
            "Example prediction:\n",
            " 0 [109 109 109]\n",
            "Example prediction:\n",
            " 2 [109 109 109]\n",
            "Example prediction:\n",
            " 4 [109 109 109]\n",
            "Example prediction:\n",
            " 6 [109 109 109]\n",
            "Example prediction:\n",
            " 8 [109 109 109]\n",
            "Example prediction:\n",
            " 10 [109 109 109]\n",
            "Example prediction:\n",
            " 12 [109 109 109]\n",
            "Example prediction:\n",
            " 14 [109 109 109]\n",
            "Example prediction:\n",
            " 16 [109 109 109]\n",
            "Example prediction:\n",
            " 18 [109 109 109]\n",
            "Example prediction:\n",
            " 20 [109 109 109]\n",
            "Example prediction:\n",
            " 22 [109 109 109]\n",
            "Building Eagle_office_Patrice\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_111 (GRU)                (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_112 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_113 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [0 0 0]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 32923.0186\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 32815.4684\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 32269.2031\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 29308.9486\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28551.5561\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 28491.3284\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 26257.5297\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25951.5007\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 25221.7486\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 24563.2687\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22998.5980\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22356.5288\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 22075.0508\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 20900.0224\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 20720.3326\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 19766.0532\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 19038.4939\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 17852.9249\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 16874.0914\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 17234.2579\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15741.7361\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15334.8357\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 15218.1298\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13959.3289\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 14412.0844\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 13401.0543\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 13373.8023\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 12166.6143\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12240.6298\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 11834.9666\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 12205.6761\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11607.2019\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 11075.3231\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 10651.0054\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 11084.8365\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 10287.5795\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 10336.6234\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9664.2011\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 9916.2784\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 9072.1547\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 8983.7509\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 9204.6114\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 9012.5385\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 9059.8431\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8526.3369\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 8358.9059\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 8002.8433\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7359.4828\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7565.3878\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 7140.1003\n",
            "mean,rmse,rmse/mean,bldg: 165.87984746703071 99.46394198659881 0.5996143805616151 Eagle_office_Patrice\n",
            "Example prediction:\n",
            " 0 [194 194 195]\n",
            "Example prediction:\n",
            " 2 [187 187 188]\n",
            "Example prediction:\n",
            " 4 [186 187 187]\n",
            "Example prediction:\n",
            " 6 [189 189 190]\n",
            "Example prediction:\n",
            " 8 [185 186 186]\n",
            "Example prediction:\n",
            " 10 [180 180 181]\n",
            "Example prediction:\n",
            " 12 [192 192 192]\n",
            "Example prediction:\n",
            " 14 [187 187 188]\n",
            "Example prediction:\n",
            " 16 [169 169 170]\n",
            "Example prediction:\n",
            " 18 [194 194 195]\n",
            "Example prediction:\n",
            " 20 [194 194 195]\n",
            "Example prediction:\n",
            " 22 [158 159 160]\n",
            "Building Eagle_education_Shana\n",
            " Count bad values before pseudofill: 2\n",
            " Count bad values after pseudofill: 0\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_114 (GRU)                (None, 24, 16)            1440      \n",
            "_________________________________________________________________\n",
            "gru_115 (GRU)                (None, 24, 16)            1632      \n",
            "_________________________________________________________________\n",
            "gru_116 (GRU)                (None, 16)                1632      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 4,755\n",
            "Trainable params: 4,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Example y train:\n",
            " [  0   0 187]\n",
            "Epoch 1/50\n",
            "273/273 [==============================] - 7s 9ms/step - loss: 12777.1791\n",
            "Epoch 2/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 11735.8412\n",
            "Epoch 3/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 10800.4442\n",
            "Epoch 4/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 10076.8124\n",
            "Epoch 5/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 9245.7104\n",
            "Epoch 6/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 8343.9872\n",
            "Epoch 7/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 7826.1337\n",
            "Epoch 8/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 7145.4587\n",
            "Epoch 9/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 6629.4699\n",
            "Epoch 10/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 6089.3386\n",
            "Epoch 11/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 5642.5211\n",
            "Epoch 12/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 5367.9551\n",
            "Epoch 13/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 4823.9115\n",
            "Epoch 14/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 4497.4705\n",
            "Epoch 15/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 4258.9134\n",
            "Epoch 16/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3868.4808\n",
            "Epoch 17/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 3628.1460\n",
            "Epoch 18/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 3408.5723\n",
            "Epoch 19/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 3130.7779\n",
            "Epoch 20/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2979.3275\n",
            "Epoch 21/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2781.8406\n",
            "Epoch 22/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2590.7457\n",
            "Epoch 23/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2539.7231\n",
            "Epoch 24/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2481.0196\n",
            "Epoch 25/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2324.8704\n",
            "Epoch 26/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2316.7949\n",
            "Epoch 27/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2252.6270\n",
            "Epoch 28/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2221.8145\n",
            "Epoch 29/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2172.5781\n",
            "Epoch 30/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2224.3031\n",
            "Epoch 31/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2153.7526\n",
            "Epoch 32/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2167.3621\n",
            "Epoch 33/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2136.3354\n",
            "Epoch 34/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2161.3865\n",
            "Epoch 35/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2124.0597\n",
            "Epoch 36/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2150.3651\n",
            "Epoch 37/50\n",
            "273/273 [==============================] - 3s 10ms/step - loss: 2146.2527\n",
            "Epoch 38/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 2132.1345\n",
            "Epoch 39/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2178.6301\n",
            "Epoch 40/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2137.8266\n",
            "Epoch 41/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 2109.7869\n",
            "Epoch 42/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 1152.4239\n",
            "Epoch 43/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 968.6939\n",
            "Epoch 44/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 835.0822\n",
            "Epoch 45/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 780.3057\n",
            "Epoch 46/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 672.9084\n",
            "Epoch 47/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 627.1806\n",
            "Epoch 48/50\n",
            "273/273 [==============================] - 2s 9ms/step - loss: 559.8491\n",
            "Epoch 49/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 513.5280\n",
            "Epoch 50/50\n",
            "273/273 [==============================] - 3s 9ms/step - loss: 477.6472\n",
            "mean,rmse,rmse/mean,bldg: 103.18172944172048 19.55897606360223 0.18955852135284873 Eagle_education_Shana\n",
            "Example prediction:\n",
            " 0 [143 143 143]\n",
            "Example prediction:\n",
            " 2 [143 143 143]\n",
            "Example prediction:\n",
            " 4 [143 143 143]\n",
            "Example prediction:\n",
            " 6 [143 143 143]\n",
            "Example prediction:\n",
            " 8 [143 143 143]\n",
            "Example prediction:\n",
            " 10 [143 143 143]\n",
            "Example prediction:\n",
            " 12 [143 143 143]\n",
            "Example prediction:\n",
            " 14 [143 143 143]\n",
            "Example prediction:\n",
            " 16 [143 143 143]\n",
            "Example prediction:\n",
            " 18 [143 143 143]\n",
            "Example prediction:\n",
            " 20 [143 143 143]\n",
            "Example prediction:\n",
            " 22 [143 143 143]\n",
            "\n",
            "History 24 Future 3\n",
            "Column 1: Mean usage.\n",
            "Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\n",
            "Column 3: RMSE/mean normalized to help understand RMSE.\n",
            "Column 4: Building.\n",
            "      0.00       0.00   inf   Eagle_office_Henriette\n",
            "      0.11       0.03  0.28   Eagle_education_Wesley\n",
            "     15.76      14.26  0.90   Eagle_education_Jewell\n",
            "     35.89       7.46  0.21   Eagle_office_Mandi\n",
            "     36.93      11.24  0.30   Eagle_office_Lamont\n",
            "     43.43      33.36  0.77   Eagle_lodging_Blake\n",
            "     46.46      22.62  0.49   Eagle_education_Eileen\n",
            "     56.50      48.63  0.86   Eagle_office_Dallas\n",
            "     57.04      24.53  0.43   Eagle_education_Petra\n",
            "     62.02      43.64  0.70   Eagle_office_Sheree\n",
            "     81.96      46.43  0.57   Eagle_lodging_Edgardo\n",
            "     87.21      33.18  0.38   Eagle_office_Phyllis\n",
            "     91.27      53.78  0.59   Eagle_lodging_Trina\n",
            "     92.81      45.79  0.49   Eagle_lodging_Dawn\n",
            "    101.56      55.72  0.55   Eagle_office_Freida\n",
            "    103.18      19.56  0.19   Eagle_education_Shana\n",
            "    121.48      48.14  0.40   Eagle_office_Remedios\n",
            "    122.36      56.32  0.46   Eagle_health_Vincenza\n",
            "    148.73      48.68  0.33   Eagle_education_Teresa\n",
            "    165.88      99.46  0.60   Eagle_office_Patrice\n",
            "    174.64     129.06  0.74   Eagle_office_Tia\n",
            "    182.06      77.01  0.42   Eagle_public_Alvin\n",
            "    192.42      86.16  0.45   Eagle_health_Jodi\n",
            "    226.17      52.60  0.23   Eagle_education_Will\n",
            "    273.02     119.69  0.44   Eagle_office_Nereida\n",
            "    276.27     176.02  0.64   Eagle_food_Kay\n",
            "    336.49     204.92  0.61   Eagle_office_Francis\n",
            "    390.81     234.07  0.60   Eagle_office_Norbert\n",
            "    477.67     313.86  0.66   Eagle_health_Athena\n",
            "    659.51     756.76  1.15   Eagle_health_Gregoria\n",
            "    694.96     519.94  0.75   Eagle_education_Alberto\n",
            "    712.01     659.34  0.93   Eagle_education_Norah\n",
            "   1003.99    1851.84  1.84   Eagle_education_Shante\n",
            "   1037.64     931.96  0.90   Eagle_office_Chauncey\n",
            "   1084.43     919.08  0.85   Eagle_health_Reba\n",
            "   1199.38    1068.66  0.89   Eagle_education_Roman\n",
            "   1639.36    1628.50  0.99   Eagle_education_Brooke\n",
            "   2032.48    2068.78  1.02   Eagle_education_Sherrill\n",
            "   3154.83    3028.26  0.96   Eagle_education_Peter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm8eEJdHbz9v"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY4snIvJbz9z"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}