{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM \n",
    "We previously used linear regression\n",
    "to predict future air temp based on past air temp.\n",
    "Here, use LSTM for the same task.\n",
    "Where LinReg viewed each vector as one point,\n",
    "LSTM will view each vector as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "BLDG = 'Eagle_education_Peter'   # one example\n",
    "PREDICTOR_VARIABLE = 'airTemperature'  # for starters\n",
    "PREDICTED_VARIABLE = 'steam'  # for starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLE = True   # if true, use 1 time per day, else 24 times per day\n",
    "STEPS_HISTORY = 7 \n",
    "STEPS_FUTURE =  1    \n",
    "def smooth(df):\n",
    "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
    "    smoothed = None\n",
    "    if DOWNSAMPLE:\n",
    "        # This alternate method samples down to 1/24 time steps.\n",
    "        smoothed = df.resample(\"24H\").mean() \n",
    "    else:\n",
    "        # This method does not reduce the number of time steps.\n",
    "        # Note the first 23 measurements get set to Nan.\n",
    "        smoothed=df.rolling(window=24).mean()\n",
    "        smoothed=smoothed[24:]\n",
    "    return smoothed\n",
    "\n",
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    # This is very slow. Is there a faster way? See...\n",
    "    # https://stackoverflow.com/questions/27852343/split-python-sequence-time-series-array-into-subsequences-with-overlap\n",
    "    # X = df.drop(METER,axis=1) # this would use all predictors, just drop the predicted\n",
    "    X=[]\n",
    "    y=[]\n",
    "    predictor_series = df[PREDICTOR_VARIABLE].values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values\n",
    "    for i in range(STEPS_HISTORY,len(df)-STEPS_FUTURE):\n",
    "        one_predictor = [[p] for p in predictor_series[i-STEPS_HISTORY:i]]\n",
    "        one_predicted = [[p] for p in predicted_series[i:i+STEPS_FUTURE]]\n",
    "        X.append(one_predictor)\n",
    "        y.append(one_predicted)\n",
    "    # Return two lists of lists of lists.\n",
    "    # At this point, each data point is a scalar (1D) but RNN expects a vector.\n",
    "    # 1000 samples * 100 time steps * 1D vector.\n",
    "    return X,y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP_VECTOR_DIMENSION = 1 # we are univariate so far\n",
    "def make_RNN():\n",
    "    rnn = Sequential([\n",
    "        SimpleRNN(20,return_sequences=True, \n",
    "                  input_shape=(STEPS_HISTORY,TIMESTEP_VECTOR_DIMENSION)), \n",
    "        SimpleRNN(10,return_sequences=True),\n",
    "        SimpleRNN(1)  #        TimeDistributed(Dense(STEPS_FUTURE))\n",
    "    ])\n",
    "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_office_Lamont\n",
      "Building Eagle_health_Athena\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 360723.2788\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 336211.0745\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 309781.7885\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 350226.6442\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 324349.2548\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 348716.7091\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 330838.8317\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 332740.4688\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 319666.6346\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 333587.0986\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 309148.1022\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 317924.8317\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 346771.7524\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 324438.2740\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 337313.7284\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 323414.9880\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 322611.4543\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 334878.7356\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 337193.6755\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 318825.3365\n",
      "Building Eagle_assembly_Herbert\n",
      "Building Eagle_public_Alvin\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 3s 6ms/step - loss: 56211.5640\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 51607.6596\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 53814.1220\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 49714.3062\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 52025.2001\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 52446.0237\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50313.0391\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 56090.1112\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 52108.7743\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 52219.6493\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 52010.4507\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 50382.8822\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 53579.1448\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 54861.3041\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 49969.8326\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 51046.2016\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 57323.5956\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 52935.7275\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 50773.1863\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 53718.8798\n",
      "Building Eagle_education_Raul\n",
      "Building Eagle_education_Roman\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 1619142.3846\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1611365.6346\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1585743.5481\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1706088.9712\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1524628.1250\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1590310.9904\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1637950.5577\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1658696.6346\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1643592.0481\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1647842.9904\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1621252.6538\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1635796.1635\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1571850.4038\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1548523.9231\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1651847.5673\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1615578.6442\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1591088.9327\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1624381.7692\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1634872.8173\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1671823.9519\n",
      "Building Eagle_office_Mandi\n",
      "Building Eagle_education_Jewell\n",
      "Building Eagle_office_Henriette\n",
      "Building Eagle_health_Reba\n",
      "Building Eagle_lodging_Edgardo\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 8ms/step - loss: 8191.1836\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8827.8919\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8790.9071\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9022.4788\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8744.8854\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8539.9034\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8130.2073\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8438.9408\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8361.4286\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7702.5064\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9124.0008\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7735.4168\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8097.7175\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8610.0678\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7664.5988\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9114.3815\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8805.4412\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8241.3335\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8491.8546\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8061.1748\n",
      "Building Eagle_education_Cassie\n",
      "Building Eagle_education_Peter\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 8ms/step - loss: 13419335.2308\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12340034.3077\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12705784.6923\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11905847.0769\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12714210.6923\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12333571.7692\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 13423697.0769\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12149210.0769\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12025381.6154\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 13215375.5385\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12867247.9231\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11692914.6923\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 12726914.5385\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12112788.7692\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 13519456.6154\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12282592.4615\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11905031.7692\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12226554.6923\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13059658.5385\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 11405623.0000\n",
      "Building Eagle_health_Gregoria\n",
      "Building Eagle_lodging_Dawn\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 8ms/step - loss: 13140.4686\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12395.3585\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11893.7864\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11486.4200\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12942.7840\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12295.2121\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13898.6101\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11710.4038\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 13294.7040\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12574.6780\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12560.0110\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 13144.3921\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12058.3748\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12102.3847\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12665.1303\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12741.0273\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12623.8190\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12449.5627\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11788.4290\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 12411.1781\n",
      "Building Eagle_office_Nereida\n",
      "Building Eagle_lodging_Tressa\n",
      "Building Eagle_education_Eileen\n",
      "Building Eagle_education_Wesley\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 0.5414\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.2629\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.1657\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0992\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0536\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0378\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0330\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0283\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0215\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0261\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0202\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0176\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0209\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0143\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0180\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0123\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0132\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0158\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0119\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0134\n",
      "Building Eagle_health_Vincenza\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 14800.5999\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 16007.0134\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 15892.2600\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15912.3416\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 15471.0756\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15280.0257\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 14906.1813\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 16132.9568\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15318.8223\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15050.7924\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15561.1058\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15515.9275\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15096.2955\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15175.9407\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15612.7241\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15239.0716\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15090.9343\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15532.1613\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 16074.6946\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 14907.1064\n",
      "Building Eagle_office_Dallas\n",
      "Building Eagle_education_Shante\n",
      "Building Eagle_office_Chauncey\n",
      "Building Eagle_office_Phyllis\n",
      "Building Eagle_office_Freida\n",
      "Building Eagle_office_Francis\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 84363.5697\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 85403.3035\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 83951.3083\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 86313.1827\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 88889.2236\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 88883.6472\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 87138.3107\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 85522.2644\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 85583.2175\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 86799.2428\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 87784.9615\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 87434.4315\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 85007.8972\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 87008.7626\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 89236.3077\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 86945.6292\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 84012.7464\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 85178.4032\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 86277.6863\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 86498.1058\n",
      "Building Eagle_office_Sheree\n",
      "Building Eagle_education_Sherrill\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 7ms/step - loss: 5568703.3462\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5330177.3269\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5194192.8846\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5302816.6154\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5273460.1154\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 7ms/step - loss: 5494753.5769\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5396748.3077\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5398023.3846\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5151785.3846\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5005457.5385\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5252524.0000\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4944426.0000\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5614357.9615\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5123494.6154\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5342073.0385\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5537667.7692\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5122153.0192\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5405983.2692\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5297187.9615\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5537159.8077\n",
      "Building Eagle_education_Brooke\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 3980650.3846\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4421928.3846\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3971901.9615\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4608744.9615\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4084636.4615\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4397535.4231\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4231882.4423\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4376873.4231\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4328279.3077\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4572099.0000\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4096402.6346\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4212389.3654\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4518543.8846\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4424401.7308\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4211400.4038\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4478761.1923\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4352155.0000\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4453395.1538\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4162926.8269\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4529127.0000\n",
      "Building Eagle_education_Alberto\n",
      "Building Eagle_food_Kay\n",
      "Building Eagle_health_Jodi\n",
      "Building Eagle_education_Norah\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 563905.9808\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 653277.4808\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 564484.1731\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 598626.4808\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 570055.5649\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 583033.9279\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 568972.3197\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 624559.0481\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 567848.3942\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 604722.1298\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 566419.1058\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 604862.8606\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 608492.2452\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 614025.0577\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 611795.1779\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 582179.7548\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 523972.0361\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 596471.8894\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 516504.7236\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 550267.8029\n",
      "Building Eagle_education_Will\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 6ms/step - loss: 78251.5349\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76583.7939\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 74354.1304\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 73994.1599\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 78058.9375\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 76703.3564\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 77770.3504\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 77604.4026\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 75202.3438\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 76031.0463\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 71863.8002\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 74697.0589\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 77073.9020\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 81636.1226\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 75000.8011\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 74314.6214\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 77027.5012\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 75731.6611\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 75582.4790\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 73379.2704\n",
      "Building Eagle_lodging_Blake\n",
      "Building Eagle_education_Petra\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 2s 7ms/step - loss: 4627.5322\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4639.3704\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4346.8158\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4244.3746\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4325.5560\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4256.2301\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4485.8873\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4126.6218\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4306.6948\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4236.2689\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4002.0692\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4152.6712\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3980.0242\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4402.9440\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4380.8604\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4302.0114\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4150.8706\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4459.9715\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4676.8724\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step - loss: 4231.6734\n",
      "Building Eagle_lodging_Trina\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 3s 8ms/step - loss: 11376.0983\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10716.4882\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10442.6324\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11265.6396\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11235.2830\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10890.6904\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10213.5969\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10554.4420\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11191.0950\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10565.6293\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10584.0448\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10648.4947\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 11150.4063\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11413.2175\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11636.3616\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10844.5660\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11109.7625\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10248.2410\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10920.5738\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10496.0391\n",
      "Building Eagle_health_Reuben\n",
      "Building Eagle_education_Teresa\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 4s 11ms/step - loss: 28275.5407\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 28684.8176\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 30979.4793\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 30247.5134\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 29123.5197\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 29650.5165\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 29408.9187\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 27912.3331\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27774.6297\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29776.5104\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 31293.1095\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 32211.1830\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 29246.2160\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 28529.8284\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 29733.4312\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 31611.3014\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 31476.5736\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27864.9288\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 29712.8723\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 30092.8403\n",
      "Building Eagle_office_Norbert\n",
      "Building Eagle_lodging_Casey\n",
      "Building Eagle_office_Tia\n",
      "Building Eagle_office_Remedios\n",
      "Building Eagle_office_Patrice\n",
      "Building Eagle_education_Shana\n",
      "History 7 Future 1\n",
      "Column 1: Correlation of steam usage to dew temp.\n",
      "          Using dew temp as leading weather correlate.\n",
      "Column 2: Mean steam usage.\n",
      "          Using mean to help understand the RMSE.\n",
      "Column 3: RMSE of LinearRegression(X=Weather, y=SteamUsage).\n",
      "Column 4: RMSE/mean normalized to help understand RMSE.\n",
      "Column 5: Building.\n",
      "-0.8895    2032.67    2231.36  1.10   Eagle_education_Sherrill\n",
      "-0.8563    1635.33    1688.65  1.03   Eagle_education_Brooke\n",
      "-0.8526    3149.69    3206.90  1.02   Eagle_education_Peter\n",
      "-0.8412     477.70     476.48  1.00   Eagle_health_Athena\n",
      "-0.8203    1197.84    1260.35  1.05   Eagle_education_Roman\n",
      "-0.8004     121.95     128.42  1.05   Eagle_health_Vincenza\n",
      "-0.7994      57.05      62.97  1.10   Eagle_education_Petra\n",
      "-0.7740     712.07     829.65  1.17   Eagle_education_Norah\n",
      "-0.7628     182.08     161.53  0.89   Eagle_public_Alvin\n",
      "-0.7222      81.97      90.83  1.11   Eagle_lodging_Edgardo\n",
      "-0.7132      92.83      95.48  1.03   Eagle_lodging_Dawn\n",
      "-0.6798     148.51     149.21  1.00   Eagle_education_Teresa\n",
      "-0.6778      91.28     101.39  1.11   Eagle_lodging_Trina\n",
      "-0.5591     336.36     397.10  1.18   Eagle_office_Francis\n",
      "-0.3639     226.25     191.14  0.84   Eagle_education_Will\n",
      " 0.7265       0.11       0.13  1.24   Eagle_education_Wesley\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "EPOCHS=20\n",
    "# Test on only Peter just during code development\n",
    "for BLDG in all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        one_bldg_df = smooth(one_bldg_df) \n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        # Ideally, split Year1 = train, Year2 = test.\n",
    "        # Some data is incomplete, so split 1st half and 2nd half.\n",
    "        split = len(X)//2 \n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "        model = make_RNN()\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Compare. Solve the problem that predict.shape != truth.shape\n",
    "        nsamples, nsteps, ndim = y_test.shape\n",
    "        y_test = y_test.reshape(nsamples,nsteps*ndim)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cor = one_bldg_df.corr().iloc[0][3] # corr(steam,dew_temp)\n",
    "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
    "        \n",
    "if True:\n",
    "    print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "    print(\"Column 1: Correlation of steam usage to dew temp.\")\n",
    "    print(\"          Using dew temp as leading weather correlate.\")\n",
    "    print(\"Column 2: Mean steam usage.\")\n",
    "    print(\"          Using mean to help understand the RMSE.\")\n",
    "    print(\"Column 3: RMSE of LinearRegression(X=Weather, y=SteamUsage).\")\n",
    "    print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
    "    print(\"Column 5: Building.\")\n",
    "    for cor in sorted(cors):\n",
    "        print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "\n",
    "Jason Brownlee  \n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/\n",
    "https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
