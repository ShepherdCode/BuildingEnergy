{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNRPftWw9pK"
   },
   "source": [
    "# RNN \n",
    "Discovered and fixed bug in prepare() where the y_train for each sample covered the same (past) days as the X_train. The code worked for predicting one time point into the future, as presented in Report 1, but not multiple time points into the future.\n",
    "\n",
    "Discovered that the model merely predicts the building's mean steam for every future time point. More epochs of training merely brings the mean closer to true. Examples of (epochs,pred_mean) where true mean is 82: (2,2) (10,20) (20,50) (50,83) (100,86)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgeDotTmw9pX",
    "outputId": "3856f352-bfbf-438c-e9fa-f98fa94f93f2"
   },
   "outputs": [],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5deM-us2w9pZ"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ONdk510Cw9pc"
   },
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZgkgsP6w9pg",
    "outputId": "5fb5bd15-5b3b-452d-886a-97aac16289a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTORS= 8 ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "PREDICTORS = ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "#PREDICTORS.append('steam')\n",
    "print(\"PREDICTORS=\",len(PREDICTORS),PREDICTORS)\n",
    "NUM_PREDICTORS = len(PREDICTORS)  \n",
    "PREDICTED_VARIABLE = 'steam'  \n",
    "STEPS_HISTORY = 24 \n",
    "STEPS_FUTURE =  24    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6YVYM_bqw9pi"
   },
   "outputs": [],
   "source": [
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VynRgLt9w9pk"
   },
   "outputs": [],
   "source": [
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
    "    X_shape = (num_samples,STEPS_HISTORY,NUM_PREDICTORS)\n",
    "    X=np.zeros(X_shape)\n",
    "    Y_shape = (num_samples,STEPS_FUTURE)\n",
    "    y=np.zeros(Y_shape)\n",
    "    predictor_series = df[PREDICTORS].values  # e.g. all weather values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values  # e.g. all meter readings\n",
    "    \n",
    "    for sam in range (0,num_samples): # Loop over all 1000 samples\n",
    "        # This is one array of weather for previous 24 time periods\n",
    "        one_sample = predictor_series[sam:sam+STEPS_HISTORY]\n",
    "        # Loop over all 24 time periods\n",
    "        for time in range (0,STEPS_HISTORY): # In 1 sample, loop over 24 time periods\n",
    "            one_period = one_sample[time]\n",
    "            for feat in range (0,NUM_PREDICTORS): # In 1 time period, loop over 8 weather metrics\n",
    "                X[sam,time,feat] = one_period[feat]\n",
    "        for time in range (0,STEPS_FUTURE):  \n",
    "            y[sam,time]=predicted_series[sam+STEPS_HISTORY+time]\n",
    "    return X,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z_8rzumTw9p2"
   },
   "outputs": [],
   "source": [
    "def make_RNN():\n",
    "    rnn = Sequential([\n",
    "        SimpleRNN(8,return_sequences=True, \n",
    "                  input_shape=(STEPS_HISTORY,NUM_PREDICTORS)), \n",
    "        SimpleRNN(8,return_sequences=False),\n",
    "        Dense(STEPS_FUTURE)\n",
    "    ])\n",
    "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypnRqq9w9p4",
    "outputId": "77846ed2-a499-4b01-a4e6-1850e382fff3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_lodging_Edgardo\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 24, 8)             136       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 488\n",
      "Trainable params: 488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example X train:\n",
      " [[   0    8    7    0    0 1019  100    2]\n",
      " [   0    8    7    0    0 1019   80    3]\n",
      " [   0    8    7    0    0 1018   80    4]\n",
      " [   0    7    6    0    0 1017   70    4]\n",
      " [   0    7    7    0    0 1016   70    5]\n",
      " [   0    7    7    0    0 1016   80    4]\n",
      " [   0    8    7    0    0 1014   70    5]\n",
      " [   0    8    7    0    0 1012   80    4]\n",
      " [   0    9    8    3    0 1011   70    7]\n",
      " [   0    9    8   33    0 1009   70    7]\n",
      " [   0    9    8   17    0    0   70    6]\n",
      " [   0   10    9   76    0 1004   80    6]\n",
      " [   0   11   10   53    0 1003   80    6]\n",
      " [   0   10   10   94  310 1001   60    3]\n",
      " [   0   12   12   36    0  999  120    3]\n",
      " [   0   14   13    3    0  998  170    5]\n",
      " [   0   15   14   13    0  998  190    5]\n",
      " [   0   16   14   18    0  996  170    5]\n",
      " [   0   16   14   -1    0  995  190    5]\n",
      " [   0   17   14   -1   84  992  190    7]\n",
      " [   4   17   12    0    0    0  210    8]\n",
      " [   2   17   10    0    0  991  230    9]\n",
      " [   4   13    7    0    0  993  270    5]\n",
      " [   4   13    6    0    0  993  250    3]]\n",
      "Example y train:\n",
      " [ 75  29 112 101  80 139 120 160 142 145 154 161 197  48 300 262 250  52\n",
      " 213 219 223  39 133 126]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 9ms/step - loss: 12166.4390\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 11793.2891\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 11566.3387\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 11402.7118\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 10897.2663\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 10895.1807\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 10517.0226\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 10070.6259\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 9736.4996\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 9636.9089\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 9226.2714\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 8803.0081\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 8872.9250\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 8482.7431\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 8236.7336\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7849.3286\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7849.5903\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7748.5875\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7676.4529\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7336.8736\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7285.3466\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 7128.2503\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6889.6374\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6745.3035\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 6834.7530\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6595.6172\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6595.8403\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6413.7185\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6279.6336\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6272.4568\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6218.0440\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5977.4698\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6138.3564\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5935.2693\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5888.6652\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 5925.4613\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 6041.4378\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5859.7267\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5820.4187\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5777.2270\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 5773.2612\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5797.4442\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5750.0229\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 5796.2097\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 5763.4721\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 5892.7443\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 5768.2994\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 5855.4160\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 5781.1023\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5909.5393\n",
      "mean,rmse,rmse/mean,bldg: 81.96779195736434 75.52171102841359 0.9213583680245567 Eagle_lodging_Edgardo\n",
      "Example prediction:\n",
      " [81 81 80 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 81 80 81 81 81 81]\n",
      "Example truth:\n",
      " [ 33 369 571 367 130 383  38 389  61 780 307 104 249 320 240  65 289 377\n",
      "  34 344 570  69 289  41]\n",
      "History 24 Future 24\n",
      "Column 1: Mean usage.\n",
      "Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 3: RMSE/mean normalized to help understand RMSE.\n",
      "Column 4: Building.\n",
      "     81.97      75.52  0.92   Eagle_lodging_Edgardo\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "for BLDG in ['Eagle_lodging_Edgardo']:  ### all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        split = len(X)//2   # year 1 vs year 2\n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "\n",
    "        model = make_RNN()\n",
    "        print(model.summary())\n",
    "        print(\"Example X train:\\n\",X_train[210].astype(int))\n",
    "        print(\"Example y train:\\n\",y_train[210].astype(int))\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"mean,rmse,rmse/mean,bldg:\",mean,rmse,rmse/mean,BLDG)\n",
    "        print(\"Example prediction:\\n\",y_pred[210].astype(int))\n",
    "        print(\"Example truth:\\n\",y_test[210].astype(int))\n",
    "\n",
    "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "print(\"Column 1: Mean usage.\")\n",
    "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
    "print(\"Column 4: Building.\")\n",
    "for cor in sorted(cors):\n",
    "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_107.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
