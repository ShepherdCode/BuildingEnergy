{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNRPftWw9pK"
   },
   "source": [
    "# CNN + LSTM on CoLab\n",
    "Assume user downloaded archive.zip from Kaggle, renamed the file BuildingData.zip, and stored the file in the data subdirectory. Assume the zip file contains the weather.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgeDotTmw9pX",
    "outputId": "61d734c6-e5c8-45a9-f1b9-58d032190415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5deM-us2w9pZ"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ONdk510Cw9pc"
   },
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PQR726k8L6Y"
   },
   "source": [
    "## CNN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZgkgsP6w9pg",
    "outputId": "f61b8261-2ea5-4923-fc4d-6c67d8e9acf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTORS= 8 ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n"
     ]
    }
   ],
   "source": [
    "# Before analyzing the entire dataset, we look at this subset.\n",
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "\n",
    "# Arrange \"picture\" of weather with temperatures toward the middle\n",
    "PREDICTED_VARIABLE = 'steam' \n",
    "PREDICTORS = ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "print(\"PREDICTORS=\",len(PREDICTORS),PREDICTORS)\n",
    "\n",
    "# Downsample True means collapse 365*24 measures to 365 daily averages\n",
    "# Downsample False means replace 365*24 measures with 365*24 window averages\n",
    "DOWNSAMPLE = False   \n",
    "\n",
    "STEPS_HISTORY = 24   # length of the predictor sequence\n",
    "STEPS_FUTURE =  24    # length of the predicted sequence\n",
    "\n",
    "## CNN parameters\n",
    "EPOCHS=25  # use 1 for testing, 25 for production\n",
    "FILTERS = 8\n",
    "WIDTH = 3\n",
    "STRIDE = (1,1)\n",
    "INPUT_SHAPE = (STEPS_HISTORY,len(PREDICTORS),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6YVYM_bqw9pi"
   },
   "outputs": [],
   "source": [
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VynRgLt9w9pk"
   },
   "outputs": [],
   "source": [
    "def smooth(df):\n",
    "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
    "    smoothed = None\n",
    "    if DOWNSAMPLE:\n",
    "        # This alternate method samples down to 1/24 time steps.\n",
    "        smoothed = df.resample(\"24H\").mean() \n",
    "    else:\n",
    "        # This method does not reduce the number of time steps.\n",
    "        # Note the first 23 measurements get set to Nan.\n",
    "        smoothed=df.rolling(window=24).mean()\n",
    "        smoothed=smoothed[24:]\n",
    "    return smoothed\n",
    "\n",
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
    "    num_predictors = len(PREDICTORS)\n",
    "    X_shape = (num_samples,STEPS_HISTORY,num_predictors,1)\n",
    "    X=np.zeros(X_shape)\n",
    "    Y_shape = (num_samples,STEPS_FUTURE)\n",
    "    y=np.zeros(Y_shape)\n",
    "    predictor_series = df[PREDICTORS].values  # e.g. all weather values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values  # e.g. all meter readings\n",
    "    \n",
    "    for x0 in range (0,num_samples): # Loop over all 1000 samples\n",
    "        # This is one array of weather for previous 24 time periods\n",
    "        one_sample = predictor_series[x0:x0+STEPS_HISTORY]\n",
    "        one_label =  predicted_series[x0+STEPS_HISTORY:x0+STEPS_FUTURE]\n",
    "        # Loop over all 24 time periods\n",
    "        for x1 in range (0,STEPS_HISTORY): # In 1 sample, loop over 24 time periods\n",
    "            one_period = one_sample[x1]\n",
    "            for x2 in range (0,num_predictors): # In 1 time period, loop over 8 weather metrics\n",
    "                one_predictor = one_period[x2]\n",
    "                # for x3 in range (0,X_shape[3]): # In 1 metric, loop over vector dimensions\n",
    "                # In our data, each weather metric is a scalar.\n",
    "                x3 = 0\n",
    "                X[x0,x1,x2,x3] = one_predictor\n",
    "        y[x0]=predicted_series[x0:x0+STEPS_FUTURE]\n",
    "    return X,y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Vi0XqPS8L6g"
   },
   "outputs": [],
   "source": [
    "def make_DNN():\n",
    "    print(\"make_DNN\")\n",
    "    print(\"input shape:\",INPUT_SHAPE)\n",
    "    dnn = Sequential()\n",
    "    dnn.add(Conv2D( input_shape=INPUT_SHAPE,\n",
    "            filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,\n",
    "            activation=None, padding=\"valid\"))\n",
    "    dnn.add(Conv2D(\n",
    "            filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,\n",
    "            activation=None, padding=\"valid\"))\n",
    "    dnn.add(MaxPooling2D())\n",
    "    dnn.add(TimeDistributed(Flatten()))\n",
    "    dnn.add(LSTM(8,return_sequences=True))\n",
    "    dnn.add(LSTM(8,return_sequences=False))\n",
    "    dnn.add(Dense(STEPS_FUTURE))   \n",
    "    dnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    dnn.build(input_shape=INPUT_SHAPE)\n",
    "    return dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPVoS4Ku8L6k"
   },
   "source": [
    "## Process all buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypnRqq9w9p4",
    "outputId": "17ba7d09-ea79-4f45-f278-c5466147f674",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_office_Lamont\n",
      "Building Eagle_health_Athena\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 13ms/step - loss: 365092.7316\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 360847.2626\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 362385.8722\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 353597.0947\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 352801.8310\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 346311.4436\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 344242.2400\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 345516.4674\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 345177.8880\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 335373.5187\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 346434.9110\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 336867.9406\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 333344.6903\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 336992.4253\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 333432.8934\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 323769.7415\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 324982.4809\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 319152.4136\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 324366.7214\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 316269.0756\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 315333.1943\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 314429.8305\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 312912.5689\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 309278.7982\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 309231.0506\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.714675935601442 477.70168061445776 443.5860948198911 0.928583910882029 Eagle_health_Athena\n",
      "Building Eagle_assembly_Herbert\n",
      "Building Eagle_public_Alvin\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 13ms/step - loss: 63466.9723\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 60490.9644\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 59560.3480\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 57698.8191\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 57799.0913\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 56715.2330\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 54711.9522\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 54449.9655\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 54233.2548\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 52678.0992\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 51009.9444\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 51361.8675\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 49507.6467\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 49278.3366\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 48669.9552\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 47265.1743\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 47246.6025\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 46923.4532\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 44601.2899\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 44320.4485\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 42346.0309\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 43127.3741\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 42123.6146\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 41507.0808\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 41378.7765\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.5644780905146625 182.08293646830808 116.39276654515152 0.6392294017369932 Eagle_public_Alvin\n",
      "Building Eagle_education_Raul\n",
      "Building Eagle_education_Roman\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 13ms/step - loss: 1736872.8441\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1731795.1532\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1704250.3286\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1707969.1773\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1710636.1864\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1730192.2000\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1698661.2682\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1721479.3164\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1696243.3400\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1691912.8582\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1670611.9095\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1647398.9059\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1694156.6986\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1673074.1727\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1650615.5841\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1653092.2141\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1645401.2995\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1635097.6173\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1647534.8409\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 1646681.5759\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1647848.6868\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1602989.2682\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1643743.7550\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1599178.1355\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1608138.5827\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.6971970415159798 1197.8359713121304 1233.2586143297451 1.0295721984194648 Eagle_education_Roman\n",
      "Building Eagle_office_Mandi\n",
      "Building Eagle_education_Jewell\n",
      "Building Eagle_office_Henriette\n",
      "Building Eagle_health_Reba\n",
      "Building Eagle_lodging_Edgardo\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 14ms/step - loss: 12389.0147\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 11833.4477\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11506.3452\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11214.5267\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10982.4723\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10561.3405\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10078.7288\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9831.3463\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 9614.0217\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9147.2461\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9087.8429\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 8756.5886\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8428.2482\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 8403.2165\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8169.2699\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7976.6893\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7863.3256\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7588.0531\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7331.8894\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7228.7110\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7164.2676\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 7171.3716\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 6778.9760\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 6652.6622\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 6688.6437\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.420958250828966 81.9677919573641 79.10605921070636 0.9650871070414306 Eagle_lodging_Edgardo\n",
      "Building Eagle_education_Cassie\n",
      "Building Eagle_education_Peter\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 12895571.5964\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13069733.2691\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12957828.1600\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13062920.3345\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12969118.5636\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 12967902.3673\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12971207.2145\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 13018448.7164\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12926848.8509\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13069315.8000\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12933010.6509\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12854219.6873\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12615009.2073\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12818712.6945\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12864294.5200\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12571011.8000\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12730327.7491\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12641873.5782\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12654793.3782\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12672645.2400\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12520006.4655\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12766570.7091\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12767725.4727\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12567819.4218\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12503380.2727\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8010592683514538 3149.6888831281212 3189.77485450335 1.0127269622056823 Eagle_education_Peter\n",
      "Building Eagle_health_Gregoria\n",
      "Building Eagle_lodging_Dawn\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 14ms/step - loss: 15258.5390\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14547.5690\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14185.2273\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13721.9203\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13163.4468\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12603.2873\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12294.1719\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12084.5066\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11748.1128\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11083.2771\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10625.4635\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10346.2169\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10110.7440\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9771.2162\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9538.6412\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9060.2490\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8807.5672\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8530.0069\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8302.7488\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8079.6427\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7796.0343\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7755.4218\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7355.4653\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7145.4022\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7137.1779\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.5293626578197084 92.82705527815749 71.95423330288108 0.775142905128998 Eagle_lodging_Dawn\n",
      "Building Eagle_office_Nereida\n",
      "Building Eagle_lodging_Tressa\n",
      "Building Eagle_education_Eileen\n",
      "Building Eagle_education_Wesley\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 0.0050\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0013\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: 0.43722987743290215 0.10518451322389408 0.04331489347789675 0.41179915322417626 Eagle_education_Wesley\n",
      "Building Eagle_health_Vincenza\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 14ms/step - loss: 18179.1126\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 17330.4560\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 16800.6379\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 16307.4463\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 15845.8875\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 15401.1769\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14773.0336\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 14308.4786\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13867.2196\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 13247.1339\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 13028.6538\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12532.2059\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12187.4936\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11829.7501\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11396.8980\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10944.6241\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10535.5051\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10232.9599\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9944.9607\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9589.5493\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9270.8587\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 9109.9801\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8732.0547\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8437.1863\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 8302.0356\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.46361408982228286 121.94931946534436 90.99021460509458 0.7461313847753963 Eagle_health_Vincenza\n",
      "Building Eagle_office_Dallas\n",
      "Building Eagle_education_Shante\n",
      "Building Eagle_office_Chauncey\n",
      "Building Eagle_office_Phyllis\n",
      "Building Eagle_office_Freida\n",
      "Building Eagle_office_Francis\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 91371.6732\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 88986.4410\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 87740.6509\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 86819.4123\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 84680.7513\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 83521.1972\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 82288.9414\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 79396.4363\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 79127.2195\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 78159.2835\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 77354.1928\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 76259.1274\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 74747.1462\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 73412.8262\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 72794.5724\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 71053.4056\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 68713.5762\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 68460.3511\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 66916.7675\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 66654.3819\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 65832.6761\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 64149.1115\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 63422.9392\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 62761.7656\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 60462.5142\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.4515947035800076 336.35952546169125 346.97719095048393 1.0315664183263986 Eagle_office_Francis\n",
      "Building Eagle_office_Sheree\n",
      "Building Eagle_education_Sherrill\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 14ms/step - loss: 5476252.4382\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5516387.1182\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5468138.8491\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5542869.1836\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5520024.5455\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5549175.9636\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5619283.2491\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5447346.7982\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5449312.8673\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5555100.4982\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5427550.4545\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5514388.3309\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5402113.9691\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5447820.7255\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5404655.7673\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5426236.1618\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5395054.3873\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5250831.1400\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5397193.4927\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5236496.5418\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5361639.0527\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5421143.6709\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5275127.4164\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5299058.2164\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5406804.4400\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8130507458567988 2032.6741548164603 2228.8370345115545 1.0965048329218348 Eagle_education_Sherrill\n",
      "Building Eagle_education_Brooke\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 5323499.3945\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5291213.4182\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5300258.1873\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5280771.8436\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5268049.1291\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5315242.0927\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5218198.5982\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5275235.3655\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5267297.2327\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5262063.3309\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5160548.5273\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5133328.0255\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5139174.7418\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5163081.9164\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5153820.1309\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5090086.8491\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5043668.9782\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5112637.5900\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5075966.5345\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5102373.1836\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5127127.1182\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5086738.2273\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5189402.8673\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5037132.7727\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5087061.2345\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.5974542280786012 1635.325760391017 1925.8017832975868 1.1776257856031787 Eagle_education_Brooke\n",
      "Building Eagle_education_Alberto\n",
      "Building Eagle_food_Kay\n",
      "Building Eagle_health_Jodi\n",
      "Building Eagle_education_Norah\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 637856.4873\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 626503.4795\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 621909.1832\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 627873.0130\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 611926.1420\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 598497.7082\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 617366.9770\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 616848.5291\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 620860.3811\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 586819.3691\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 591877.7419\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 600109.6742\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 599441.4439\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 585295.4182\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 597627.4109\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 570394.7755\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 586955.6516\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 570334.2568\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 562780.1695\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 574567.5686\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 573612.7731\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 557811.7711\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 557942.8060\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 558879.8674\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 559500.5390\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.6928377753347054 712.0697702804412 803.7884503641144 1.1288057489753438 Eagle_education_Norah\n",
      "Building Eagle_education_Will\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 15ms/step - loss: 79474.1627\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 76589.6038\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 75768.4104\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 75150.7799\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 74291.1815\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 71291.3842\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 69120.1439\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 69442.3439\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 67315.2039\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 66592.8426\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 64935.3363\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 64511.6581\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 63900.1200\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 62554.8268\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 61801.9698\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 60289.3148\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 59324.0390\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 58520.2099\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 56986.6401\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 56391.3748\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 54464.2737\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 54940.5874\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 52638.4531\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 52128.1509\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 51409.9650\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.3225867063544024 226.25485356247063 136.2377295118002 0.6021427932558537 Eagle_education_Will\n",
      "Building Eagle_lodging_Blake\n",
      "Building Eagle_education_Petra\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 4690.1914\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4291.3237\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4063.5971\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3668.9362\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3486.1410\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3407.3748\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3099.7447\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3042.8717\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2889.3612\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2700.9837\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2520.0476\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2375.7063\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2252.1343\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2206.7203\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2079.8058\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1992.8625\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1885.2535\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1870.8522\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1756.5781\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1808.2149\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1699.1426\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1680.7735\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1674.0725\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1593.2494\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1602.4028\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.6191464903644708 57.05018764819895 42.91177314614104 0.752175845779111 Eagle_education_Petra\n",
      "Building Eagle_lodging_Trina\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 7s 14ms/step - loss: 15062.3773\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 15059.0716\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14716.7008\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14012.5671\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 13760.8338\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 13531.9697\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12946.0104\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12892.8656\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12643.6543\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 11926.1645\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12045.3646\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 11532.9941\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 11119.1368\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10771.5518\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10653.5133\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10925.2065\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10279.7296\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9913.7905\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9962.2832\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9586.4002\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9631.9520\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9397.0413\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9473.3443\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9193.1116\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 8700.8538\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.4243310096275085 91.28035335157311 87.99174215201161 0.9639724094088991 Eagle_lodging_Trina\n",
      "Building Eagle_health_Reuben\n",
      "Building Eagle_education_Teresa\n",
      "make_DNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 20, 4, 8)          584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 10, 8)             800       \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 2,224\n",
      "Trainable params: 2,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8748, 24, 8, 1)\n",
      "Epoch 1/25\n",
      "274/274 [==============================] - 8s 14ms/step - loss: 31459.5633\n",
      "Epoch 2/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 30536.7598\n",
      "Epoch 3/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 29689.8341\n",
      "Epoch 4/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 29586.6538\n",
      "Epoch 5/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 28329.0702\n",
      "Epoch 6/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 27879.0625\n",
      "Epoch 7/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 27237.9453\n",
      "Epoch 8/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 26868.2621\n",
      "Epoch 9/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 25109.4666\n",
      "Epoch 10/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 25178.4018\n",
      "Epoch 11/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 24894.0836\n",
      "Epoch 12/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 23968.2297\n",
      "Epoch 13/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 23813.0065\n",
      "Epoch 14/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 23260.7244\n",
      "Epoch 15/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 22260.8635\n",
      "Epoch 16/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 21861.3237\n",
      "Epoch 17/25\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 21313.7400\n",
      "Epoch 18/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 20983.8699\n",
      "Epoch 19/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 20451.2655\n",
      "Epoch 20/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 20413.4181\n",
      "Epoch 21/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 19500.3113\n",
      "Epoch 22/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 19714.1465\n",
      "Epoch 23/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 18389.1263\n",
      "Epoch 24/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 18416.7790\n",
      "Epoch 25/25\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 18270.5674\n",
      "Raw y_pred.shape: (8748, 24)\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.5300855283289124 148.50781927724552 108.40165628518712 0.7299390484134359 Eagle_education_Teresa\n",
      "Building Eagle_office_Norbert\n",
      "Building Eagle_lodging_Casey\n",
      "Building Eagle_office_Tia\n",
      "Building Eagle_office_Remedios\n",
      "Building Eagle_office_Patrice\n",
      "Building Eagle_education_Shana\n",
      "\n",
      "History 24 Future 24\n",
      "Column 1: Correlation of steam and dewTemperature\n",
      "          Using one weather feature as leading correlate.\n",
      "Column 2: Mean usage.\n",
      "          Using mean to help understand the RMSE.\n",
      "Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 4: RMSE/mean normalized to help understand RMSE.\n",
      "Column 5: Building.\n",
      "-0.8131    2032.67    2228.84  1.10   Eagle_education_Sherrill\n",
      "-0.8011    3149.69    3189.77  1.01   Eagle_education_Peter\n",
      "-0.7147     477.70     443.59  0.93   Eagle_health_Athena\n",
      "-0.6972    1197.84    1233.26  1.03   Eagle_education_Roman\n",
      "-0.6928     712.07     803.79  1.13   Eagle_education_Norah\n",
      "-0.6191      57.05      42.91  0.75   Eagle_education_Petra\n",
      "-0.5975    1635.33    1925.80  1.18   Eagle_education_Brooke\n",
      "-0.5645     182.08     116.39  0.64   Eagle_public_Alvin\n",
      "-0.5301     148.51     108.40  0.73   Eagle_education_Teresa\n",
      "-0.5294      92.83      71.95  0.78   Eagle_lodging_Dawn\n",
      "-0.4636     121.95      90.99  0.75   Eagle_health_Vincenza\n",
      "-0.4516     336.36     346.98  1.03   Eagle_office_Francis\n",
      "-0.4243      91.28      87.99  0.96   Eagle_lodging_Trina\n",
      "-0.4210      81.97      79.11  0.97   Eagle_lodging_Edgardo\n",
      "-0.3226     226.25     136.24  0.60   Eagle_education_Will\n",
      " 0.4372       0.11       0.04  0.41   Eagle_education_Wesley\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "ONE_PREDICTOR = 'dewTemperature'  ## illustrate difficulty by showing best correlate\n",
    "for BLDG in all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        #one_bldg_df = smooth(one_bldg_df) \n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        # Ideally, split Year1 = train, Year2 = test.\n",
    "        # Some data is incomplete, so split 1st half and 2nd half.\n",
    "        split = len(X)//2 \n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "\n",
    "        model = make_DNN()\n",
    "        print(model.summary())\n",
    "        print(\"X_train.shape:\",X_train.shape)\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)        \n",
    "        print(\"Raw y_pred.shape:\",y_pred.shape)\n",
    "        #nsamples, nsteps, ndim = y_pred.shape\n",
    "        #y_pred = y_pred.reshape(nsamples,nsteps*ndim)\n",
    "        #print(\"Reshaped y_pred.shape:\",y_pred.shape)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][ONE_PREDICTOR] \n",
    "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"cor,mean,rmse,rmse/mean,bldg:\",cor,mean,rmse,rmse/mean,BLDG)\n",
    "        \n",
    "print()\n",
    "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",ONE_PREDICTOR)\n",
    "print(\"          Using one weather feature as leading correlate.\")\n",
    "print(\"Column 2: Mean usage.\")\n",
    "print(\"          Using mean to help understand the RMSE.\")\n",
    "print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
    "print(\"Column 5: Building.\")\n",
    "for cor in sorted(cors):\n",
    "    print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-2XXhGa8L6p"
   },
   "source": [
    "### Report 2\n",
    "Results on all buildings.\n",
    "\n",
    "* 0.88 mean RMSE\n",
    "* 0.22 stddev\n",
    "\n",
    "Here are the results omitting outlier building Wesley.\n",
    "\n",
    "* 0.91 mean RMSE\n",
    "* 0.18 stddev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2wApjMjP8L6q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Conv_104_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
