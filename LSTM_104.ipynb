{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNRPftWw9pK"
   },
   "source": [
    "# LSTM \n",
    "We previously used linear regression\n",
    "to predict future air temp based on past air temp.\n",
    "Here, use LSTM for the same task.\n",
    "Where LinReg viewed each vector as one point,\n",
    "LSTM will view each vector as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgeDotTmw9pX",
    "outputId": "1dcf2d4d-add7-414f-8caa-44f5812ac31e"
   },
   "outputs": [],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5deM-us2w9pZ"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ONdk510Cw9pc"
   },
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jZgkgsP6w9pg"
   },
   "outputs": [],
   "source": [
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "BLDG = 'Eagle_education_Peter'   # one example\n",
    "PREDICTOR_VARIABLE = 'airTemperature'  # for starters\n",
    "PREDICTED_VARIABLE = 'steam'  # for starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6YVYM_bqw9pi"
   },
   "outputs": [],
   "source": [
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VynRgLt9w9pk"
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLE = False   # if true, use 1 time per day, else 24 times per day\n",
    "STEPS_HISTORY = 24 \n",
    "STEPS_FUTURE =  1    \n",
    "def smooth(df):\n",
    "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
    "    smoothed = None\n",
    "    if DOWNSAMPLE:\n",
    "        # This alternate method samples down to 1/24 time steps.\n",
    "        smoothed = df.resample(\"24H\").mean() \n",
    "    else:\n",
    "        # This method does not reduce the number of time steps.\n",
    "        # Note the first 23 measurements get set to Nan.\n",
    "        smoothed=df.rolling(window=24).mean()\n",
    "        smoothed=smoothed[24:]\n",
    "    return smoothed\n",
    "\n",
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    # This is very slow. Is there a faster way? See...\n",
    "    # https://stackoverflow.com/questions/27852343/split-python-sequence-time-series-array-into-subsequences-with-overlap\n",
    "    # X = df.drop(METER,axis=1) # this would use all predictors, just drop the predicted\n",
    "    X=[]\n",
    "    y=[]\n",
    "    predictor_series = df[PREDICTOR_VARIABLE].values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values\n",
    "    for i in range(STEPS_HISTORY,len(df)-STEPS_FUTURE):\n",
    "        one_predictor = [[p] for p in predictor_series[i-STEPS_HISTORY:i]]\n",
    "        one_predicted = [[p] for p in predicted_series[i:i+STEPS_FUTURE]]\n",
    "        X.append(one_predictor)\n",
    "        y.append(one_predicted)\n",
    "    # Return two lists of lists of lists.\n",
    "    # At this point, each data point is a scalar (1D) but RNN expects a vector.\n",
    "    # 1000 samples * 100 time steps * 1D vector.\n",
    "    return X,y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "z_8rzumTw9p2"
   },
   "outputs": [],
   "source": [
    "TIMESTEP_VECTOR_DIMENSION = 1 # we are univariate so far\n",
    "def make_RNN():\n",
    "    rnn = Sequential([\n",
    "        LSTM(20,return_sequences=True, \n",
    "                  input_shape=(STEPS_HISTORY,TIMESTEP_VECTOR_DIMENSION)), \n",
    "        LSTM(10,return_sequences=False),\n",
    "        Dense(STEPS_FUTURE)   \n",
    "    ])\n",
    "    rnn = Sequential([\n",
    "        SimpleRNN(20,return_sequences=True, \n",
    "                  input_shape=(STEPS_HISTORY,TIMESTEP_VECTOR_DIMENSION)), \n",
    "        SimpleRNN(10,return_sequences=False),\n",
    "        Dense(STEPS_FUTURE)  \n",
    "    ])\n",
    "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypnRqq9w9p4",
    "outputId": "89650343-d508-4190-c09a-e9721e919b65",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_office_Lamont\n",
      "Building Eagle_health_Athena\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 6s 12ms/step - loss: 334716.4024\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 329819.1536\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 335799.3678\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 327674.1815\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 325038.6126\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 321706.0964\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 321183.4865\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 315266.1672\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 318005.8091\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 310830.4507\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 306047.9911\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 308045.7745\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 302521.1825\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 295715.1607\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 292816.8254\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 296204.1016\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 290384.5749\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 284400.1570\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 282750.8424\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 280556.1149\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 277882.5868\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 275669.6530\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 271979.4590\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 270504.7784\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 269479.0281\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 263957.6103\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 259855.4001\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 256541.4532\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 256899.6623\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 256675.9889\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 245841.0109\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 252099.3235\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 247635.8524\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 240239.7603\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 247156.1419\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 246381.9068\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 237163.9805\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 236245.2186\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 235938.3269\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 225693.4764\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 222372.3053\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 218874.1248\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 216602.3535\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 216403.8522\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 215868.1465\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 218932.4619\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 214774.6969\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 211516.3274\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 208792.9640\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 205738.1595\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.849214848008229 477.4110643545475 352.08852698280316 0.7374955321968114 Eagle_health_Athena\n",
      "Building Eagle_assembly_Herbert\n",
      "Building Eagle_public_Alvin\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 12ms/step - loss: 53350.6877\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 49793.4509\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 49667.3749\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 48401.3686\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 46799.2572\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 45773.4236\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 43830.9125\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 41960.2018\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 41971.6745\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 40900.4264\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 39466.8575\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 39876.7857\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 39020.2924\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 37158.3094\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 35813.1339\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 34816.4014\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 33768.7769\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 32968.1692\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 32297.7847\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 31889.8406\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 30829.7447\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 29545.0842\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 29371.9761\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 29107.5685\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 27615.9141\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 26846.3000\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 25721.2824\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 26187.6559\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 25139.7698\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 24184.9024\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 23803.4502\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 22887.2518\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 22043.4001\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 21144.6906\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 20484.7143\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 20964.4180\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 20286.8008\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 19525.4414\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 18860.6846\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 18592.0094\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 18342.6066\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 17596.2350\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 16789.8636\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 15847.5226\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 16044.3378\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 15511.2432\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 15698.9588\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 14422.4421\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 14569.8494\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 13752.7295\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.755524810622147 181.93965687500085 56.10652788757045 0.3083798708388115 Eagle_public_Alvin\n",
      "Building Eagle_education_Raul\n",
      "Building Eagle_education_Roman\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_4 (SimpleRNN)     (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 5s 12ms/step - loss: 1672425.9009\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1689545.3423\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 1616647.8182\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1618755.5427\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1661609.7573\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1612785.5455\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1585723.0273\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 1590285.1886\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1589225.7509\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 1601162.4218\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1574980.5086\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 1564308.2618\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 1544103.8368\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1571328.0664\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1568650.7241\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1528320.8482\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1550142.3064\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1539034.9623\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1523019.0945\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1520287.5564\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1541106.3605\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1507151.1041\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1518745.0736\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1498879.9232\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1525461.7791\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1487740.2250\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1475519.4450\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1476065.5718\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1457065.4336\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1451119.4659\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1457596.5909\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1423389.3850\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1424581.7332\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1439048.8991\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1446212.8668\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1424124.3664\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1379256.2391\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1393643.2641\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1389012.9982\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1399723.7409\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1395869.4455\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1372456.5518\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1366603.0282\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1360105.7191\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 1374278.6955\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1344959.5377\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1326426.5868\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1362487.5245\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 1335926.2936\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 1318576.9323\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8040385849969112 1197.016015073252 1119.5726752478338 0.9353030044291605 Eagle_education_Roman\n",
      "Building Eagle_office_Mandi\n",
      "Building Eagle_education_Jewell\n",
      "Building Eagle_office_Henriette\n",
      "Building Eagle_health_Reba\n",
      "Building Eagle_lodging_Edgardo\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_6 (SimpleRNN)     (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 4s 9ms/step - loss: 8544.8601\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 7654.7407\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 7300.3502\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6847.0177\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 6439.1744\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5972.4432\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5787.1481\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5389.7676\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 5056.5354\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 4868.4777\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 4574.0978\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4254.2884\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 4234.0025\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 3834.6199\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 3794.5935\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 3578.4786\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3228.4286\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 3186.8639\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 2974.9267\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2946.5288\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2813.3788\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2740.6512\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 2609.9573\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2544.5485\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2401.0038\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2373.3887\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2228.8867\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2266.1643\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2282.9313\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 2203.0166\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2155.6499\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2247.3632\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 2139.6793\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 2166.2526\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 1672.7551\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1589.8638\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1544.6796\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1382.1347\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1372.3636\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1354.2118\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1275.5423\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1219.3988\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1185.1085\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 1099.9656\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 1106.5156\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1089.4422\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1054.1190\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 955.2492\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 942.7174: 0s - loss: 942.60\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 927.9588\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.7661481928706323 81.87169456264256 30.376309602073423 0.37102334041506335 Eagle_lodging_Edgardo\n",
      "Building Eagle_education_Cassie\n",
      "Building Eagle_education_Peter\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_8 (SimpleRNN)     (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 8s 20ms/step - loss: 12800548.0327\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12696681.4945\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12697091.2727\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12737569.0291\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12773674.6545\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12416018.0800\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12820531.3091\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12831153.5709\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 7s 25ms/step - loss: 12522418.9891\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12530954.9382\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 12535476.5564\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 12497850.1309\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 12686922.3382\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 12409435.3236\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 12628787.5164\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 12583628.2473\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12639205.3164\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12508381.8982\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12201938.7527\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12195079.9818\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12475915.2691\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12138526.3018\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12252156.9091\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 12481501.1782\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12354912.8764\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 12340980.1018\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 12278642.9164\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 12267234.6545\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12295002.6182\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 12071528.0727\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 12105481.3855\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 12111224.3455\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12256524.3491\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12049689.3927\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12209858.8036\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12136571.5527\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 11964519.2764\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12111018.9855\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 11895347.6255\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12065231.7382\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12158919.9673\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11924493.5236\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 11960304.6582\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12122657.6436\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 11978406.0364\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 11781501.3855\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11808330.1382\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 11932540.1236\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11856389.7382\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 11939436.4364\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8267485430759834 3147.430703431568 3077.1103595214668 0.9776578579368141 Eagle_education_Peter\n",
      "Building Eagle_health_Gregoria\n",
      "Building Eagle_lodging_Dawn\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 6s 16ms/step - loss: 12791.9635\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 11790.4838\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 11224.8731\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10507.5326\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9977.0536\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 9985.4616\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 9131.2437\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 8907.9878\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 8362.8423\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 7979.6042\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 7605.6234\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 6s 22ms/step - loss: 7191.4739\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 6865.0293\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 6528.1928\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 5885.2940\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 5974.5934\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 5505.0238\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 6s 22ms/step - loss: 5459.8420\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 5247.2565\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 4950.6108\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 4673.1119\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 4696.7917\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4278.0897\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4202.7478\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4090.3940\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3965.5433\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3581.1293\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 3355.1619\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 3363.9509\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 3348.7197\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3159.8625\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 6s 23ms/step - loss: 3117.2891\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 7s 25ms/step - loss: 3106.3895\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 3566.6117\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 3909.1336\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3854.0022\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 2529.3654\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 2603.4330\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 2593.5667\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 2406.0111\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 2430.3747\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 3s 13ms/step - loss: 2200.4695\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2223.2731\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2049.6040\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 2101.0941\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2100.8126\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 1818.6355\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 1852.1693\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1873.8892\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1715.0340\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.7248890899079364 92.73484781606874 40.28795110428591 0.434442413537934 Eagle_lodging_Dawn\n",
      "Building Eagle_office_Nereida\n",
      "Building Eagle_lodging_Tressa\n",
      "Building Eagle_education_Eileen\n",
      "Building Eagle_education_Wesley\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_12 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_13 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 12s 26ms/step - loss: 0.2151\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 0.0010\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 6s 22ms/step - loss: 6.5009e-04\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 5s 19ms/step - loss: 5.1615e-04\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 4.9405e-04\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 4.5366e-04\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3.8121e-04\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 3.3513e-04\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 3.0118e-04\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 3.1872e-04\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 3.6214e-04\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.6565e-04\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.9265e-04\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.6592e-04\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.6645e-04\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.7215e-04\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.6028e-04\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 2.7726e-04\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 2.6412e-04\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 2.7347e-04\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.7459e-04\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 2.6926e-04\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 2.9208e-04\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 6s 22ms/step - loss: 2.7352e-04\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 2.8554e-04\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.5326e-04\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.7900e-04\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5289e-04\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.7094e-04\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5857e-04\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4240e-04\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5326e-04\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.7861e-04\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.6948e-04\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.3889e-04\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4095e-04\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5743e-04\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5031e-04\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.3808e-04\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.6546e-04\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.9751e-04\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.3808e-04\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5066e-04\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4669e-04\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4313e-04\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.5507e-04\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 2.4662e-04\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 2.4915e-04\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4386e-04\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2.4135e-04\n",
      "cor,mean,rmse,rmse/mean,bldg: 0.7078518941773995 0.10523124548135475 0.019492057759539726 0.18523070472441952 Eagle_education_Wesley\n",
      "Building Eagle_health_Vincenza\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_14 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_15 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 11ms/step - loss: 15140.1029\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 13959.0278\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 13217.2604\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 12551.6077\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 12075.0680\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 11546.9544\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 10742.7101\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 10473.7568\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 9891.3729\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 9302.9502\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 8860.1470\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 8230.8417\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 7997.1698\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 7534.1423\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 7108.1232\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6659.1364\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 6447.0338\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 6011.1235\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 5743.1109\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5204.2445\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 5065.4138\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4654.2208\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 4396.6185\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 4243.6796\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3954.1916\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3748.5122\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3482.6692\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3317.6141\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 3084.4469\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2904.5071\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 2712.4402\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2583.3035\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 2454.8877\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2343.3019\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 2222.5969\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2112.4724\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1990.4781\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1881.2342\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1737.4454\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1633.6050\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 1499.9217\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 1385.7978\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 1318.5576\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 1217.9075\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1185.3162\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1163.7992\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1019.5770\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 958.5555\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 934.1135\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 3s 9ms/step - loss: 895.5528\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8217409529348659 121.90840096508735 29.805315358337825 0.244489429131907 Eagle_health_Vincenza\n",
      "Building Eagle_office_Dallas\n",
      "Building Eagle_education_Shante\n",
      "Building Eagle_office_Chauncey\n",
      "Building Eagle_office_Phyllis\n",
      "Building Eagle_office_Freida\n",
      "Building Eagle_office_Francis\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_16 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_17 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 18ms/step - loss: 85677.5626\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 83333.7831\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 82419.9984\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 79440.2280\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 77940.3023\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 76290.9436\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 74695.0099\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 73842.0424\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 71737.0532\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 70326.8685\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 69213.7434\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 67282.1949\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 66587.5793\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 63552.6710\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 63153.6809\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 61602.8147\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 61142.3762: 0s - loss: \n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 59081.5143\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 58015.3467\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 56144.7244\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 54839.0304\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 54747.7890\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 53009.7934\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 51037.0732\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 49750.6562\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 49423.7254\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 48880.5475\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 46803.3908\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 45343.9272\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 45560.2918\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 43218.7559\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 41799.5532\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 41887.0633\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 40861.5604\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 39332.9385\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 38706.4500\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 36997.0993\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 35939.4025\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 35624.5661\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 34694.2919\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 33534.9377\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 32644.6806\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 31596.2496\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 30731.7766\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 30118.8612\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 29116.3152\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 28062.6498\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 27400.5061\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 26920.0878\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 25694.4470\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.612183884934729 335.9563635497514 257.97589076067516 0.7678851147061895 Eagle_office_Francis\n",
      "Building Eagle_office_Sheree\n",
      "Building Eagle_education_Sherrill\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_18 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_19 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 17ms/step - loss: 5414452.8782\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 5276388.7255\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 5339145.8673\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 5351016.5255\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 5267362.9800\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 5356066.4509\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 5240334.3782\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 4s 15ms/step - loss: 5370844.0436\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5357518.2400\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5243037.9536\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5262155.1836\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 5324926.8982\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5282644.6400\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5238316.6545\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5297986.0127\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5174215.1709\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5216864.8727\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5115708.1182\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5176157.1909\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5160659.2709\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 5291593.3655\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5093444.2164\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5125691.1055\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5101926.7182\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5053956.0545\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5216649.1909\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5120549.2382\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5114100.0800\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5035029.5545\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4962628.0564\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 5044836.4236\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5029179.2255\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4966391.3364\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 5115273.7800\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4945241.1245\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4979136.2455\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4937484.3436\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4879439.8327\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4915982.0509\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4902743.7000\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4899811.6727\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4773783.2309\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4844876.1018\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4886159.9636\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4745283.2091\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4802619.4300\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4804029.2000\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4840672.9582\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4883365.8055\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4847691.3736\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.9191698832911114 2030.3587884358292 2109.351969898919 1.0389060209028107 Eagle_education_Sherrill\n",
      "Building Eagle_education_Brooke\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_20 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_21 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 16ms/step - loss: 4316591.2173\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4398152.8936\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4331366.7382\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 4379933.1182\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 4368342.7700\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 4356932.5473\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4359907.4964\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4284171.7973\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4271871.6882\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 4265004.0345\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4266062.1764\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4238891.5700\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4242693.1618\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4272400.7073\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 4258074.1000\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4244749.4427\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 4107597.7136\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4072622.5873\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 4208129.8573\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4098928.3482\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 4211015.2682\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 4084604.1973\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 4129055.7409\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4080885.3218\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 4147992.0391\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4058311.3109\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4061828.2527\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 4073518.8109\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 4103595.7645\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4087949.8845\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4066416.6082\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4024795.1173\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4019644.8073\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 6s 22ms/step - loss: 4053186.7182\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 4052782.3391\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 3940708.9409\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 3992467.0491\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 4015133.6118\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3960111.7600\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3949573.2927\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3949793.6173\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3925964.3464\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 3909007.3391\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3993615.1582\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3922725.1764\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3870997.6264\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3850124.5364\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3867909.1900\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3812512.9336\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 3814101.2936\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8668943529930063 1634.2804902547193 1574.5156045659933 0.9634304600433606 Eagle_education_Brooke\n",
      "Building Eagle_education_Alberto\n",
      "Building Eagle_food_Kay\n",
      "Building Eagle_health_Jodi\n",
      "Building Eagle_education_Norah\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_22 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_23 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 17ms/step - loss: 617698.3027\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 603746.8175\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 589358.1968\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 592994.8493 0s - loss:\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 582376.1041\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 576590.5760\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 576519.6832\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 573336.1302\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 570354.4440\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 576385.1417\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 557431.6372\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 567575.2395\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 557663.6560\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 566285.8726\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 551836.4186\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 549028.4168\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 543836.0123\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 545908.7702\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 527264.7669\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 545265.1561\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 534118.3649\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 517624.2074\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 523413.6560\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 516975.5298\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 524813.0819\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 505205.0731\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 501402.9694\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 493682.1642\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 505565.7694\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 487590.8165\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 498402.7815\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 484975.4133\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 481102.0159\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 482018.8850\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 470500.8400\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 475916.9193\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 468806.4623\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 466008.5951\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 462656.9907\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 6s 23ms/step - loss: 465383.1489\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 469336.9073\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 461272.1405\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 460319.8533\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 455827.5517\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 456129.7365\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 441355.0886\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 439303.0222\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 430162.9783\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 439085.3936\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 426986.9340\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8006961414633348 711.3309670245889 702.6314012357835 0.9877700167824908 Eagle_education_Norah\n",
      "Building Eagle_education_Will\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_24 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_25 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 8s 20ms/step - loss: 75173.9239\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 74063.6543\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 72061.9143\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 70320.4301\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 6s 20ms/step - loss: 67668.9840\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 67149.2606\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 65991.3685\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 64404.3549\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 62580.9634\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 4s 13ms/step - loss: 61358.1332\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 60966.3483\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 58793.3152\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 57225.8626\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 57394.2807\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 55586.2417\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 53962.0675\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 51885.1065\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 51225.6200\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 50708.6354\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 48916.3538\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 47506.7180\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 47809.2147\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 46033.8623\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 44581.8185\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 44167.6887\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 42886.8530\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 41323.0512\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 40505.0925\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 39555.9829\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 37491.9878\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 36913.8992\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 36384.2793\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 35039.4861\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 34422.1524\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 33978.7084\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 33129.6141\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 31857.0977\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 30780.5450\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 29538.1399\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 28710.7425\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 28436.2793\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 27391.0201\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 27029.5814\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 26011.1174\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 24803.1374\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 24665.8600\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 24086.2826\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 23973.1175\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 22539.5974\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 21912.8969\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.3432541996930441 226.06948909769716 59.66949775331811 0.2639431707103634 Eagle_education_Will\n",
      "Building Eagle_lodging_Blake\n",
      "Building Eagle_education_Petra\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_26 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_27 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 19ms/step - loss: 4169.1248\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 3604.2433\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3291.2943\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2959.6185\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2823.0995\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2611.4514\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 2401.3233\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 2209.2599\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 1978.1892\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 2011.7238\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 1850.4496\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1674.0975\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1625.4140\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1551.6868\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1451.3559\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1354.8745\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1280.4294\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 1167.3828\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1063.1755\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 1016.8615\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 977.2186\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 886.2410\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 854.5703\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 732.9362\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 729.8849\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 700.3456\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 658.5205\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 603.7197\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 555.0934\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 516.7348\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 488.1912\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 6s 21ms/step - loss: 435.6917\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 445.8773\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 420.1409\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 20ms/step - loss: 401.9582\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 367.9323\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 337.3870\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 348.2311\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 311.8949\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 315.6462\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 301.6466\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 288.5868\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 289.7668\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 4s 15ms/step - loss: 282.0259\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 268.1191\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 259.2554\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 328.2594\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 244.9250\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 241.3042\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 239.1627\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8318744067272149 56.96274977501869 17.001869974447093 0.29847347681771064 Eagle_education_Petra\n",
      "Building Eagle_lodging_Trina\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_28 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_29 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 6s 15ms/step - loss: 11567.5265\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 10643.0336\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10069.8739\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 9626.6072\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 9114.8388\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 8938.1308\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 8472.2695\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 8116.6159\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7851.8265\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7334.4436\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 7152.9860\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 6900.9075\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 6451.0202\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 6308.0362\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 6052.7766\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 5901.2900\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5440.3777\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5648.8058\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5200.2093\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4877.9748\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 5086.1727\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4914.5704\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4513.3468\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 4613.8376\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4462.7712\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 4342.1614\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 4354.2731\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 5346.1885\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3980.4729\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3684.3556\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3549.5962\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3455.5400\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3570.5800\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 3377.5594\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3227.3710\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 3330.1285\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 3286.4546\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2837.1953\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2811.3964\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2701.7071\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2736.3375\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2647.0900\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 2539.3893\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 2524.5891\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2501.3082\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2346.0291\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 2479.2699\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 2247.7192\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 2317.4433\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 2220.4565\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.7102555423632535 91.19691350551768 35.06685395246603 0.38451799084564836 Eagle_lodging_Trina\n",
      "Building Eagle_health_Reuben\n",
      "Building Eagle_education_Teresa\n",
      "Train on 8747 samples...\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_30 (SimpleRNN)    (None, 24, 20)            440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_31 (SimpleRNN)    (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 7s 16ms/step - loss: 28502.5592\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 27104.6614\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 26554.6198\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 25483.7137\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 23834.8288\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 24344.5327\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 23136.7348\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 22226.0994\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 21579.4632\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 20934.9665\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 21941.8794\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 21733.4729\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 20392.8151\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 20402.5547\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 19648.6533\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 17610.8953\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 4s 13ms/step - loss: 17332.8359\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 16151.9461\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 16482.6354\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 15457.0048\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 14539.4240\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 13996.8088\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 13876.0842\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 13108.5185\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12486.3264\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 12748.2122\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 12029.0023\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 11633.1025\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 11320.8921\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10989.7685\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 10295.5381\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 10367.3147\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 9784.7449\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 9360.7382\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 9580.1499\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 9248.4896\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 8868.3797\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 8497.0610\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 8066.5014\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 8243.7379\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 8072.3473\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 7963.5020\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 7792.3929\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 7434.3578\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 7443.0653\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 7301.0619\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 5s 17ms/step - loss: 7303.8205\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 4s 16ms/step - loss: 7184.8031\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 5s 16ms/step - loss: 7004.7534\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 6929.7252\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.730241336157007 148.50737262033823 45.49235584804314 0.306330622145913 Eagle_education_Teresa\n",
      "Building Eagle_office_Norbert\n",
      "Building Eagle_lodging_Casey\n",
      "Building Eagle_office_Tia\n",
      "Building Eagle_office_Remedios\n",
      "Building Eagle_office_Patrice\n",
      "Building Eagle_education_Shana\n",
      "History 24 Future 1\n",
      "Column 1: Correlation of steam and airTemperature\n",
      "          Using one weather feature as leading correlate.\n",
      "Column 2: Mean usage.\n",
      "          Using mean to help understand the RMSE.\n",
      "Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 4: RMSE/mean normalized to help understand RMSE.\n",
      "Column 5: Building.\n",
      "-0.9192    2030.36    2109.35  1.04   Eagle_education_Sherrill\n",
      "-0.8669    1634.28    1574.52  0.96   Eagle_education_Brooke\n",
      "-0.8492     477.41     352.09  0.74   Eagle_health_Athena\n",
      "-0.8319      56.96      17.00  0.30   Eagle_education_Petra\n",
      "-0.8267    3147.43    3077.11  0.98   Eagle_education_Peter\n",
      "-0.8217     121.91      29.81  0.24   Eagle_health_Vincenza\n",
      "-0.8040    1197.02    1119.57  0.94   Eagle_education_Roman\n",
      "-0.8007     711.33     702.63  0.99   Eagle_education_Norah\n",
      "-0.7661      81.87      30.38  0.37   Eagle_lodging_Edgardo\n",
      "-0.7555     181.94      56.11  0.31   Eagle_public_Alvin\n",
      "-0.7302     148.51      45.49  0.31   Eagle_education_Teresa\n",
      "-0.7249      92.73      40.29  0.43   Eagle_lodging_Dawn\n",
      "-0.7103      91.20      35.07  0.38   Eagle_lodging_Trina\n",
      "-0.6122     335.96     257.98  0.77   Eagle_office_Francis\n",
      "-0.3433     226.07      59.67  0.26   Eagle_education_Will\n",
      " 0.7079       0.11       0.02  0.19   Eagle_education_Wesley\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "EPOCHS=50\n",
    "# Test on only Peter just during code development\n",
    "for BLDG in all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        one_bldg_df = smooth(one_bldg_df) \n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        # Ideally, split Year1 = train, Year2 = test.\n",
    "        # Some data is incomplete, so split 1st half and 2nd half.\n",
    "        split = len(X)//2 \n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "        print(\"Train on\",len(X_train),\"samples...\")\n",
    "        model = make_RNN()\n",
    "        print(model.summary())\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Compare. Solve the problem that predict.shape != truth.shape \n",
    "        ##print(\" before ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
    "        nsamples, nsteps, ndim = y_test.shape\n",
    "        y_test = y_test.reshape(nsamples,nsteps*ndim)\n",
    "        #nsamples, nsteps, ndim = y_pred.shape\n",
    "        #y_pred = y_pred.reshape(nsamples,nsteps*ndim)\n",
    "        ##print(\" after ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][PREDICTOR_VARIABLE] \n",
    "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"cor,mean,rmse,rmse/mean,bldg:\",cor,mean,rmse,rmse/mean,BLDG)\n",
    "\n",
    "        ## break   ## REMOVE THIS LINE TO LOOP OVER BUILDINGS!\n",
    "        \n",
    "if True:\n",
    "    print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "    print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",PREDICTOR_VARIABLE)\n",
    "    print(\"          Using one weather feature as leading correlate.\")\n",
    "    print(\"Column 2: Mean usage.\")\n",
    "    print(\"          Using mean to help understand the RMSE.\")\n",
    "    print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "    print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
    "    print(\"Column 5: Building.\")\n",
    "    for cor in sorted(cors):\n",
    "        print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HW9PKIwow9p8"
   },
   "source": [
    "## Useful Links\n",
    "\n",
    "Jason Brownlee  \n",
    "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/\n",
    "https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w1WeQ4Vw9p-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_104CL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
