{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_107.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFNRPftWw9pK"
      },
      "source": [
        "# CNN \n",
        "Bug fix in selecting y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeDotTmw9pX",
        "outputId": "91aba099-b344-4548-cb6d-fe36b148cc1e"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "STEAM_FILE='steam.csv'\n",
        "WEATHER_FILE='weather.csv'\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_office_Lamont\n",
      "Building Eagle_health_Athena\n",
      "Train on 8747 samples such as [[[ 0.00e+00]\n",
      "  [-7.17e+00]\n",
      "  [-1.77e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.95e+02]\n",
      "  [ 2.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-7.05e+00]\n",
      "  [-1.74e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.95e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.96e+00]\n",
      "  [-1.72e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.72e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.90e+00]\n",
      "  [-1.69e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.65e+02]\n",
      "  [ 1.57e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.83e+00]\n",
      "  [-1.66e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.50e+02]\n",
      "  [ 1.40e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.69e+00]\n",
      "  [-1.62e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.20e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.48e+00]\n",
      "  [-1.58e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.32e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.23e+00]\n",
      "  [-1.54e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.27e+02]\n",
      "  [ 1.06e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.95e+00]\n",
      "  [-1.51e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.26e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.70e+00]\n",
      "  [-1.49e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 9.04e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.46e+00]\n",
      "  [-1.47e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.18e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.23e+00]\n",
      "  [-1.45e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.14e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.05e+00]\n",
      "  [-1.44e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.08e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.87e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.17e+02]\n",
      "  [ 9.50e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.68e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.50e+00]\n",
      "  [-1.41e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.08e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.24e+00]\n",
      "  [-1.40e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.08e+00]\n",
      "  [-1.39e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.33e+02]\n",
      "  [ 1.10e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.87e+00]\n",
      "  [-1.38e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.71e+00]\n",
      "  [-1.37e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.55e+00]\n",
      "  [-1.36e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.34e+00]\n",
      "  [-1.35e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.22e+00]\n",
      "  [-1.34e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.04e+00]\n",
      "  [-1.33e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]]\n",
      "Predict 8747 labels such as [856.91]\n",
      "make_CNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1057      \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8747, 24, 8, 1)\n",
      "Epoch 1/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 42984.9521\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 20404.6281\n",
      "Epoch 3/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 19847.8318\n",
      "Epoch 4/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 18678.3538\n",
      "Epoch 5/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 18307.8331\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.8403439150973826 477.4110643545475 180.8119238359288 0.3787342551023274 Eagle_health_Athena\n",
      "Building Eagle_assembly_Herbert\n",
      "Building Eagle_public_Alvin\n",
      "Train on 8747 samples such as [[[ 0.00e+00]\n",
      "  [-7.17e+00]\n",
      "  [-1.77e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.95e+02]\n",
      "  [ 2.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-7.05e+00]\n",
      "  [-1.74e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.95e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.96e+00]\n",
      "  [-1.72e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.72e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.90e+00]\n",
      "  [-1.69e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.65e+02]\n",
      "  [ 1.57e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.83e+00]\n",
      "  [-1.66e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.50e+02]\n",
      "  [ 1.40e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.69e+00]\n",
      "  [-1.62e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.20e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.48e+00]\n",
      "  [-1.58e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.32e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.23e+00]\n",
      "  [-1.54e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.27e+02]\n",
      "  [ 1.06e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.95e+00]\n",
      "  [-1.51e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.26e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.70e+00]\n",
      "  [-1.49e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 9.04e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.46e+00]\n",
      "  [-1.47e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.18e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.23e+00]\n",
      "  [-1.45e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.14e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.05e+00]\n",
      "  [-1.44e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.08e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.87e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.17e+02]\n",
      "  [ 9.50e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.68e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.50e+00]\n",
      "  [-1.41e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.08e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.24e+00]\n",
      "  [-1.40e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.08e+00]\n",
      "  [-1.39e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.33e+02]\n",
      "  [ 1.10e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.87e+00]\n",
      "  [-1.38e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.71e+00]\n",
      "  [-1.37e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.55e+00]\n",
      "  [-1.36e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.34e+00]\n",
      "  [-1.35e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.22e+00]\n",
      "  [-1.34e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.04e+00]\n",
      "  [-1.33e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]]\n",
      "Predict 8747 labels such as [424.34]\n",
      "make_CNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 1057      \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8747, 24, 8, 1)\n",
      "Epoch 1/5\n",
      "274/274 [==============================] - 2s 5ms/step - loss: 20571.6444\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 3665.1763\n",
      "Epoch 3/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 3895.4077\n",
      "Epoch 4/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 3590.6381\n",
      "Epoch 5/5\n",
      "274/274 [==============================] - 1s 2ms/step - loss: 3522.6895\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.759617507777322 181.93965687500085 65.90671578398623 0.36224491634205147 Eagle_public_Alvin\n",
      "Building Eagle_education_Raul\n",
      "Building Eagle_education_Roman\n",
      "Train on 8747 samples such as [[[ 0.00e+00]\n",
      "  [-7.17e+00]\n",
      "  [-1.77e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.95e+02]\n",
      "  [ 2.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-7.05e+00]\n",
      "  [-1.74e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.95e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.96e+00]\n",
      "  [-1.72e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.72e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.90e+00]\n",
      "  [-1.69e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.65e+02]\n",
      "  [ 1.57e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.83e+00]\n",
      "  [-1.66e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.50e+02]\n",
      "  [ 1.40e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.69e+00]\n",
      "  [-1.62e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.20e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.48e+00]\n",
      "  [-1.58e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.32e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.23e+00]\n",
      "  [-1.54e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.27e+02]\n",
      "  [ 1.06e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.95e+00]\n",
      "  [-1.51e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.26e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.70e+00]\n",
      "  [-1.49e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 9.04e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.46e+00]\n",
      "  [-1.47e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.18e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.23e+00]\n",
      "  [-1.45e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.14e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.05e+00]\n",
      "  [-1.44e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.08e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.87e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.17e+02]\n",
      "  [ 9.50e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.68e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.50e+00]\n",
      "  [-1.41e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.08e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.24e+00]\n",
      "  [-1.40e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.08e+00]\n",
      "  [-1.39e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.33e+02]\n",
      "  [ 1.10e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.87e+00]\n",
      "  [-1.38e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.71e+00]\n",
      "  [-1.37e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.55e+00]\n",
      "  [-1.36e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.34e+00]\n",
      "  [-1.35e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.22e+00]\n",
      "  [-1.34e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.04e+00]\n",
      "  [-1.33e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]]\n",
      "Predict 8747 labels such as [2374.16]\n",
      "make_CNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 1057      \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8747, 24, 8, 1)\n",
      "Epoch 1/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 318191.6911\n",
      "Epoch 2/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 93069.0874\n",
      "Epoch 3/5\n",
      "274/274 [==============================] - 1s 2ms/step - loss: 87951.7662\n",
      "Epoch 4/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 89194.2677\n",
      "Epoch 5/5\n",
      "274/274 [==============================] - 1s 3ms/step - loss: 89911.2267\n",
      "cor,mean,rmse,rmse/mean,bldg: -0.81855226807807 1197.016015073252 254.6884782687987 0.2127694826649524 Eagle_education_Roman\n",
      "Building Eagle_office_Mandi\n",
      "Building Eagle_education_Jewell\n",
      "Building Eagle_office_Henriette\n",
      "Building Eagle_health_Reba\n",
      "Building Eagle_lodging_Edgardo\n",
      "Train on 8747 samples such as [[[ 0.00e+00]\n",
      "  [-7.17e+00]\n",
      "  [-1.77e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.95e+02]\n",
      "  [ 2.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-7.05e+00]\n",
      "  [-1.74e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.95e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.96e+00]\n",
      "  [-1.72e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.80e+02]\n",
      "  [ 1.72e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.90e+00]\n",
      "  [-1.69e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.65e+02]\n",
      "  [ 1.57e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.83e+00]\n",
      "  [-1.66e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.50e+02]\n",
      "  [ 1.40e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.69e+00]\n",
      "  [-1.62e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.20e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.48e+00]\n",
      "  [-1.58e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.32e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-6.23e+00]\n",
      "  [-1.54e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.27e+02]\n",
      "  [ 1.06e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.95e+00]\n",
      "  [-1.51e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.26e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.70e+00]\n",
      "  [-1.49e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 9.04e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.46e+00]\n",
      "  [-1.47e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.18e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.23e+00]\n",
      "  [-1.45e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.14e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-5.05e+00]\n",
      "  [-1.44e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.04e+03]\n",
      "  [ 1.08e+02]\n",
      "  [ 8.63e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.87e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.17e+02]\n",
      "  [ 9.50e-01]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.68e+00]\n",
      "  [-1.42e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.25e+02]\n",
      "  [ 1.01e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.50e+00]\n",
      "  [-1.41e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.35e+02]\n",
      "  [ 1.08e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.24e+00]\n",
      "  [-1.40e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-4.08e+00]\n",
      "  [-1.39e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.33e+02]\n",
      "  [ 1.10e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.87e+00]\n",
      "  [-1.38e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.71e+00]\n",
      "  [-1.37e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.43e+02]\n",
      "  [ 1.19e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.55e+00]\n",
      "  [-1.36e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.34e+00]\n",
      "  [-1.35e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.58e+02]\n",
      "  [ 1.25e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.22e+00]\n",
      "  [-1.34e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]\n",
      "\n",
      " [[ 0.00e+00]\n",
      "  [-3.04e+00]\n",
      "  [-1.33e+01]\n",
      "  [ 0.00e+00]\n",
      "  [ 0.00e+00]\n",
      "  [ 1.03e+03]\n",
      "  [ 1.45e+02]\n",
      "  [ 1.16e+00]]]\n",
      "Predict 8747 labels such as [207.79]\n",
      "make_CNN\n",
      "input shape: (24, 8, 1)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 22, 6, 8)          80        \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 1057      \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "X_train.shape: (8747, 24, 8, 1)\n",
      "Epoch 1/5\n"
     ]
=======
      "cell_type": "code",
      "metadata": {
        "id": "5deM-us2w9pZ"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats  # mode\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Flatten\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdk510Cw9pc"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n",
        "def get_site_timeseries(panda,site):\n",
        "    # Assume the panda dataframe has a datetime column.\n",
        "    # (If not, call fix_date_type() before this.)\n",
        "    # Extract the timeseries for one site.\n",
        "    # Convert the datetime column to a DatetimeIndex.\n",
        "    site_df = panda[panda['site_id']==site]\n",
        "    temp_col = site_df['date']\n",
        "    temp_val = temp_col.values\n",
        "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
        "    dropped = site_df.drop('date',axis=1)\n",
        "    panda = dropped.set_index(temp_ndx)\n",
        "    return panda"
      ],
      "execution_count": 3,
      "outputs": []
>>>>>>> a345a1cad41cd4ae86a167016bb2411ca7866bb6
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEtz-J2B6vWw"
      },
      "source": [
        "## CNN setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZgkgsP6w9pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb8bc97-8572-4a2f-f454-d8810f4ce199"
      },
      "source": [
        "# Before analyzing the entire dataset, we look at this subset.\n",
        "SITE = 'Eagle'\n",
        "METER = 'steam'\n",
        "\n",
        "# Arrange \"picture\" of weather with temperatures toward the middle\n",
        "PREDICTED_VARIABLE = 'steam' \n",
        "PREDICTORS = ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
        "print(\"PREDICTORS=\",len(PREDICTORS),PREDICTORS)\n",
        "\n",
        "# Downsample True means collapse 365*24 measures to 365 daily averages\n",
        "# Downsample False means replace 365*24 measures with 365*24 window averages\n",
        "DOWNSAMPLE = False   \n",
        "\n",
        "STEPS_HISTORY = 24   # length of the predictor sequence\n",
        "STEPS_FUTURE =  1    # length of the predicted sequence\n",
        "\n",
        "## CNN parameters\n",
        "EPOCHS=25\n",
        "FILTERS = 8\n",
        "WIDTH = 3\n",
        "STRIDE = (1,1)\n",
        "INPUT_SHAPE = (STEPS_HISTORY,len(PREDICTORS),1) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTORS= 8 ['cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YVYM_bqw9pi"
      },
      "source": [
        "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
        "wet_df = fix_date_type(wet_df)\n",
        "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
        "stm_df = fix_date_type(stm_df)\n",
        "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
        "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynRgLt9w9pk"
      },
      "source": [
        "def smooth(df):\n",
        "    # For smoothing the 24 hour cycle, we do not want exponential smoothing.\n",
        "    smoothed = None\n",
        "    if DOWNSAMPLE:\n",
        "        # This alternate method samples down to 1/24 time steps.\n",
        "        smoothed = df.resample(\"24H\").mean() \n",
        "    else:\n",
        "        # This method does not reduce the number of time steps.\n",
        "        # Note the first 23 measurements get set to Nan.\n",
        "        smoothed=df.rolling(window=24).mean()\n",
        "        smoothed=smoothed[24:]\n",
        "    return smoothed\n",
        "\n",
        "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
        "# We will ignore buildings that have >max bad meter readings.\n",
        "def is_usable_column(df,column_name):\n",
        "    MAX_BAD = 500 \n",
        "    bad = df[column_name].isin([0]).sum()\n",
        "    return bad<=MAX_BAD\n",
        "\n",
        "def prepare_for_learning(df):\n",
        "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
        "    num_predictors = len(PREDICTORS)\n",
        "    X_shape = (num_samples,STEPS_HISTORY,num_predictors,1)\n",
        "    X=np.zeros(X_shape)\n",
        "    Y_shape = (num_samples,STEPS_FUTURE)\n",
        "    y=np.zeros(Y_shape)\n",
        "    predictor_series = df[PREDICTORS].values  # e.g. all weather values\n",
        "    predicted_series = df[PREDICTED_VARIABLE].values  # e.g. all meter readings\n",
        "    \n",
        "    for x0 in range (0,num_samples): # Loop over all 1000 samples\n",
        "        # This is one array of weather for previous 24 time periods\n",
        "        one_sample = predictor_series[x0:x0+STEPS_HISTORY]\n",
        "        one_label =  predicted_series[x0+STEPS_HISTORY:x0+STEPS_FUTURE]\n",
        "        # Loop over all 24 time periods\n",
        "        for x1 in range (0,STEPS_HISTORY): # In 1 sample, loop over 24 time periods\n",
        "            one_period = one_sample[x1]\n",
        "            for x2 in range (0,num_predictors): # In 1 time period, loop over 8 weather metrics\n",
        "                one_predictor = one_period[x2]\n",
        "                # for x3 in range (0,X_shape[3]): # In 1 metric, loop over vector dimensions\n",
        "                # In our data, each weather metric is a scalar.\n",
        "                x3 = 0\n",
        "                X[x0,x1,x2,x3] = one_predictor\n",
        "        y[x0]=predicted_series[x0:x0+STEPS_FUTURE]\n",
        "    return X,y \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoxunwFl6vW8"
      },
      "source": [
        "def make_CNN():\n",
        "    print(\"make_CNN\")\n",
        "    print(\"input shape:\",INPUT_SHAPE)\n",
        "    cnn = Sequential()\n",
        "    cnn.add(\n",
        "        Conv2D( input_shape=INPUT_SHAPE,\n",
        "            filters=FILTERS,kernel_size=WIDTH,strides=STRIDE,\n",
        "            activation=None, padding=\"valid\"))\n",
        "    cnn.add(Flatten())\n",
        "    cnn.add(Dense(STEPS_FUTURE))   \n",
        "    cnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
        "    return cnn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B8uACMc6vW_"
      },
      "source": [
        "## Process all buildings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypnRqq9w9p4",
        "scrolled": false,
        "outputId": "5e58d2c0-ca1b-4c98-bd2f-d483aa23da6d"
      },
      "source": [
        "cors = []\n",
        "ONE_PREDICTOR = 'dewTemperature'  ## illustrate difficulty by showing best correlate\n",
        "for BLDG in all_buildings:\n",
        "    print(\"Building\",BLDG)\n",
        "    # Get steam usage for one building.\n",
        "    bldg_specific_steam = stm_df[[BLDG]]\n",
        "    # Concatenate steam usage with weather.\n",
        "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
        "    # Drop the site, which is constant (we selected for one site).\n",
        "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
        "    # The original steam table used column name = building name.\n",
        "    # We are processing one building, so rename to the column 'steam'.\n",
        "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
        "    # In order to filter bad buildings, count sum of NaN + zero.\n",
        "    one_bldg_df = one_bldg_df.fillna(0)\n",
        "    \n",
        "    if is_usable_column(one_bldg_df,METER):\n",
        "        one_bldg_df = smooth(one_bldg_df) \n",
        "        X,y = prepare_for_learning(one_bldg_df)\n",
        "        # Ideally, split Year1 = train, Year2 = test.\n",
        "        # Some data is incomplete, so split 1st half and 2nd half.\n",
        "        split = len(X)//2 \n",
        "        X_train = np.asarray(X[0:split])\n",
        "        y_train = np.asarray(y[0:split])\n",
        "        X_test = np.asarray(X[split:])\n",
        "        y_test = np.asarray(y[split:])\n",
        "        print(\"Train on\",len(X_train),\"samples such as\",X_train[100][0])\n",
        "        print(\"Predict\",len(y_train),\"labels such as\",y_train[100])\n",
        "\n",
        "        model = make_CNN()\n",
        "        print(model.summary())\n",
        "        print(\"X_train.shape:\",X_train.shape)\n",
        "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Compare. Solve the problem that predict.shape != truth.shape \n",
        "        #print(\" before ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
        "        #nsamples, nsteps, ndim = y_test.shape\n",
        "        #y_test = y_test.reshape(nsamples,nsteps*ndim)\n",
        "        #nsamples, nsteps, ndim = y_pred.shape\n",
        "        #y_pred = y_pred.reshape(nsamples,nsteps*ndim)\n",
        "        ##print(\" after ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
        "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
        "        # Keep a table for reporting later.\n",
        "        mean = one_bldg_df[METER].mean()\n",
        "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][ONE_PREDICTOR] \n",
        "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
        "        print(\"cor,mean,rmse,rmse/mean,bldg:\",cor,mean,rmse,rmse/mean,BLDG)\n",
        "\n",
        "        ## break   ## REMOVE THIS LINE TO LOOP OVER BUILDINGS!\n",
        "        \n",
        "if True:\n",
        "    print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
        "    print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",ONE_PREDICTOR)\n",
        "    print(\"          Using one weather feature as leading correlate.\")\n",
        "    print(\"Column 2: Mean usage.\")\n",
        "    print(\"          Using mean to help understand the RMSE.\")\n",
        "    print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
        "    print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
        "    print(\"Column 5: Building.\")\n",
        "    for cor in sorted(cors):\n",
        "        print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            "Building Eagle_health_Athena\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [856.91]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 2s 3ms/step - loss: 56686.5848\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 19608.4118\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 20073.0126\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18980.4050\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18533.9380\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18945.5574\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18674.3660\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17890.3272\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 19559.0105\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18417.3292\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17862.8527\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18294.3271\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17288.3245\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16937.3600\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17809.6126\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17012.8936\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 18083.1261\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17021.8322\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17356.5762\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17655.2563\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16214.9646\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17509.4499\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16719.0203\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17257.6534\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 17280.0036\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8403439150973826 477.4110643545472 160.9849911701198 0.3372041479343784 Eagle_health_Athena\n",
            "Building Eagle_assembly_Herbert\n",
            "Building Eagle_public_Alvin\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [424.34]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8704.5287\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3688.9003\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3681.1312\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4090.0925\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3539.2013\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3605.4984\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3534.3282\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3599.9554\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3481.5902\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3598.7487\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3529.2118\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3494.1558\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3530.6849\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3529.3108\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3330.4658\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3518.1331\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3410.0959\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3540.5471\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3549.2954\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3361.2452\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3430.7063\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3370.6102\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3278.8966\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3326.4092\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3326.1289\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.759617507777322 181.93965687500068 78.67013638686082 0.4323968602453182 Eagle_public_Alvin\n",
            "Building Eagle_education_Raul\n",
            "Building Eagle_education_Roman\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [2374.16]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 242918.8322\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 90925.1515\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 86134.6669\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 87467.3192\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 86289.9063\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 85208.3236\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 84147.9903\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 83552.0537\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 78209.0922\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 79932.5177\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 77759.2901\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 80410.7067\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 75414.6221\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 82156.7244\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 78183.0415\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 78437.5915\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 80620.5375\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 78376.9496\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 79275.0631\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 78146.7885\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 76687.0854\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 76643.1355\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 76353.7167\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 77171.4037\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 76848.2674\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.81855226807807 1197.0160150732597 240.8009430798691 0.20116768702140683 Eagle_education_Roman\n",
            "Building Eagle_office_Mandi\n",
            "Building Eagle_education_Jewell\n",
            "Building Eagle_office_Henriette\n",
            "Building Eagle_health_Reba\n",
            "Building Eagle_lodging_Edgardo\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [207.79]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3803.7027\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 987.9137\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 994.9116\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1020.4439\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 949.9923\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 856.3845\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 879.5150\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 845.2146\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 856.2762\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 892.5684\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 893.7702\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 920.6423\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 831.8826\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 861.4405\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 860.0375\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 853.5888\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 908.7680\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 887.5644\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 899.0946\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 864.0939\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 865.5415\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 827.7912\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 880.8989\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 827.8305\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 843.1541\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7222281821273872 81.87169456264219 30.137094812378617 0.3681015151008012 Eagle_lodging_Edgardo\n",
            "Building Eagle_education_Cassie\n",
            "Building Eagle_education_Peter\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [6895.45]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3906787.3082\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 906326.7227\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 646440.3651\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 599960.2191\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 600914.5182\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 595025.5450\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 574726.0524\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 572688.7602\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 542984.7373\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 539150.4258\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 537209.7051\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 544310.2869\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 524509.1925\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 525159.6228\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 535807.6107\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 511045.2125\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 494761.7522\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 511375.5169\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 509477.5580\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 504519.8194\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 496329.4455\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 505336.8497\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 497347.6244\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 502039.4026\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 477965.3693\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.850213186834573 3147.4307034315702 696.9744594060988 0.22144235253414915 Eagle_education_Peter\n",
            "Building Eagle_health_Gregoria\n",
            "Building Eagle_lodging_Dawn\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [256.52]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2592.2578\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1458.6623\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1369.5492\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1340.1217\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1384.9945\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1409.6011\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1324.3537\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1329.2521\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1349.1827\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1307.0820\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1307.3267\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1272.4528\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1253.9320\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1284.9499\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1242.1882\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1222.5440\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1414.7622\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1303.4606\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1313.6661\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1297.3219\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1261.6443\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1220.6356\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1300.3478\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1202.0237\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1284.2066\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7129673388128998 92.73484781606884 36.522175924532455 0.3938344299326493 Eagle_lodging_Dawn\n",
            "Building Eagle_office_Nereida\n",
            "Building Eagle_lodging_Tressa\n",
            "Building Eagle_education_Eileen\n",
            "Building Eagle_education_Wesley\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [0.08]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6603.6837\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 24.0993\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 16.9853\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 12.2950\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9.4360\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7.8479\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7.6485\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6.7253\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5.2028\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6.2439\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5.5621\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5.3946\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 5.2889\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9.8254\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9.2691\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9.4001\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8.2175\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 6.6687\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9.6150\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6.3382\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6.9865\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 14.8317\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5.1086\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 6.7158\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 8.2002\n",
            "cor,mean,rmse,rmse/mean,bldg: 0.7230993469793111 0.10523124548135511 0.9124493710995225 8.670897763546764 Eagle_education_Wesley\n",
            "Building Eagle_health_Vincenza\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [201.49]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 5326.7402\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 611.5574\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 586.2609\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 557.7555\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 545.5400\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 499.4267\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 635.5284\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 575.9867\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 609.4158\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 572.9813\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 506.1478\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 549.2981\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 548.7993\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 544.1850\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 528.5790\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 518.4618\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 520.4009\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 515.9301\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 494.9897\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 482.8593\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 504.9153\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 488.4446\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 500.7917\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 541.6859\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 511.0482\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7961450049576672 121.90840096508708 22.677155762106825 0.18601799041397693 Eagle_health_Vincenza\n",
            "Building Eagle_office_Dallas\n",
            "Building Eagle_education_Shante\n",
            "Building Eagle_office_Chauncey\n",
            "Building Eagle_office_Phyllis\n",
            "Building Eagle_office_Freida\n",
            "Building Eagle_office_Francis\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [412.35]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 9458.6446\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4291.3310\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 4091.9724\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3998.6232\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3956.3397\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3975.3161\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3814.4977\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3647.7161\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3713.4870\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3726.1212\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3795.3697\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3711.1746\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3498.7845\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3746.0922\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3806.0975\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3395.4897\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3594.0330\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3639.6506\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3697.8893\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3475.3323\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3593.5246\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3608.8603\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3782.4173\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3572.8031\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3666.4068\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.5552570597696993 335.95636354975403 127.92100706966886 0.38076673326869187 Eagle_office_Francis\n",
            "Building Eagle_office_Sheree\n",
            "Building Eagle_education_Sherrill\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [3984.16]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1409732.6311\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 356037.1149\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 291765.8491\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 273361.3435\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 267603.2483\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 247573.9576\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 234686.3927\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 229340.5261\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 234891.7796\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 217990.5844\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 221517.3416\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 219534.2257\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 218615.1238\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 204357.2112\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 211055.1606\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 210513.2155\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 210899.8611\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 211853.0049\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 220614.3455\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 210238.6963\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 208463.5770\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 211646.3566\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 206407.7797\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 212210.7360\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 201309.6568\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8876757978269461 2030.3587884358317 410.3815231950081 0.20212266203017348 Eagle_education_Sherrill\n",
            "Building Eagle_education_Brooke\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [3581.43]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1017748.2939\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 298350.0616\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 259830.9240\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 243269.1847\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 242594.0917\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 231573.6430\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 221650.4885\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 217051.6319\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 215756.6859\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 217421.0102\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 208529.9106\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 205873.4720\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 207153.9370\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 208557.4685\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 206840.8048\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 199040.2816\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 201308.2688\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 202578.0216\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 202338.3069\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 204929.6240\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 201483.8956\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 190340.0943\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 192722.5159\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 197275.9468\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 199008.1667\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.8545240602973272 1634.2804902547134 737.369852412033 0.4511892889923131 Eagle_education_Brooke\n",
            "Building Eagle_education_Alberto\n",
            "Building Eagle_food_Kay\n",
            "Building Eagle_health_Jodi\n",
            "Building Eagle_education_Norah\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [1543.14]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 106242.6389\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 74695.2760\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 71581.8321\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 70575.5272\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 67392.0898\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 66348.6104\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 64541.2512\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 66156.3454\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 64241.5924\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 66002.7999\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 63420.6277\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 64919.6956\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 63672.1296\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 63815.9909\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 62855.2989\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 61876.3693\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 61287.8889\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 60404.1705\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 62929.4723\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 60978.3008\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 63353.5666\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 60969.1132\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 60870.8253\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 63535.2033\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 62398.5049\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7722467071075976 711.3309670245861 245.6342712635548 0.3453164316619226 Eagle_education_Norah\n",
            "Building Eagle_education_Will\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [297.45]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 11103.3201\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7303.0598\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7732.7040\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7248.7273\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7515.1875\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7812.0688\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7085.1286\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7330.1804\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7365.5904\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7325.4132\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7344.8461\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7126.5012\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7420.1907\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7361.9697\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7438.0800\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7600.7942\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7439.7832\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7219.9192\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7078.2145\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7515.4096\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7390.3390\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 7474.2953\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7346.1384\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7410.9302\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 7159.1428\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.3578536854358871 226.06948909769736 85.13843960119485 0.37660296372148533 Eagle_education_Will\n",
            "Building Eagle_lodging_Blake\n",
            "Building Eagle_education_Petra\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [135.07]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1302.9100\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 444.1770\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 415.6320\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 401.4668\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 396.7102\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 416.0757\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 392.5519\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 390.1511\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 399.0999\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 383.7105\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 351.0718\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 398.7995\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 397.8987\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 361.5290\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 386.8514\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 342.9205\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 374.8993\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 369.4864\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 374.4484\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 360.1519\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 350.1401\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 344.4666\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 342.5963\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 353.3593\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 332.2417\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.7988023057131248 56.9627497750187 19.01945300010917 0.333892817239842 Eagle_education_Petra\n",
            "Building Eagle_lodging_Trina\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [304.34]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3373.2770\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2067.9466\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1998.9489\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1896.4069\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1953.8333\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1903.5410\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1961.7184\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2010.9487\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1916.6795\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1924.9036\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1909.6315\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1909.0672\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1921.4373\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1923.2673\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1924.1351\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1816.8758\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1906.3013\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1979.3377\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1929.0226\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1839.3850\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1942.7804\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1978.2966\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1877.3836\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 1932.7364\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 1882.4492\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.6740953050024701 91.19691350551751 39.704951262023904 0.43537604219052556 Eagle_lodging_Trina\n",
            "Building Eagle_health_Reuben\n",
            "Building Eagle_education_Teresa\n",
            "Train on 8747 samples such as [[   0.  ]\n",
            " [  -7.17]\n",
            " [ -17.68]\n",
            " [   0.  ]\n",
            " [   0.  ]\n",
            " [1035.42]\n",
            " [ 195.  ]\n",
            " [   2.19]]\n",
            "Predict 8747 labels such as [234.44]\n",
            "make_CNN\n",
            "input shape: (24, 8, 1)\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 22, 6, 8)          80        \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 1056)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 1057      \n",
            "=================================================================\n",
            "Total params: 1,137\n",
            "Trainable params: 1,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train.shape: (8747, 24, 8, 1)\n",
            "Epoch 1/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 20209.0943\n",
            "Epoch 2/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3169.5068\n",
            "Epoch 3/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 3082.5734\n",
            "Epoch 4/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2953.1393\n",
            "Epoch 5/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2881.5684\n",
            "Epoch 6/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2896.1634\n",
            "Epoch 7/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2745.2720\n",
            "Epoch 8/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2887.0298\n",
            "Epoch 9/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2733.8171\n",
            "Epoch 10/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2611.4961\n",
            "Epoch 11/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2724.4845\n",
            "Epoch 12/25\n",
            "274/274 [==============================] - 2s 6ms/step - loss: 2636.5801\n",
            "Epoch 13/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2651.6521\n",
            "Epoch 14/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2787.7901\n",
            "Epoch 15/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2905.8767\n",
            "Epoch 16/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2589.6558\n",
            "Epoch 17/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2552.2944\n",
            "Epoch 18/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2784.0472\n",
            "Epoch 19/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2613.5903\n",
            "Epoch 20/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2549.0707\n",
            "Epoch 21/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2628.9003\n",
            "Epoch 22/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2597.6827\n",
            "Epoch 23/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2633.5614\n",
            "Epoch 24/25\n",
            "274/274 [==============================] - 1s 4ms/step - loss: 2490.7948\n",
            "Epoch 25/25\n",
            "274/274 [==============================] - 1s 3ms/step - loss: 2630.6417\n",
            "cor,mean,rmse,rmse/mean,bldg: -0.6796379179294123 148.50737262033783 42.35600080504578 0.28521143467624177 Eagle_education_Teresa\n",
            "Building Eagle_office_Norbert\n",
            "Building Eagle_lodging_Casey\n",
            "Building Eagle_office_Tia\n",
            "Building Eagle_office_Remedios\n",
            "Building Eagle_office_Patrice\n",
            "Building Eagle_education_Shana\n",
            "History 24 Future 1\n",
            "Column 1: Correlation of steam and dewTemperature\n",
            "          Using one weather feature as leading correlate.\n",
            "Column 2: Mean usage.\n",
            "          Using mean to help understand the RMSE.\n",
            "Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\n",
            "Column 4: RMSE/mean normalized to help understand RMSE.\n",
            "Column 5: Building.\n",
            "-0.8877    2030.36     410.38  0.20   Eagle_education_Sherrill\n",
            "-0.8545    1634.28     737.37  0.45   Eagle_education_Brooke\n",
            "-0.8502    3147.43     696.97  0.22   Eagle_education_Peter\n",
            "-0.8403     477.41     160.98  0.34   Eagle_health_Athena\n",
            "-0.8186    1197.02     240.80  0.20   Eagle_education_Roman\n",
            "-0.7988      56.96      19.02  0.33   Eagle_education_Petra\n",
            "-0.7961     121.91      22.68  0.19   Eagle_health_Vincenza\n",
            "-0.7722     711.33     245.63  0.35   Eagle_education_Norah\n",
            "-0.7596     181.94      78.67  0.43   Eagle_public_Alvin\n",
            "-0.7222      81.87      30.14  0.37   Eagle_lodging_Edgardo\n",
            "-0.7130      92.73      36.52  0.39   Eagle_lodging_Dawn\n",
            "-0.6796     148.51      42.36  0.29   Eagle_education_Teresa\n",
            "-0.6741      91.20      39.70  0.44   Eagle_lodging_Trina\n",
            "-0.5553     335.96     127.92  0.38   Eagle_office_Francis\n",
            "-0.3579     226.07      85.14  0.38   Eagle_education_Will\n",
            " 0.7231       0.11       0.91  8.67   Eagle_education_Wesley\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1WeQ4Vw9p-"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
<<<<<<< HEAD
   ],
   "source": [
    "cors = []\n",
    "ONE_PREDICTOR = 'dewTemperature'  ## illustrate difficulty by showing best correlate\n",
    "for BLDG in all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        one_bldg_df = smooth(one_bldg_df) \n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        # Ideally, split Year1 = train, Year2 = test.\n",
    "        # Some data is incomplete, so split 1st half and 2nd half.\n",
    "        split = len(X)//2 \n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "        print(\"Train on\",len(X_train),\"samples such as\",X_train[100][0])\n",
    "        print(\"Predict\",len(y_train),\"labels such as\",y_train[100])\n",
    "\n",
    "        model = make_CNN()\n",
    "        print(model.summary())\n",
    "        print(\"X_train.shape:\",X_train.shape)\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Compare. Solve the problem that predict.shape != truth.shape \n",
    "        #print(\" before ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
    "        #nsamples, nsteps, ndim = y_test.shape\n",
    "        #y_test = y_test.reshape(nsamples,nsteps*ndim)\n",
    "        #nsamples, nsteps, ndim = y_pred.shape\n",
    "        #y_pred = y_pred.reshape(nsamples,nsteps*ndim)\n",
    "        ##print(\" after ytestshape\",y_test.shape,\"ypredshape\",y_pred.shape)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cor = one_bldg_df.corr().loc[PREDICTED_VARIABLE][ONE_PREDICTOR] \n",
    "        cors.append([cor,mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"cor,mean,rmse,rmse/mean,bldg:\",cor,mean,rmse,rmse/mean,BLDG)\n",
    "\n",
    "        ## break   ## REMOVE THIS LINE TO LOOP OVER BUILDINGS!\n",
    "        \n",
    "if True:\n",
    "    print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "    print(\"Column 1: Correlation of\",PREDICTED_VARIABLE,\"and\",ONE_PREDICTOR)\n",
    "    print(\"          Using one weather feature as leading correlate.\")\n",
    "    print(\"Column 2: Mean usage.\")\n",
    "    print(\"          Using mean to help understand the RMSE.\")\n",
    "    print(\"Column 3: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "    print(\"Column 4: RMSE/mean normalized to help understand RMSE.\")\n",
    "    print(\"Column 5: Building.\")\n",
    "    for cor in sorted(cors):\n",
    "        print(\"%7.4f %10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3],cor[4]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w1WeQ4Vw9p-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_104CL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
=======
  ]
}
>>>>>>> a345a1cad41cd4ae86a167016bb2411ca7866bb6
