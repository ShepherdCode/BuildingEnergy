{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Eagle_ARIMA.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8_C9we-hgL",
        "outputId": "7fe929ab-f1d9-4521-8b88-c55d49189def"
      },
      "source": [
        "DATAPATH=''\n",
        "try:\n",
        "    # On Google Drive, set path to my drive / data directory.\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "    PATH='/content/drive/'\n",
        "    drive.mount(PATH)\n",
        "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
        "except:\n",
        "    # On home computer, set path to local data directory.\n",
        "    IN_COLAB = False\n",
        "    DATAPATH='data/'  # must end in \"/\"\n",
        "\n",
        "ZIP_FILE='BuildingData.zip'\n",
        "ZIP_PATH = DATAPATH+ZIP_FILE\n",
        "STEAM_FILE='steam.csv'\n",
        "MODEL_FILE='Model'  # will be used later to save models"
      ],
      "id": "ZX8_C9we-hgL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbMd_R9m-hgc",
        "outputId": "1b5b4764-99b7-4811-9d05-65a64697b779"
      },
      "source": [
        "from os import listdir\n",
        "import csv\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import statsmodels.api as sm\n",
        "#from statsmodels.tsa.arima.model import ARIMA\n",
        "#from pmdarima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.stattools import adfuller,acf,pacf\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tools.eval_measures import rmse\n",
        "from math import sqrt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
        "np.set_printoptions(precision=2)"
      ],
      "id": "bbMd_R9m-hgc",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73L_-TTV-hge"
      },
      "source": [
        "def read_zip_to_panda(zip_filename,csv_filename):\n",
        "    zip_handle = ZipFile(zip_filename)\n",
        "    csv_handle = zip_handle.open(csv_filename)\n",
        "    panda = pd.read_csv(csv_handle)\n",
        "    return panda\n",
        "def fix_date_type(panda):\n",
        "    # Convert the given timestamp column to the pandas datetime data type.\n",
        "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
        "    indexed = panda.set_index(['timestamp'])\n",
        "    return indexed\n",
        "def get_site_timeseries(panda,site):\n",
        "    # Assume the panda dataframe has a datetime column.\n",
        "    # (If not, call fix_date_type() before this.)\n",
        "    # Extract the timeseries for one site.\n",
        "    # Convert the datetime column to a DatetimeIndex.\n",
        "    site_df = panda[panda['site_id']==site]\n",
        "    temp_col = site_df['date']\n",
        "    temp_val = temp_col.values\n",
        "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
        "    dropped = site_df.drop('date',axis=1)\n",
        "    panda = dropped.set_index(temp_ndx)\n",
        "    return panda"
      ],
      "id": "73L_-TTV-hge",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRXpMsYw-hgg",
        "outputId": "6ce198ec-08a2-4d4c-dc0b-6fb10eecdb2f"
      },
      "source": [
        "steam_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
        "steam_df = fix_date_type(steam_df)\n",
        "steam_df.info()"
      ],
      "id": "pRXpMsYw-hgg",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 17544 entries, 2016-01-01 00:00:00 to 2017-12-31 23:00:00\n",
            "Columns: 370 entries, Peacock_lodging_Terrie to Cockatoo_public_Shad\n",
            "dtypes: float64(370)\n",
            "memory usage: 49.7 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgW1QMiA-hgh",
        "outputId": "920108d3-11fd-4ef7-fc1e-79c3661f042f"
      },
      "source": [
        "buildings = [c for c in steam_df.columns if 'Eagle' in c]\n",
        "print(buildings)"
      ],
      "id": "fgW1QMiA-hgh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Eagle_office_Lamont', 'Eagle_health_Athena', 'Eagle_assembly_Herbert', 'Eagle_public_Alvin', 'Eagle_education_Raul', 'Eagle_education_Roman', 'Eagle_office_Mandi', 'Eagle_education_Jewell', 'Eagle_office_Henriette', 'Eagle_health_Reba', 'Eagle_lodging_Edgardo', 'Eagle_education_Cassie', 'Eagle_education_Peter', 'Eagle_health_Gregoria', 'Eagle_lodging_Dawn', 'Eagle_office_Nereida', 'Eagle_lodging_Tressa', 'Eagle_education_Eileen', 'Eagle_education_Wesley', 'Eagle_health_Vincenza', 'Eagle_office_Dallas', 'Eagle_education_Shante', 'Eagle_office_Chauncey', 'Eagle_office_Phyllis', 'Eagle_office_Freida', 'Eagle_office_Francis', 'Eagle_office_Sheree', 'Eagle_education_Sherrill', 'Eagle_education_Brooke', 'Eagle_education_Alberto', 'Eagle_food_Kay', 'Eagle_health_Jodi', 'Eagle_education_Norah', 'Eagle_education_Will', 'Eagle_lodging_Blake', 'Eagle_education_Petra', 'Eagle_lodging_Trina', 'Eagle_health_Reuben', 'Eagle_education_Teresa', 'Eagle_office_Norbert', 'Eagle_lodging_Casey', 'Eagle_office_Tia', 'Eagle_office_Remedios', 'Eagle_office_Patrice', 'Eagle_education_Shana']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KQedtd--hgj"
      },
      "source": [
        "# Before analyzing the entire dataset, we look at this subset.\n",
        "SITE = 'Eagle'\n",
        "METER = 'steam'\n",
        "\n",
        "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
        "stm_df = fix_date_type(stm_df)\n",
        "stm_df = stm_df.fillna(4)\n",
        "#site_specific_weather = stm_df.loc[stm_df['site_id'] == SITE]\n",
        "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]"
      ],
      "id": "9KQedtd--hgj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99aQjjy-hgl"
      },
      "source": [
        "## Check Stationarity"
      ],
      "id": "t99aQjjy-hgl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "HBpO9bek-hgl",
        "outputId": "ad4c8367-625a-4e00-8f33-6ed276356034"
      },
      "source": [
        "\n",
        "for BLDG in all_buildings:\n",
        "    print(\"Building\",BLDG)\n",
        "    # Get steam usage for one building.\n",
        "    bldg_specific_steam = stm_df[BLDG]\n",
        "    bldg_specific_steam= pd.DataFrame(bldg_specific_steam)\n",
        "    bldg_specific_steam = bldg_specific_steam.fillna(0)\n",
        "    #Perform Building Dickey-Fuller test:\n",
        "    print ('Results of Dickey-Fuller Test: \\n the test statistic is less than critical value, reject the null hypothesis')\n",
        "    dftest = adfuller(bldg_specific_steam, autolag = 'AIC') #AIC gives the information about time series \n",
        "    dfoutput= pd.Series (dftest[0:4], index= ['Test Statistic','p-value: \\n p-value is smaller than 0.05','#lags used', 'Number of Observations Used'])\n",
        "    for key, value in dftest [4].items ():\n",
        "        dfoutput ['Critical Value (%s)' %key] = value\n",
        "\n",
        "    print (dfoutput)\n",
        "    #Determine the rolling statistic\n",
        "    rolmean = bldg_specific_steam.rolling(window = 24).mean()\n",
        "    rolstd = bldg_specific_steam.rolling(window = 24).std()\n",
        "\n",
        "    #Checking the Stationarity\n",
        "    #Plot rolling statistics\n",
        "    plt.figure(figsize=(20,10))\n",
        "    orig = plt.plot (bldg_specific_steam, color = 'blue',label = (BLDG))\n",
        "    mean = plt.plot (rolmean, color = 'red',label = 'Rolling Mean')\n",
        "    std = plt.plot (rolstd, color = 'black',label = 'Rolling std')\n",
        "    plt.legend (loc ='best')\n",
        "    plt.title ('Rolling Mean & Standard Deviation')\n",
        "    plt.show (block = False)\n",
        "print(bldg_specific_steam)\n"
      ],
      "id": "HBpO9bek-hgl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building Eagle_office_Lamont\n",
            "Results of Dickey-Fuller Test: \n",
            " the test statistic is less than critical value, reject the null hypothesis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-061912e06dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Perform Building Dickey-Fuller test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Results of Dickey-Fuller Test: \\n the test statistic is less than critical value, reject the null hypothesis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdftest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbldg_specific_steam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautolag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AIC'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#AIC gives the information about time series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdfoutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Test Statistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'p-value: \\n p-value is smaller than 0.05'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'#lags used'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Number of Observations Used'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdftest\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/stattools.py\u001b[0m in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    234\u001b[0m                          'deterministic regressors')\n\u001b[1;32m    235\u001b[0m     \u001b[0mxdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mxdall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxdall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/tsatools.py\u001b[0m in \u001b[0;36mlagmat\u001b[0;34m(x, maxlag, trim, original, use_pandas)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0mnobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sep'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mdropidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynIEE-G6-hgn"
      },
      "source": [
        "## Automatic Time Series Decomposition"
      ],
      "id": "ynIEE-G6-hgn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0brLPN_x-hgo"
      },
      "source": [
        "\n",
        "stm_df = stm_df.fillna(4)\n",
        "\n",
        "for time_series in all_buildings:\n",
        "    bldg_specific_steam = stm_df[time_series]\n",
        "    bldg_specific_steam= pd.DataFrame(bldg_specific_steam)\n",
        "    decomposition = seasonal_decompose (bldg_specific_steam.values,period = 24*30, model = 'additive') \n",
        "    decomposition.plot()\n",
        "    plt.title(time_series)\n",
        "    plt.tight_layout()\n",
        "\n",
        "print('The result:')\n",
        "print(decomposition.observed)\n",
        "print(decomposition.trend)\n",
        "print(decomposition.seasonal)\n",
        "print(decomposition.resid)\n",
        "\n",
        "\n"
      ],
      "id": "0brLPN_x-hgo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9oQ0iTX-hgq"
      },
      "source": [
        "## Build ARIMA"
      ],
      "id": "A9oQ0iTX-hgq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0CtGAF5-hgu"
      },
      "source": [
        "## Determine the order of AR, I and MA component \n",
        "AR = p = period for autoregressive model (regression the past lag value, PACF method),\n",
        "<br>\n",
        "Integrated = d = order of autoregression (differenced value from present and previous to eliminate the effects of seasonality; removing the trend and seasonality to make it stationary)\n",
        "<br>\n",
        "MA = q = periods in moving average (present value is not only depended on the past value but the error lag value as well, use the ACF method)\n",
        "<br>\n",
        "Using AFC autocorreclation plot and PACF partial autocorrelatioin plot"
      ],
      "id": "V0CtGAF5-hgu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op7wUI1C-hgv"
      },
      "source": [
        "for BLDG in all_buildings:\n",
        " \n",
        "    bldg_specific_steam = stm_df[BLDG]\n",
        "    bldg_specific_steam= pd.DataFrame(bldg_specific_steam)\n",
        "    fig = plt.figure(figsize = (20,6))\n",
        "    building_acf = fig.add_subplot(211)\n",
        "    acf_plot = sm.graphics.tsa.plot_acf (bldg_specific_steam.dropna(),lags = 40, ax = building_acf )\n",
        "    building_pacf = fig.add_subplot(212)\n",
        "    pacf_plot = sm.graphics.tsa.plot_pacf (bldg_specific_steam.dropna(),lags = 40, ax = building_pacf )"
      ],
      "id": "Op7wUI1C-hgv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TasY99xE-hgw"
      },
      "source": [
        "for BLDG in all_buildings:\n",
        " \n",
        "    bldg_specific_steam = stm_df[BLDG]\n",
        "    bldg_specific_steam= pd.DataFrame(bldg_specific_steam)\n",
        "    print(bldg_specific_steam)\n",
        "    size = int(len(bldg_specific_steam) * 0.85)\n",
        "    train, test = bldg_specific_steam[0:size], bldg_specific_steam[size:len(bldg_specific_steam)]\n",
        "    train_building = [x for x in train]\n",
        "    predictions = list()\n",
        "  \n",
        "    for t in range(len(test)):\n",
        "        model = ARIMA(train, order=(3,1,5))\n",
        "        results_ARIMA = model.fit()\n",
        "        predictions = results_ARIMA.predict(start = len (train), end = len(bldg_specific_steam)-1, typ = 'levels'). rename ('ARIMA predictions')\n",
        "        print(predictions)\n",
        "        rmse = sqrt(mean_squared_error(test, predictions))\n",
        "       \n",
        "        \n",
        "        \n",
        "rmse = sqrt(mean_squared_error(test, predictions))\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "TasY99xE-hgw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmlAL6LU-hgw"
      },
      "source": [
        "\n"
      ],
      "id": "VmlAL6LU-hgw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrWZbj6O-hgy"
      },
      "source": [
        ""
      ],
      "id": "wrWZbj6O-hgy",
      "execution_count": null,
      "outputs": []
    }
  ]
}