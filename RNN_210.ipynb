{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFNRPftWw9pK"
   },
   "source": [
    "# RNN \n",
    "Didn't help with SimpleRNN: smooth the y_train, add hour to X.\n",
    "\n",
    "Try L1 regularizer on RNN(8). There are many ways to implement this and I tried only one. It make the model revert to constant predictions. Not explored further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgeDotTmw9pX",
    "outputId": "3856f352-bfbf-438c-e9fa-f98fa94f93f2"
   },
   "outputs": [],
   "source": [
    "DATAPATH=''\n",
    "try:\n",
    "    # On Google Drive, set path to my drive / data directory.\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATAPATH=PATH+'My Drive/data/'  # must end in \"/\"\n",
    "except:\n",
    "    # On home computer, set path to local data directory.\n",
    "    IN_COLAB = False\n",
    "    DATAPATH='data/'  # must end in \"/\"\n",
    "\n",
    "ZIP_FILE='BuildingData.zip'\n",
    "ZIP_PATH = DATAPATH+ZIP_FILE\n",
    "STEAM_FILE='steam.csv'\n",
    "WEATHER_FILE='weather.csv'\n",
    "MODEL_FILE='Model'  # will be used later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5deM-us2w9pZ"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats  # mode\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "mycmap = colors.ListedColormap(['red','blue'])  # list color for label 0 then 1\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ONdk510Cw9pc"
   },
   "outputs": [],
   "source": [
    "def read_zip_to_panda(zip_filename,csv_filename):\n",
    "    zip_handle = ZipFile(zip_filename)\n",
    "    csv_handle = zip_handle.open(csv_filename)\n",
    "    panda = pd.read_csv(csv_handle)\n",
    "    return panda\n",
    "def fix_date_type(panda):\n",
    "    # Convert the given timestamp column to the pandas datetime data type.\n",
    "    panda['timestamp'] = pd.to_datetime(panda['timestamp'], infer_datetime_format = True)\n",
    "    indexed = panda.set_index(['timestamp'])\n",
    "    return indexed\n",
    "def get_site_timeseries(panda,site):\n",
    "    # Assume the panda dataframe has a datetime column.\n",
    "    # (If not, call fix_date_type() before this.)\n",
    "    # Extract the timeseries for one site.\n",
    "    # Convert the datetime column to a DatetimeIndex.\n",
    "    site_df = panda[panda['site_id']==site]\n",
    "    temp_col = site_df['date']\n",
    "    temp_val = temp_col.values\n",
    "    temp_ndx = pd.DatetimeIndex(temp_val)\n",
    "    dropped = site_df.drop('date',axis=1)\n",
    "    panda = dropped.set_index(temp_ndx)\n",
    "    return panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZgkgsP6w9pg",
    "outputId": "5fb5bd15-5b3b-452d-886a-97aac16289a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTORS= 2 ['hour', 'airTemperature']\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "SITE = 'Eagle'\n",
    "METER = 'steam'\n",
    "PREDICTORS = ['hour','cloudCoverage', 'airTemperature', 'dewTemperature', 'precipDepth1HR', 'precipDepth6HR', 'seaLvlPressure', 'windDirection', 'windSpeed']\n",
    "PREDICTORS = ['hour','airTemperature']\n",
    "NUM_PREDICTORS=len(PREDICTORS)\n",
    "print(\"PREDICTORS=\",NUM_PREDICTORS,PREDICTORS)\n",
    "PREDICTED_VARIABLE = 'hour'  \n",
    "STEPS_HISTORY = 24 \n",
    "STEPS_FUTURE =  24    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6YVYM_bqw9pi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>site_id</th>\n",
       "      <th>airTemperature</th>\n",
       "      <th>cloudCoverage</th>\n",
       "      <th>dewTemperature</th>\n",
       "      <th>precipDepth1HR</th>\n",
       "      <th>precipDepth6HR</th>\n",
       "      <th>seaLvlPressure</th>\n",
       "      <th>windDirection</th>\n",
       "      <th>windSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 18:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>330.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>330.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>Eagle</td>\n",
       "      <td>-12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour site_id  airTemperature  cloudCoverage  \\\n",
       "timestamp                                                          \n",
       "2017-12-31 18:00:00    18   Eagle           -11.1            0.0   \n",
       "2017-12-31 20:00:00    20   Eagle           -12.2            0.0   \n",
       "2017-12-31 21:00:00    21   Eagle           -12.8            0.0   \n",
       "2017-12-31 22:00:00    22   Eagle           -12.8            0.0   \n",
       "2017-12-31 23:00:00    23   Eagle           -12.8            0.0   \n",
       "\n",
       "                     dewTemperature  precipDepth1HR  precipDepth6HR  \\\n",
       "timestamp                                                             \n",
       "2017-12-31 18:00:00           -20.6             0.0             NaN   \n",
       "2017-12-31 20:00:00           -21.1             0.0             NaN   \n",
       "2017-12-31 21:00:00           -21.1             0.0             NaN   \n",
       "2017-12-31 22:00:00           -20.6             0.0             NaN   \n",
       "2017-12-31 23:00:00           -20.6             0.0             NaN   \n",
       "\n",
       "                     seaLvlPressure  windDirection  windSpeed  \n",
       "timestamp                                                      \n",
       "2017-12-31 18:00:00          1026.2          330.0        2.6  \n",
       "2017-12-31 20:00:00          1027.0          320.0        1.5  \n",
       "2017-12-31 21:00:00          1027.2          310.0        2.6  \n",
       "2017-12-31 22:00:00          1027.4          330.0        3.1  \n",
       "2017-12-31 23:00:00          1027.4          320.0        4.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will have to change when we predict across multiple sites!\n",
    "wet_df = read_zip_to_panda(ZIP_PATH,WEATHER_FILE)\n",
    "wet_df = fix_date_type(wet_df)\n",
    "site_specific_weather = wet_df.loc[wet_df['site_id'] == SITE]\n",
    "site_specific_weather.insert(0,'hour',0)\n",
    "L=len(site_specific_weather)\n",
    "for i in range(0,L):\n",
    "    t=site_specific_weather.index[i]\n",
    "    h=t.hour\n",
    "    site_specific_weather.iat[i,0] = h\n",
    "site_specific_weather.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peacock_lodging_Terrie</th>\n",
       "      <th>Peacock_lodging_Francesca</th>\n",
       "      <th>Peacock_lodging_Jamaal</th>\n",
       "      <th>Peacock_education_Patience</th>\n",
       "      <th>Peacock_public_Kelvin</th>\n",
       "      <th>Peacock_assembly_Mamie</th>\n",
       "      <th>Peacock_office_Major</th>\n",
       "      <th>Peacock_education_Pasquale</th>\n",
       "      <th>Peacock_office_Effie</th>\n",
       "      <th>Peacock_office_Annie</th>\n",
       "      <th>...</th>\n",
       "      <th>Cockatoo_office_Ada</th>\n",
       "      <th>Cockatoo_education_Janet</th>\n",
       "      <th>Cockatoo_education_Minh</th>\n",
       "      <th>Cockatoo_education_Oliver</th>\n",
       "      <th>Cockatoo_education_Marva</th>\n",
       "      <th>Cockatoo_education_June</th>\n",
       "      <th>Cockatoo_education_Lionel</th>\n",
       "      <th>Cockatoo_public_Leah</th>\n",
       "      <th>Cockatoo_education_Tyler</th>\n",
       "      <th>Cockatoo_public_Shad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-31 19:00:00</th>\n",
       "      <td>241.8533</td>\n",
       "      <td>215.4024</td>\n",
       "      <td>639.3171</td>\n",
       "      <td>342.0473</td>\n",
       "      <td>1479.8580</td>\n",
       "      <td>669.7637</td>\n",
       "      <td>574.4268</td>\n",
       "      <td>1539.9567</td>\n",
       "      <td>471.9326</td>\n",
       "      <td>267.5926</td>\n",
       "      <td>...</td>\n",
       "      <td>215.5021</td>\n",
       "      <td>890.7319</td>\n",
       "      <td>437.4846</td>\n",
       "      <td>1916.2204</td>\n",
       "      <td>727.4228</td>\n",
       "      <td>1132.3494</td>\n",
       "      <td>621.8740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>715.1907</td>\n",
       "      <td>267.5935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>256.1989</td>\n",
       "      <td>232.5905</td>\n",
       "      <td>687.0603</td>\n",
       "      <td>331.8853</td>\n",
       "      <td>1426.0128</td>\n",
       "      <td>675.0972</td>\n",
       "      <td>564.3212</td>\n",
       "      <td>1759.2085</td>\n",
       "      <td>481.5564</td>\n",
       "      <td>254.9783</td>\n",
       "      <td>...</td>\n",
       "      <td>210.9283</td>\n",
       "      <td>909.0651</td>\n",
       "      <td>490.0404</td>\n",
       "      <td>1971.5018</td>\n",
       "      <td>731.6641</td>\n",
       "      <td>1120.2619</td>\n",
       "      <td>627.2668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778.3055</td>\n",
       "      <td>268.3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>245.8563</td>\n",
       "      <td>243.0206</td>\n",
       "      <td>710.0197</td>\n",
       "      <td>310.7550</td>\n",
       "      <td>1675.4829</td>\n",
       "      <td>640.8035</td>\n",
       "      <td>647.2405</td>\n",
       "      <td>1735.3011</td>\n",
       "      <td>489.8763</td>\n",
       "      <td>230.5927</td>\n",
       "      <td>...</td>\n",
       "      <td>222.1489</td>\n",
       "      <td>936.0364</td>\n",
       "      <td>429.0448</td>\n",
       "      <td>1957.5765</td>\n",
       "      <td>718.3806</td>\n",
       "      <td>1081.8156</td>\n",
       "      <td>624.3197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>777.3900</td>\n",
       "      <td>244.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>260.6364</td>\n",
       "      <td>276.0460</td>\n",
       "      <td>724.1752</td>\n",
       "      <td>320.5401</td>\n",
       "      <td>1906.5174</td>\n",
       "      <td>634.8941</td>\n",
       "      <td>639.4427</td>\n",
       "      <td>1627.2782</td>\n",
       "      <td>484.2541</td>\n",
       "      <td>264.0964</td>\n",
       "      <td>...</td>\n",
       "      <td>220.9402</td>\n",
       "      <td>897.2196</td>\n",
       "      <td>439.0410</td>\n",
       "      <td>1953.9542</td>\n",
       "      <td>728.9375</td>\n",
       "      <td>1096.4455</td>\n",
       "      <td>614.0127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>678.9083</td>\n",
       "      <td>244.7395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>293.5679</td>\n",
       "      <td>276.2506</td>\n",
       "      <td>720.1304</td>\n",
       "      <td>366.4860</td>\n",
       "      <td>1796.8740</td>\n",
       "      <td>640.4161</td>\n",
       "      <td>630.9230</td>\n",
       "      <td>1580.0464</td>\n",
       "      <td>503.8209</td>\n",
       "      <td>326.5357</td>\n",
       "      <td>...</td>\n",
       "      <td>207.5597</td>\n",
       "      <td>911.1747</td>\n",
       "      <td>431.9885</td>\n",
       "      <td>1921.4320</td>\n",
       "      <td>721.0554</td>\n",
       "      <td>1115.7129</td>\n",
       "      <td>610.7566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>798.9906</td>\n",
       "      <td>241.5469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Peacock_lodging_Terrie  Peacock_lodging_Francesca  \\\n",
       "timestamp                                                                \n",
       "2017-12-31 19:00:00                241.8533                   215.4024   \n",
       "2017-12-31 20:00:00                256.1989                   232.5905   \n",
       "2017-12-31 21:00:00                245.8563                   243.0206   \n",
       "2017-12-31 22:00:00                260.6364                   276.0460   \n",
       "2017-12-31 23:00:00                293.5679                   276.2506   \n",
       "\n",
       "                     Peacock_lodging_Jamaal  Peacock_education_Patience  \\\n",
       "timestamp                                                                 \n",
       "2017-12-31 19:00:00                639.3171                    342.0473   \n",
       "2017-12-31 20:00:00                687.0603                    331.8853   \n",
       "2017-12-31 21:00:00                710.0197                    310.7550   \n",
       "2017-12-31 22:00:00                724.1752                    320.5401   \n",
       "2017-12-31 23:00:00                720.1304                    366.4860   \n",
       "\n",
       "                     Peacock_public_Kelvin  Peacock_assembly_Mamie  \\\n",
       "timestamp                                                            \n",
       "2017-12-31 19:00:00              1479.8580                669.7637   \n",
       "2017-12-31 20:00:00              1426.0128                675.0972   \n",
       "2017-12-31 21:00:00              1675.4829                640.8035   \n",
       "2017-12-31 22:00:00              1906.5174                634.8941   \n",
       "2017-12-31 23:00:00              1796.8740                640.4161   \n",
       "\n",
       "                     Peacock_office_Major  Peacock_education_Pasquale  \\\n",
       "timestamp                                                               \n",
       "2017-12-31 19:00:00              574.4268                   1539.9567   \n",
       "2017-12-31 20:00:00              564.3212                   1759.2085   \n",
       "2017-12-31 21:00:00              647.2405                   1735.3011   \n",
       "2017-12-31 22:00:00              639.4427                   1627.2782   \n",
       "2017-12-31 23:00:00              630.9230                   1580.0464   \n",
       "\n",
       "                     Peacock_office_Effie  Peacock_office_Annie  ...  \\\n",
       "timestamp                                                        ...   \n",
       "2017-12-31 19:00:00              471.9326              267.5926  ...   \n",
       "2017-12-31 20:00:00              481.5564              254.9783  ...   \n",
       "2017-12-31 21:00:00              489.8763              230.5927  ...   \n",
       "2017-12-31 22:00:00              484.2541              264.0964  ...   \n",
       "2017-12-31 23:00:00              503.8209              326.5357  ...   \n",
       "\n",
       "                     Cockatoo_office_Ada  Cockatoo_education_Janet  \\\n",
       "timestamp                                                            \n",
       "2017-12-31 19:00:00             215.5021                  890.7319   \n",
       "2017-12-31 20:00:00             210.9283                  909.0651   \n",
       "2017-12-31 21:00:00             222.1489                  936.0364   \n",
       "2017-12-31 22:00:00             220.9402                  897.2196   \n",
       "2017-12-31 23:00:00             207.5597                  911.1747   \n",
       "\n",
       "                     Cockatoo_education_Minh  Cockatoo_education_Oliver  \\\n",
       "timestamp                                                                 \n",
       "2017-12-31 19:00:00                 437.4846                  1916.2204   \n",
       "2017-12-31 20:00:00                 490.0404                  1971.5018   \n",
       "2017-12-31 21:00:00                 429.0448                  1957.5765   \n",
       "2017-12-31 22:00:00                 439.0410                  1953.9542   \n",
       "2017-12-31 23:00:00                 431.9885                  1921.4320   \n",
       "\n",
       "                     Cockatoo_education_Marva  Cockatoo_education_June  \\\n",
       "timestamp                                                                \n",
       "2017-12-31 19:00:00                  727.4228                1132.3494   \n",
       "2017-12-31 20:00:00                  731.6641                1120.2619   \n",
       "2017-12-31 21:00:00                  718.3806                1081.8156   \n",
       "2017-12-31 22:00:00                  728.9375                1096.4455   \n",
       "2017-12-31 23:00:00                  721.0554                1115.7129   \n",
       "\n",
       "                     Cockatoo_education_Lionel  Cockatoo_public_Leah  \\\n",
       "timestamp                                                              \n",
       "2017-12-31 19:00:00                   621.8740                   NaN   \n",
       "2017-12-31 20:00:00                   627.2668                   NaN   \n",
       "2017-12-31 21:00:00                   624.3197                   NaN   \n",
       "2017-12-31 22:00:00                   614.0127                   NaN   \n",
       "2017-12-31 23:00:00                   610.7566                   NaN   \n",
       "\n",
       "                     Cockatoo_education_Tyler  Cockatoo_public_Shad  \n",
       "timestamp                                                            \n",
       "2017-12-31 19:00:00                  715.1907              267.5935  \n",
       "2017-12-31 20:00:00                  778.3055              268.3583  \n",
       "2017-12-31 21:00:00                  777.3900              244.5572  \n",
       "2017-12-31 22:00:00                  678.9083              244.7395  \n",
       "2017-12-31 23:00:00                  798.9906              241.5469  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm_df = read_zip_to_panda(ZIP_PATH,STEAM_FILE)\n",
    "stm_df = fix_date_type(stm_df)\n",
    "all_buildings = [x for x in stm_df.columns if x.startswith(SITE)]\n",
    "stm_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VynRgLt9w9pk"
   },
   "outputs": [],
   "source": [
    "# Correlation is low when buildings have many NaN and 0 meter readings.\n",
    "# We will ignore buildings that have >max bad meter readings.\n",
    "def is_usable_column(df,column_name):\n",
    "    MAX_BAD = 500 \n",
    "    bad = df[column_name].isin([0]).sum()\n",
    "    return bad<=MAX_BAD\n",
    "\n",
    "def prepare_for_learning(df):\n",
    "    num_samples = len(df) - STEPS_FUTURE - STEPS_HISTORY\n",
    "    X_shape = (num_samples,STEPS_HISTORY,NUM_PREDICTORS)\n",
    "    X=np.zeros(X_shape)\n",
    "    Y_shape = (num_samples,STEPS_FUTURE)\n",
    "    y=np.zeros(Y_shape)\n",
    "    predictor_series = df[PREDICTORS].values  # e.g. all weather values\n",
    "    predicted_series = df[PREDICTED_VARIABLE].values  # e.g. all meter readings\n",
    "    \n",
    "    for sam in range (0,num_samples): # Loop over all 1000 samples\n",
    "        # This is one array of weather for previous 24 time periods\n",
    "        one_sample = predictor_series[sam:sam+STEPS_HISTORY]\n",
    "        # Loop over all 24 time periods\n",
    "        for time in range (0,STEPS_HISTORY): # In 1 sample, loop over 24 time periods\n",
    "            one_period = one_sample[time]\n",
    "            for feat in range (0,NUM_PREDICTORS): # In 1 time period, loop over 8 weather metrics\n",
    "                X[sam,time,feat] = one_period[feat]\n",
    "        for time in range (0,STEPS_FUTURE):  \n",
    "            y[sam,time]=predicted_series[sam+STEPS_HISTORY+time]\n",
    "            # Fake data to test model\n",
    "            #t=df.index[sam+STEPS_HISTORY+time]\n",
    "            #h=t.hour\n",
    "            #y[sam,time]=h\n",
    "    return X,y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z_8rzumTw9p2"
   },
   "outputs": [],
   "source": [
    "def make_RNN():\n",
    "    rnn = Sequential([\n",
    "        SimpleRNN(8,return_sequences=True, \n",
    "                  activity_regularizer=regularizers.L1(0.1),\n",
    "                  input_shape=(STEPS_HISTORY,NUM_PREDICTORS)), \n",
    "        SimpleRNN(8,return_sequences=False),\n",
    "        Dense(STEPS_FUTURE)\n",
    "    ])\n",
    "    rnn.compile(optimizer='adam',loss=MeanSquaredError())\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_smooth(oldarray):\n",
    "    win_len=5\n",
    "    df = pd.DataFrame(oldarray)\n",
    "    newdf = df.rolling(win_len).mean()\n",
    "    newarray = np.asarray(newdf)\n",
    "    for i in range(0,win_len):\n",
    "        newarray[i]=oldarray[i]\n",
    "    return newarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas rolling() supports these window function from scipy:  \n",
    "https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XypnRqq9w9p4",
    "outputId": "77846ed2-a499-4b01-a4e6-1850e382fff3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Eagle_lodging_Edgardo\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 24, 8)             88        \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 24)                216       \n",
      "=================================================================\n",
      "Total params: 440\n",
      "Trainable params: 440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Example X train:\n",
      " [[19  8]\n",
      " [20  8]\n",
      " [21  7]\n",
      " [22  7]\n",
      " [23  7]\n",
      " [ 0  8]\n",
      " [ 1  8]\n",
      " [ 2  9]\n",
      " [ 3  9]\n",
      " [ 4  9]\n",
      " [ 5 10]\n",
      " [ 6 11]\n",
      " [ 7 10]\n",
      " [ 8 12]\n",
      " [ 9 14]\n",
      " [10 15]\n",
      " [11 16]\n",
      " [12 16]\n",
      " [13 17]\n",
      " [14 17]\n",
      " [15 17]\n",
      " [16 13]\n",
      " [17 13]\n",
      " [18 12]]\n",
      "Example y train before smooth:\n",
      " [19 20 21 22 23  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Example y train after smooth:\n",
      " [19 20 21 22 23  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "Epoch 1/50\n",
      "274/274 [==============================] - 4s 9ms/step - loss: 183.6948\n",
      "Epoch 2/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 129.5766\n",
      "Epoch 3/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 93.3731\n",
      "Epoch 4/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 74.0759\n",
      "Epoch 5/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 58.7787\n",
      "Epoch 6/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 52.5783\n",
      "Epoch 7/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 49.7249\n",
      "Epoch 8/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 48.5809\n",
      "Epoch 9/50\n",
      "274/274 [==============================] - 2s 9ms/step - loss: 48.1584\n",
      "Epoch 10/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0529\n",
      "Epoch 11/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0064\n",
      "Epoch 12/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0068\n",
      "Epoch 13/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0087\n",
      "Epoch 14/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 47.9887\n",
      "Epoch 15/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 48.0187\n",
      "Epoch 16/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 47.9938\n",
      "Epoch 17/50\n",
      "274/274 [==============================] - 3s 12ms/step - loss: 48.0068\n",
      "Epoch 18/50\n",
      "274/274 [==============================] - 3s 10ms/step - loss: 47.9923\n",
      "Epoch 19/50\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 47.9888\n",
      "Epoch 20/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 48.0027\n",
      "Epoch 21/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9913\n",
      "Epoch 22/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9802\n",
      "Epoch 23/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9987\n",
      "Epoch 24/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0041\n",
      "Epoch 25/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9955\n",
      "Epoch 26/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9986\n",
      "Epoch 27/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9862\n",
      "Epoch 28/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9918\n",
      "Epoch 29/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9890\n",
      "Epoch 30/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0033\n",
      "Epoch 31/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 47.9965\n",
      "Epoch 32/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9964\n",
      "Epoch 33/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9761\n",
      "Epoch 34/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0122\n",
      "Epoch 35/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9908\n",
      "Epoch 36/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9858\n",
      "Epoch 37/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9985\n",
      "Epoch 38/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0049\n",
      "Epoch 39/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9884\n",
      "Epoch 40/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0059\n",
      "Epoch 41/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0068\n",
      "Epoch 42/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0116\n",
      "Epoch 43/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9749\n",
      "Epoch 44/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9955\n",
      "Epoch 45/50\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 48.0044\n",
      "Epoch 46/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9902\n",
      "Epoch 47/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9848\n",
      "Epoch 48/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0006\n",
      "Epoch 49/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 47.9958\n",
      "Epoch 50/50\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 48.0002\n",
      "mean,rmse,rmse/mean,bldg: 81.96779195736434 6.922554865968152 0.08445457295676488 Eagle_lodging_Edgardo\n",
      "Example prediction:\n",
      " 0 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "Example truth:\n",
      " 0 [ 7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6]\n",
      "Example prediction:\n",
      " 1 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "Example truth:\n",
      " 1 [ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6  7]\n",
      "Example prediction:\n",
      " 2 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "Example truth:\n",
      " 2 [ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6  7  8]\n",
      "Example prediction:\n",
      " 3 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "Example truth:\n",
      " 3 [10 11 12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6  7  8  9]\n",
      "Example prediction:\n",
      " 4 [11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11]\n",
      "Example truth:\n",
      " 4 [11 12 13 14 15 16 17 18 19 20 21 22 23  0  1  2  3  4  5  6  7  8  9 10]\n",
      "History 24 Future 24\n",
      "Column 1: Mean usage.\n",
      "Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\n",
      "Column 3: RMSE/mean normalized to help understand RMSE.\n",
      "Column 4: Building.\n",
      "     81.97       6.92  0.08   Eagle_lodging_Edgardo\n"
     ]
    }
   ],
   "source": [
    "cors = []\n",
    "for BLDG in ['Eagle_lodging_Edgardo']:  ### all_buildings:\n",
    "    print(\"Building\",BLDG)\n",
    "    # Get steam usage for one building.\n",
    "    bldg_specific_steam = stm_df[[BLDG]]\n",
    "    # Concatenate steam usage with weather.\n",
    "    one_bldg_df = pd.concat([bldg_specific_steam,site_specific_weather],axis=1)\n",
    "    # Drop the site, which is constant (we selected for one site).\n",
    "    one_bldg_df = one_bldg_df.drop(['site_id'],axis=1)\n",
    "    # The original steam table used column name = building name.\n",
    "    # We are processing one building, so rename to the column 'steam'.\n",
    "    one_bldg_df = one_bldg_df.rename(columns={BLDG : METER})\n",
    "    # In order to filter bad buildings, count sum of NaN + zero.\n",
    "    one_bldg_df = one_bldg_df.fillna(0)\n",
    "    \n",
    "    if is_usable_column(one_bldg_df,METER):\n",
    "        X,y = prepare_for_learning(one_bldg_df)\n",
    "        split = len(X)//2   # year 1 vs year 2\n",
    "        X_train = np.asarray(X[0:split])\n",
    "        y_train = np.asarray(y[0:split])\n",
    "        X_test = np.asarray(X[split:])\n",
    "        y_test = np.asarray(y[split:])\n",
    "        example=211\n",
    "        model = make_RNN()\n",
    "        print(model.summary())\n",
    "        print(\"Example X train:\\n\",X_train[example].astype(int))\n",
    "        print(\"Example y train before smooth:\\n\",y_train[example].astype(int))\n",
    "        #y_train = window_smooth(y_train)\n",
    "        print(\"Example y train after smooth:\\n\",y_train[example].astype(int))\n",
    "        model.fit(X_train,y_train,epochs=EPOCHS)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "        # Keep a table for reporting later.\n",
    "        mean = one_bldg_df[METER].mean()\n",
    "        cors.append([mean,rmse,rmse/mean,BLDG])\n",
    "        print(\"mean,rmse,rmse/mean,bldg:\",mean,rmse,rmse/mean,BLDG)\n",
    "        for hr in range(0,5):\n",
    "            print(\"Example prediction:\\n\",hr,y_pred[example+hr].astype(int))\n",
    "            print(\"Example truth:\\n\",hr,y_test[example+hr].astype(int))\n",
    "\n",
    "print(\"History\",STEPS_HISTORY,\"Future\",STEPS_FUTURE)\n",
    "print(\"Column 1: Mean usage.\")\n",
    "print(\"Column 2: RMSE of LinearRegression(X=Weather, y=Usage).\")\n",
    "print(\"Column 3: RMSE/mean normalized to help understand RMSE.\")\n",
    "print(\"Column 4: Building.\")\n",
    "for cor in sorted(cors):\n",
    "    print(\"%10.2f %10.2f %5.2f   %s\"%(cor[0],cor[1],cor[2],cor[3]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_107.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
